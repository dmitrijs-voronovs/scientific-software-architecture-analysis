id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/239:57698,interoperability,platform,platforms,57698,"TK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:57710,interoperability,platform,platformnames,57710,"lidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:58069,interoperability,platform,platforms,58069,"bayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:58081,interoperability,platform,platformnames,58081,"00xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:58440,interoperability,platform,platforms,58440,"00xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:58452,interoperability,platform,platformnames,58452,"iSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:58811,interoperability,platform,platforms,58811,"freebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:58823,interoperability,platform,platformnames,58823,"qPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:59182,interoperability,platform,platforms,59182,"freebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:59194,interoperability,platform,platformnames,59194,"qPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:564:420. chr20	10012387	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:59553,interoperability,platform,platforms,59553,"freebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:59565,interoperability,platform,platformnames,59565,"qPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:564:302. chr20	10012479	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:59924,interoperability,platform,platforms,59924,"freebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:59936,interoperability,platform,platformnames,59936,"qPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:193. chr20	10012498	.	C	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:60326,interoperability,platform,platforms,60326,"mal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:60338,interoperability,platform,platformnames,60338,"ssingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:507:209. chr20	10012518	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:60734,interoperability,platform,platforms,60734,"dPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:60746,interoperability,platform,platformnames,60746,"idSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|1:.:486:334. chr20	10012521	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:61142,interoperability,platform,platforms,61142,"xomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_Sol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:61154,interoperability,platform,platformnames,61154,",CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:489:182. chr20	10012570	.	G	GCA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKH",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:61513,interoperability,platform,platforms,61513,"dSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:61525,interoperability,platform,platformnames,61525,"=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:245:135. chr20	10012572	.	GT	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=2;callsetnames=HiSeqPE300xGATK,CGnormal;datasetsmissingcall=HiSeqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:61884,interoperability,platform,platforms,61884,"eqPE300x,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:61896,interoperability,platform,platformnames,61896,"ome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:251:135. chr20	10012631	.	C	CG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:62274,interoperability,platform,platforms,62274,"0xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_Sol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:62286,interoperability,platform,platformnames,62286,"l;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:453:278. chr20	10012636	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKH",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:62664,interoperability,platform,platforms,62664,"asetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:62676,interoperability,platform,platformnames,62676,"ll=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:467:349. chr20	10012714	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:63013,interoperability,platform,platforms,63013,"E300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:63025,interoperability,platform,platformnames,63025,"rmal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:514:167. chr20	10012751	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:63418,interoperability,platform,platforms,63418,"mal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:63430,interoperability,platform,platformnames,63430,"ssingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:492:169. chr20	10013119	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:63767,interoperability,platform,platforms,63767,"iSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:63779,interoperability,platform,platformnames,63779,"bayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:521:450. chr20	10013574	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:64116,interoperability,platform,platforms,64116,"s=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:64128,interoperability,platform,platformnames,64128,"es=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:707:600. chr20	10014990	.	C	CAT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:64465,interoperability,platform,platforms,64465,"asetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:64477,interoperability,platform,platformnames,64477,"qPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:502:227. chr20	10015679	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:64836,interoperability,platform,platforms,64836,"CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:64848,interoperability,platform,platformnames,64848,"ets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:544:780. chr20	10015761	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:65208,interoperability,platform,platforms,65208,"lsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:65220,interoperability,platform,platformnames,65220,"qPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:547:692. chr20	10018158	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:65580,interoperability,platform,platforms,65580,"ames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:65592,interoperability,platform,platformnames,65592,"0xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:612:775. chr20	10018555	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:65971,interoperability,platform,platforms,65971,"bayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:65983,interoperability,platform,platformnames,65983,"00xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:1024. chr20	10019093	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:66368,interoperability,platform,platforms,66368,",IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:66380,interoperability,platform,platformnames,66380,"atasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:789:758. chr20	10020229	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:66740,interoperability,platform,platforms,66740,"qPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:66752,interoperability,platform,platformnames,66752,"normal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1071. chr20	10023689	.	G	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:67083,interoperability,platform,platforms,67083,"SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:67095,interoperability,platform,platformnames,67095,"llsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:746:1471. chr20	10024107	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:67436,interoperability,platform,platforms,67436,"PE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:67448,interoperability,platform,platformnames,67448,"l,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:670:1017. chr20	10026357	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:67785,interoperability,platform,platforms,67785,"=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:67797,interoperability,platform,platformnames,67797,"s=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:887:681. chr20	10026794	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:68205,interoperability,platform,platforms,68205,",HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:68217,interoperability,platform,platformnames,68217,"TK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:646:660. chr20	10027234	.	A	ATTAG	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:68627,interoperability,platform,platforms,68627,",SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:68639,interoperability,platform,platformnames,68639,"owcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:756:506. chr20	10027868	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:69002,interoperability,platform,platforms,69002,"atasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:69014,interoperability,platform,platformnames,69014,"call=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:655:1008. chr20	10027872	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:69368,interoperability,platform,platforms,69368,"300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:69380,interoperability,platform,platformnames,69380,"mal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0|1:.:661:1201. chr20	10028867	.	A	ATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:69740,interoperability,platform,platforms,69740,"SeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:69752,interoperability,platform,platformnames,69752,"datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	0/1:.:578:160. chr20	10030188	.	T	A	50	PASS	platforms=4;platformnames=Illumina,CG,Ion,Solid;datasets=5;datasetnames=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:70089,interoperability,platform,platforms,70089,",IonExome,SolidPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:70101,interoperability,platform,platformnames,70101,"dPE50x50bp,SolidSE75bp;callsets=6;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC,SolidPE50x50GATKHC,SolidSE75GATKHC;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:789:1079. chr20	10031254	.	A	AT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:70482,interoperability,platform,platforms,70482,"names=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:70494,interoperability,platform,platformnames,70494,"00xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:767:1002. chr20	10031342	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:70853,interoperability,platform,platforms,70853,"freebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:70865,interoperability,platform,platformnames,70865,"qPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:757. chr20	10031798	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:71253,interoperability,platform,platforms,71253,"l,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:71265,interoperability,platform,platformnames,71265,"KHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:724:226. chr20	10031827	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:71596,interoperability,platform,platforms,71596,"reebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:71608,interoperability,platform,platformnames,71608,"PE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:737:452. chr20	10032094	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:71998,interoperability,platform,platforms,71998,"qPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:72010,interoperability,platform,platformnames,72010,"normal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:742:634. chr20	10032413	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Ion;datasets=3;datasetnames=HiSeqPE300x,CGnormal,IonExome;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:72403,interoperability,platform,platforms,72403,"K,CGnormal,IonExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:72415,interoperability,platform,platformnames,72415,"ExomeTVC;datasetsmissingcall=SolidPE50x50bp,SolidSE75bp;lowcov=CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:858:819. chr20	10032882	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:72777,interoperability,platform,platforms,72777,";datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:72789,interoperability,platform,platformnames,72789,"ngcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:880:812. chr20	10032972	.	C	CAT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:73152,interoperability,platform,platforms,73152,"TK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:73164,interoperability,platform,platformnames,73164,"lidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:670:987. chr20	10034306	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:73579,interoperability,platform,platforms,73579,"50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:73591,interoperability,platform,platformnames,73591,"tasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:601:949. chr20	10037037	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:73985,interoperability,platform,platforms,73985,"ov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:73997,interoperability,platform,platformnames,73997,"TVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:643:396. chr20	10037110	.	T	TGATA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:74357,interoperability,platform,platforms,74357,"owcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:74369,interoperability,platform,platformnames,74369,"mal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:545:237. chr20	10037144	.	T	TGATAGATA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xGATK,HiSeqPE300xfreebayes;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:74761,interoperability,platform,platforms,74761,"lidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,Sol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:74773,interoperability,platform,platformnames,74773,"ov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:405:99. chr20	10037709	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:75161,interoperability,platform,platforms,75161,"ATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebaye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:75173,interoperability,platform,platformnames,75173,"missingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:709:1048. chr20	10039371	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:75587,interoperability,platform,platforms,75587,"ov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,Hi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:75599,interoperability,platform,platformnames,75599,"TVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:694:733. chr20	10040772	.	C	CT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:76007,interoperability,platform,platforms,76007,"C_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:76019,interoperability,platform,platformnames,76019,"lidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:684:227. chr20	10041304	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:76429,interoperability,platform,platforms,76429,"owcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:76441,interoperability,platform,platformnames,76441,"PE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:626:454. chr20	10041701	.	A	ATATG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:76819,interoperability,platform,platforms,76819,"S_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:76831,interoperability,platform,platformnames,76831,"GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidSE75GATKHC_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:183:99. chr20	10042319	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:77241,interoperability,platform,platforms,77241,"l=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:77253,interoperability,platform,platformnames,77253,"cov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:409. chr20	10042761	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:77632,interoperability,platform,platforms,77632,"idSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:77644,interoperability,platform,platformnames,77644,"atasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:720:472. chr20	10042829	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:78054,interoperability,platform,platforms,78054,"=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:78066,interoperability,platform,platformnames,78066,"ov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:723:479. chr20	10043002	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:78444,interoperability,platform,platforms,78444,"idSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:78456,interoperability,platform,platformnames,78456,"atasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:749:1139. chr20	10044849	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:78876,interoperability,platform,platforms,78876,";lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:78888,interoperability,platform,platformnames,78888,"ExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:559:433. chr20	10045078	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:79232,interoperability,platform,platforms,79232,"al,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:79244,interoperability,platform,platformnames,79244,"0GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:649:507. chr20	10045642	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:79581,interoperability,platform,platforms,79581,"SeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:79593,interoperability,platform,platformnames,79593,"ayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:712:438. chr20	10046178	.	AAGAAAGAAAG	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonEx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:79982,interoperability,platform,platforms,79982,"ayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:79994,interoperability,platform,platformnames,79994,"0xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:469:160. chr20	10046537	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:80354,interoperability,platform,platforms,80354,",HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:80366,interoperability,platform,platformnames,80366,"TK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:554:852. chr20	10050828	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:80725,interoperability,platform,platforms,80725,"eqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:80737,interoperability,platform,platformnames,80737,"Gnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:646:1011. chr20	10051448	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;dataset",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:81104,interoperability,platform,platforms,81104,"SeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:81116,interoperability,platform,platformnames,81116,"ayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:614:1278. chr20	10052688	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=Hi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:81516,interoperability,platform,platforms,81516,"mal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:81528,interoperability,platform,platformnames,81528,"ATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:774:770. chr20	10058022	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:81981,interoperability,platform,platforms,81981,"S_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:81993,interoperability,platform,platformnames,81993,"GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:1257. chr20	10067049	.	TAAAAAAA	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:82371,interoperability,platform,platforms,82371,"v,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:82383,interoperability,platform,platformnames,82383,"GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:225:157. chr20	10067090	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:82773,interoperability,platform,platforms,82773,"normal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:82785,interoperability,platform,platformnames,82785,"CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:460:375. chr20	10067264	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:83169,interoperability,platform,platforms,83169,"50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:83181,interoperability,platform,platformnames,83181,"lidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:563:436. chr20	10067722	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,Soli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:83591,interoperability,platform,platforms,83591,"setsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,Solid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:83603,interoperability,platform,platformnames,83603,"l=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:602:405. chr20	10068158	.	GTGTATATATATA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xGATK;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:83962,interoperability,platform,platforms,83962,"=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:83974,interoperability,platform,platformnames,83974,"owcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:171:99. chr20	10068981	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:84369,interoperability,platform,platforms,84369,"SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,Soli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:84381,interoperability,platform,platformnames,84381,"C;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:615:401. chr20	10070602	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;da",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:84775,interoperability,platform,platforms,84775,"tasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:84787,interoperability,platform,platformnames,84787,"all=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:498:351. chr20	10070936	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:85165,interoperability,platform,platforms,85165,"call=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datase",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:85177,interoperability,platform,platformnames,85177,"SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:674:370. chr20	10070938	.	G	GA	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:85587,interoperability,platform,platforms,85587,"olidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=Ion",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:85599,interoperability,platform,platformnames,85599,"cov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1|1:.:667:349. chr20	10071135	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:85977,interoperability,platform,platforms,85977,"lidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:85989,interoperability,platform,platformnames,85989,"datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:705:449. chr20	10071187	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasets",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:86348,interoperability,platform,platforms,86348,"lidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:86360,interoperability,platform,platformnames,86360,"HC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:701:517. chr20	10071890	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:86767,interoperability,platform,platforms,86767,",SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:86779,interoperability,platform,platformnames,86779,"ATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:598:473. chr20	10072505	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:87189,interoperability,platform,platforms,87189,"olidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:87201,interoperability,platform,platformnames,87201,"lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:616:449. chr20	10074187	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:87611,interoperability,platform,platforms,87611,"TVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:87623,interoperability,platform,platformnames,87623,"SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:631:376. chr20	10074240	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,Soli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:88033,interoperability,platform,platforms,88033,"_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:88045,interoperability,platform,platformnames,88045,"idPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:666:381. chr20	10074716	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:88455,interoperability,platform,platforms,88455,"_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKH",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:88467,interoperability,platform,platformnames,88467,"idPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:596:339. chr20	10074806	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:88827,interoperability,platform,platforms,88827,"datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:88839,interoperability,platform,platformnames,88839,"gcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:591:435. chr20	10075043	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_Ion",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:89202,interoperability,platform,platforms,89202,"TK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmiss",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:89214,interoperability,platform,platformnames,89214,"lidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:564:430. chr20	10075168	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:89583,interoperability,platform,platforms,89583,"00xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:89595,interoperability,platform,platformnames,89595,"iSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:564:366. chr20	10075508	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:89974,interoperability,platform,platforms,89974,"CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:89986,interoperability,platform,platformnames,89986,"ome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:526:160. chr20	10076250	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:90365,interoperability,platform,platforms,90365,"call=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;data",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:90377,interoperability,platform,platformnames,90377,"SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:470:469. chr20	10076339	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:90736,interoperability,platform,platforms,90736,"es,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetname",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:90748,interoperability,platform,platformnames,90748,"GATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:1194. chr20	10076399	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:91179,interoperability,platform,platforms,91179,"SE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebaye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:91191,interoperability,platform,platformnames,91191,"asetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:678:1291. chr20	10077752	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:91603,interoperability,platform,platforms,91603,"nExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:91615,interoperability,platform,platformnames,91615,"ov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:799:833. chr20	10081750	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:92025,interoperability,platform,platforms,92025,"GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:92037,interoperability,platform,platformnames,92037,"CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:725:944. chr20	10081800	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:92415,interoperability,platform,platforms,92415,"IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=Ion",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:92427,interoperability,platform,platformnames,92427,"wcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:661:998. chr20	10082892	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:92805,interoperability,platform,platforms,92805,"lidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:92817,interoperability,platform,platformnames,92817,"datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:461:289. chr20	10085211	.	A	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:93210,interoperability,platform,platforms,93210,"dPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:93222,interoperability,platform,platformnames,93222,",SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:702:901. chr20	10086110	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:93582,interoperability,platform,platforms,93582,"GATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:93594,interoperability,platform,platformnames,93594,"SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:760:880. chr20	10086283	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:93954,interoperability,platform,platforms,93954,"00xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:93966,interoperability,platform,platformnames,93966,"al,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:731:746. chr20	10086619	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:94325,interoperability,platform,platforms,94325,"ames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:94337,interoperability,platform,platformnames,94337,"0xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:699:1053. chr20	10086853	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:94730,interoperability,platform,platforms,94730,"300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:94742,interoperability,platform,platformnames,94742,"mal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:695:1044. chr20	10086954	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnorma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:95101,interoperability,platform,platforms,95101,"E300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:95113,interoperability,platform,platformnames,95113,"rmal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:623:832. chr20	10087230	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:95501,interoperability,platform,platforms,95501,"ATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:95513,interoperability,platform,platformnames,95513,"missingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:747:973. chr20	10087394	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:95922,interoperability,platform,platforms,95922,"ssingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,Soli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:95934,interoperability,platform,platformnames,95934,"xome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:769:699. chr20	10087754	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:96307,interoperability,platform,platforms,96307,"xome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:96319,interoperability,platform,platformnames,96319,"x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:723:924. chr20	10087804	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:96726,interoperability,platform,platforms,96726,";lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:96738,interoperability,platform,platformnames,96738,"ormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:685:929. chr20	10087820	.	C	CAG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:97075,interoperability,platform,platforms,97075,"al,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:97087,interoperability,platform,platformnames,97087,"lidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:543:147. chr20	10088063	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:97424,interoperability,platform,platforms,97424,"ts=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:97436,interoperability,platform,platformnames,97436,"mes=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:748:690. chr20	10088699	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:97773,interoperability,platform,platforms,97773,"asetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:97785,interoperability,platform,platformnames,97785,"qPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:624:550. chr20	10088730	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:98122,interoperability,platform,platforms,98122,"asetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:98134,interoperability,platform,platformnames,98134,"qPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:603:655. chr20	10088736	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:98471,interoperability,platform,platforms,98471,"asetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:98483,interoperability,platform,platformnames,98483,"qPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:599:747. chr20	10088747	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:98854,interoperability,platform,platforms,98854,"lsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:98866,interoperability,platform,platformnames,98866,"tnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:576:751. chr20	10088799	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:99225,interoperability,platform,platforms,99225,"iSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:99237,interoperability,platform,platformnames,99237,"bayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:538:746. chr20	10088895	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:99597,interoperability,platform,platforms,99597,"eqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:99609,interoperability,platform,platformnames,99609,"Gnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:429:670. chr20	10089441	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:99953,interoperability,platform,platforms,99953,"lsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_Ion",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:99965,interoperability,platform,platformnames,99965,"tnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:668:933. chr20	10089525	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:100324,interoperability,platform,platforms,100324,"lsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:100336,interoperability,platform,platformnames,100336,"tnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:712:924. chr20	10090289	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;dataset",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:100695,interoperability,platform,platforms,100695,"00xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:100707,interoperability,platform,platformnames,100707,"iSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:441:160. chr20	10090764	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:101115,interoperability,platform,platforms,101115,"mal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:101127,interoperability,platform,platformnames,101127,"ATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:656:967. chr20	10090970	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:101507,interoperability,platform,platforms,101507,"atasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:101519,interoperability,platform,platformnames,101519,"call=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:591:642. chr20	10091214	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:101863,interoperability,platform,platforms,101863,"ATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:101875,interoperability,platform,platformnames,101875,"olidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:563:1218. chr20	10092415	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:102241,interoperability,platform,platforms,102241,"setnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:102253,interoperability,platform,platformnames,102253,"PE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:728:1152. chr20	10093568	.	GT	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:102612,interoperability,platform,platforms,102612,"bayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_Solid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:102624,interoperability,platform,platformnames,102624,"00xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:412:160. chr20	10093923	.	T	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:102983,interoperability,platform,platforms,102983,"es,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExome",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:102995,interoperability,platform,platformnames,102995,"GATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:623:986. chr20	10094251	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:103364,interoperability,platform,platforms,103364,"eqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:103376,interoperability,platform,platformnames,103376,"yes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:638:879. chr20	10094582	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:103720,interoperability,platform,platforms,103720,"allsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:103732,interoperability,platform,platformnames,103732,"SeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:618:846. chr20	10094774	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:104111,interoperability,platform,platforms,104111,"00xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:104123,interoperability,platform,platformnames,104123,"iSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:689:1065. chr20	10095432	.	GTGATGATGA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:104511,interoperability,platform,platforms,104511,"CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:104523,interoperability,platform,platformnames,104523,"ome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:411:160. chr20	10095741	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:104882,interoperability,platform,platforms,104882,"E300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:104894,interoperability,platform,platformnames,104894,"rmal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:634:1118. chr20	10096293	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:105273,interoperability,platform,platforms,105273,"mal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKH",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:105285,interoperability,platform,platformnames,105285,"ATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:985. chr20	10096596	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:105623,interoperability,platform,platforms,105623,"etnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:105635,interoperability,platform,platformnames,105635,"E300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:661:932. chr20	10096768	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:105972,interoperability,platform,platforms,105972,"E50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:105984,interoperability,platform,platformnames,105984,"SE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:647:1022. chr20	10096899	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:106343,interoperability,platform,platforms,106343,"Gnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKH",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:106355,interoperability,platform,platformnames,106355,"ts=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:677:825. chr20	10096905	.	TA	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:106715,interoperability,platform,platforms,106715,"lsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:106727,interoperability,platform,platformnames,106727,"qPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:658:797. chr20	10096933	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:107090,interoperability,platform,platforms,107090,"s=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:107102,interoperability,platform,platformnames,107102,"reebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:916. chr20	10096958	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:107475,interoperability,platform,platforms,107475,"reebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,Sol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:107487,interoperability,platform,platformnames,107487,"PE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:730:1035. chr20	10097075	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:107864,interoperability,platform,platforms,107864,"00xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:107876,interoperability,platform,platformnames,107876,"al,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:732:1300. chr20	10097101	.	C	CTTT	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:108261,interoperability,platform,platforms,108261,"Exome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:108273,interoperability,platform,platformnames,108273,"0x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:565:365. chr20	10097436	.	CTTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTTCTTT	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:108633,interoperability,platform,platforms,108633,"nExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:108645,interoperability,platform,platformnames,108645,"50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	1|0:.:368:148. chr20	10097453	.	CTTTC	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:109001,interoperability,platform,platforms,109001,"E300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:109013,interoperability,platform,platformnames,109013,",IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt;arbitrated=TRUE	GT:PS:DP:GQ	0|1:.:129:148. chr20	10097626	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:109372,interoperability,platform,platforms,109372,"setnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:109384,interoperability,platform,platformnames,109384,"PE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:609:1043. chr20	10097789	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:109772,interoperability,platform,platforms,109772,"CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:109784,interoperability,platform,platformnames,109784,"etsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:592:566. chr20	10097928	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:110172,interoperability,platform,platforms,110172,"Exome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:110184,interoperability,platform,platformnames,110184,"0x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:589:338. chr20	10098110	.	G	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_Ion",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:110562,interoperability,platform,platforms,110562,"p,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:110574,interoperability,platform,platformnames,110574,"lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:611:238. chr20	10098135	.	C	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:110969,interoperability,platform,platforms,110969,"SE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:110981,interoperability,platform,platformnames,110981,"CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:608:280. chr20	10098945	.	T	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:111376,interoperability,platform,platforms,111376,"normal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:111388,interoperability,platform,platformnames,111388,"CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt	GT:PS:DP:GQ	0/1:.:432:160. chr20	10099044	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:111783,interoperability,platform,platforms,111783,"eTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:111795,interoperability,platform,platformnames,111795,"_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:416:425. chr20	10099046	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:112190,interoperability,platform,platforms,112190,"eTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:112202,interoperability,platform,platformnames,112202,"_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0|1:.:418:425. chr20	10099055	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:112558,interoperability,platform,platforms,112558,"PE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:112570,interoperability,platform,platformnames,112570,"dSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:432:525. chr20	10099079	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:112936,interoperability,platform,platforms,112936,"etsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_Ion",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:112948,interoperability,platform,platformnames,112948,"=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:451:461. chr20	10099140	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:113326,interoperability,platform,platforms,113326,"TK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:113338,interoperability,platform,platformnames,113338,"tasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:563:393. chr20	10099190	.	G	T	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:113697,interoperability,platform,platforms,113697,"ingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:113709,interoperability,platform,platformnames,113709,"al,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:592:160. chr20	10099220	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:114100,interoperability,platform,platforms,114100,"all=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,Solid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:114112,interoperability,platform,platformnames,114112,"olidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:691:310. chr20	10099250	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;dat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:114504,interoperability,platform,platforms,114504,"olidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:114516,interoperability,platform,platformnames,114516,"SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:619:296. chr20	10099535	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDEL PASS 4 4 0 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:114895,interoperability,platform,platforms,114895,"=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDEL PASS 4 4 0 48 0 44 0 1 1 0,916667 1 . SNP ALL 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. SNP PASS 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. ```. Is it normal? Is `test_nist.b37_chr20_100kbp_at_10mb.vcf` outdated or it is made on latest deepvariant version?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:114907,interoperability,platform,platformnames,114907,"=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDEL PASS 4 4 0 48 0 44 0 1 1 0,916667 1 . SNP ALL 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. SNP PASS 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. ```. Is it normal? Is `test_nist.b37_chr20_100kbp_at_10mb.vcf` outdated or it is made on latest deepvariant version?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1104,modifiability,scal,scaled,1104,"have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28880,modifiability,INTEGR,INTEGRATION,28880,"g=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:115798,modifiability,version,version,115798,"=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDEL PASS 4 4 0 48 0 44 0 1 1 0,916667 1 . SNP ALL 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. SNP PASS 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. ```. Is it normal? Is `test_nist.b37_chr20_100kbp_at_10mb.vcf` outdated or it is made on latest deepvariant version?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1104,performance,scale,scaled,1104,"have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28880,reliability,INTEGR,INTEGRATION,28880,"g=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:21,safety,test,test,21,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:133,safety,test,test,133,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:169,safety,test,test,169,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24961,safety,Compl,Complete,24961," ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Desc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25004,safety,compl,completely,25004,"ist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at lea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:50,security,team,team,50,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:335,security,model,model,335,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24961,security,Compl,Complete,24961," ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Desc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25004,security,compl,completely,25004,"ist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at lea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28880,security,INTEGR,INTEGRATION,28880,"g=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:21,testability,test,test,21,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:133,testability,test,test,133,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:169,testability,test,test,169,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:852,testability,observ,observed,852,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:27370,testability,coverag,coverage,27370,"erent datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<ID=filt,Number=1,Type=String,Description=""List of callsets that had this call filtered."">. ##INFO=<ID=lowcov,Number=1,Type=String,Description=""List of callsets that had this call in a region with low coverage of high MQ reads."">. ##INFO=<ID=arbitrated,Number=1,Type=String,Description=""TRUE if callsets had discordant calls so that arbitration was needed."">. ##contig=<ID=chr1,length=249250621,assembly=b37>. ##contig=<ID=chr2,length=243199373,assembly=b37>. ##contig=<ID=chr3,length=198022430,assembly=b37>. ##contig=<ID=chr4,length=191154276,assembly=b37>. ##contig=<ID=chr5,length=180915260,assembly=b37>. ##contig=<ID=chr6,length=171115067,assembly=b37>. ##contig=<ID=chr7,length=159138663,assembly=b37>. ##contig=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,asse",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28880,testability,INTEGR,INTEGRATION,28880,"g=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:84,usability,tool,tool,84,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:841,usability,Minim,Minimum,841,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1147,usability,close,closest,1147,"ls>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:36:0,36:1:4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26259,usability,indicat,indicating,26259,"ined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<ID=filt,Number=1,Type=String,Description=""List of callsets that had this call filtered."">. ##I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/240:0,energy efficiency,GPU,GPU,0,"GPU Selection; Dear,. Apology for a not really related software issue,. Do you have any suggestions for the minimum specs needed for a GPU? For example, I would like to know PNY Quadro P5000, is able to handle the tasks. Thanks in advance. Amin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:135,energy efficiency,GPU,GPU,135,"GPU Selection; Dear,. Apology for a not really related software issue,. Do you have any suggestions for the minimum specs needed for a GPU? For example, I would like to know PNY Quadro P5000, is able to handle the tasks. Thanks in advance. Amin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:0,performance,GPU,GPU,0,"GPU Selection; Dear,. Apology for a not really related software issue,. Do you have any suggestions for the minimum specs needed for a GPU? For example, I would like to know PNY Quadro P5000, is able to handle the tasks. Thanks in advance. Amin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:135,performance,GPU,GPU,135,"GPU Selection; Dear,. Apology for a not really related software issue,. Do you have any suggestions for the minimum specs needed for a GPU? For example, I would like to know PNY Quadro P5000, is able to handle the tasks. Thanks in advance. Amin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:108,usability,minim,minimum,108,"GPU Selection; Dear,. Apology for a not really related software issue,. Do you have any suggestions for the minimum specs needed for a GPU? For example, I would like to know PNY Quadro P5000, is able to handle the tasks. Thanks in advance. Amin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/241:203,deployability,releas,released,203,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:212,deployability,version,versions,212,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:123,energy efficiency,current,current,123,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:131,energy efficiency,model,model,131,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:212,integrability,version,versions,212,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:338,interoperability,specif,specify,338,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:72,modifiability,exten,extend,72,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:212,modifiability,version,versions,212,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:19,performance,perform,performance,19,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:190,performance,time,time,190,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:426,performance,network,network,426,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:329,reliability,doe,does,329,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:131,security,model,model,131,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:426,security,network,network,426,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:63,testability,plan,plans,63,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:19,usability,perform,performance,19,"Somatic calls (and performance in general); Hi,. Are there any plans to extend DeepVariant to somatic variant calling? The current model seems to be inherently diploid. What is the training time for the released versions of DeepVariant? The Supplementary information from the Nature paper mentions something about ""80 hours"" but does not specify which kind of hardware was used? Do you have any numbers on how much the neural network improves the accuracy as compared to the raw (over-sensitive) variant calls output after the haplotype-aware realignment step?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/242:1373,deployability,updat,updating,1373,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1769,deployability,modul,module,1769,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1495,modifiability,Concern,Concerning,1495,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1769,modifiability,modul,module,1769,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1373,safety,updat,updating,1373,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1769,safety,modul,module,1769,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:867,security,expos,exposed,867,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1373,security,updat,updating,1373,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1495,testability,Concern,Concerning,1495,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:284,usability,confirm,confirmed,284,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:882,usability,user,users,882,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1188,usability,user,user,1188,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:1193,usability,experien,experience,1193,"Non-unique names of temp files; Running several DeepVariant jobs (v0.9.0) on the same server, e.g., by splitting a dataset via the `--regions` option, results in corrupted files (DataLossError) because of non-unique file names for the temp files generated under `/tmp` on the server (confirmed, see below). > I just checked the code, and you're right that the temp file names will be the same:. > https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L264-L266. > For now, please pass in different `intermediate_results_dir` for each run. > For example:. > `--intermediate_results_dir=""/tmp/deepvariant_tmp_output/chr1""` for chr1, and so on. > I'll think about how we want to improve this in the future. I can think of a few options for future improvements, such as :. > 1. Use a random name for the internal /tmp files. Given that these are not exposed to the users anyway. > 2. Use a unique name derived from the output VCF file, instead of calling all temp files the same name. > For now, using the `--intermediate_results_dir` should hopefully resolve your issue. Let me know if it works. If you have a suggestion on what's the best future improvement for better user experience, please let me know. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/175#issuecomment-560625427_. @pichuan. I think as an immediate step, updating the docs and making this explicit (also the option of using the `intermediate_results_dir`) would be reasonable. Concerning a proper solution, creating a randomly named temp dir for all temp files of the job (which then could have non-random names) seems like a very straightforward way; ideally, this should also take care of the clean-up, e.g.,as it is provided by Python's `tempfile` module. I assume basic functionality like this exists in all relevant programming languages. +Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/243:2115,availability,operat,operating,2115,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2285,availability,error,error,2285,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2409,availability,error,error,2409,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:371,deployability,modul,module,371,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:537,deployability,modul,module,537,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:669,deployability,modul,module,669,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:864,deployability,modul,module,864,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:987,deployability,modul,module,987,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1114,deployability,modul,module,1114,"ariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1269,deployability,modul,module,1269,"/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1276,deployability,fail,failed,1276,"runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1324,deployability,fail,failed,1324,"t/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1331,deployability,build,build,1331,"ariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1472,deployability,version,version,1472,"-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No suc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1552,deployability,version,version,1552,"sorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1574,deployability,instal,installed,1574,"ome/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1591,deployability,instal,installation,1591,"local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1904,deployability,version,versions,1904,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2063,deployability,instal,installed,2063,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2091,deployability,instal,installed,2091,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2168,deployability,version,versions,2168,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2187,deployability,instal,installed,2187,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2240,deployability,version,versions,2240,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2263,deployability,build,build,2263,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2269,deployability,log,log,2269,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2596,deployability,version,version,2596,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:130,energy efficiency,gpu,gpu,130,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1010,energy efficiency,core,core,1010,"Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1082,energy efficiency,core,core,1082,"r directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2592,energy efficiency,GPU,GPU,2592,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1409,integrability,repositor,repository,1409,"trics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1472,integrability,version,version,1472,"-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No suc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1552,integrability,version,version,1552,"sorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1904,integrability,version,versions,1904,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2168,integrability,version,versions,2168,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2240,integrability,version,versions,2240,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2596,integrability,version,version,2596,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:50,interoperability,share,shared,50,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1409,interoperability,repositor,repository,1409,"trics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2450,interoperability,share,shared,2450,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2574,interoperability,platform,platform,2574,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:371,modifiability,modul,module,371,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:477,modifiability,pac,packages,477,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:537,modifiability,modul,module,537,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:622,modifiability,pac,packages,622,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:669,modifiability,modul,module,669,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:810,modifiability,pac,packages,810,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:864,modifiability,modul,module,864,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:944,modifiability,pac,packages,944,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:987,modifiability,modul,module,987,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1067,modifiability,pac,packages,1067,"o such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1114,modifiability,modul,module,1114,"ariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1259,modifiability,extens,extension,1259,"le ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1269,modifiability,modul,module,1269,"/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1472,modifiability,version,version,1472,"-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No suc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1552,modifiability,version,version,1552,"sorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1904,modifiability,version,versions,1904,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2168,modifiability,version,versions,2168,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2240,modifiability,version,versions,2240,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2596,modifiability,version,version,2596,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:130,performance,gpu,gpu,130,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2285,performance,error,error,2285,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2409,performance,error,error,2409,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2592,performance,GPU,GPU,2592,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1276,reliability,fail,failed,1276,"runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1324,reliability,fail,failed,1324,"t/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:371,safety,modul,module,371,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:537,safety,modul,module,537,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:669,safety,modul,module,669,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:864,safety,modul,module,864,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:987,safety,modul,module,987,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1114,safety,modul,module,1114,"ariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1269,safety,modul,module,1269,"/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2269,safety,log,log,2269,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2285,safety,error,error,2285,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2409,safety,error,error,2409,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1480,security,control,control,1480,"s/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2269,security,log,log,2269,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:226,testability,Trace,Traceback,226,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1480,testability,control,control,1480,"s/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1521,testability,simpl,simply,1521,"line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2269,testability,log,log,2269,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:214,usability,user,user,214,"Singularity Issue - libopenblas.so.0: cannot open shared object file: No such file or directory; Converting the deepvariant 0.9.0-gpu docker image to singularity results in the following issue when run as non-root user:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lkokkqy4/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 46, in <module>. from tensor2tensor.utils import metrics_hook. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensor2tensor/utils/metrics_hook.py"", line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1521,usability,simpl,simply,1521,"line 22, in <module>. import tensorflow as tf. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2285,usability,error,error,2285,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2409,usability,error,error,2409,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2542,usability,user,user,2542,"e-packages/tensorflow/__init__.py"", line 24, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 47, in <module>. import numpy as np. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/__init__.py"", line 142, in <module>. from . import core. File ""/home/josephguhlin/.local/lib/python2.7/site-packages/numpy/core/__init__.py"", line 47, in <module>. raise ImportError(msg). ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE! Importing the multiarray numpy extension module failed. Most. likely you are trying to import a failed build of numpy. Here is how to proceed:. - If you're working with a numpy git repository, try `git clean -xdf`. (removes all files not under version control) and rebuild numpy. - If you are simply trying to use the numpy version that you have installed:. your installation is broken - please reinstall numpy. - If you have already reinstalled and that did not fix the problem, then:. 1. Check that you are using the Python you expect (you're using /usr/bin/python),. and that you have no directories in your PATH or PYTHONPATH that can. interfere with the Python and numpy versions you're trying to use. 2. If (1) looks fine, you can open a new issue at. https://github.com/numpy/numpy/issues. Please include details on:. - how you installed Python. - how you installed numpy. - your operating system. - whether or not you have multiple versions of Python installed. - if you built from source, your compiler versions and ideally a build log. Note: this error has many possible causes, so please don't comment on. an existing issue about this - open a new one instead. Original error was: libopenblas.so.0: cannot open shared object file: No such file or directory. ```. I need to run deepvariant as a non-root user via singulairty on the HPC platform. The non-GPU version works just fine.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/pull/244:76,deployability,updat,update,76,"Added new blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/244
https://github.com/google/deepvariant/pull/244:121,integrability,sub,submitted,121,"Added new blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/244
https://github.com/google/deepvariant/pull/244:76,safety,updat,update,76,"Added new blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/244
https://github.com/google/deepvariant/pull/244:76,security,updat,update,76,"Added new blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/244
https://github.com/google/deepvariant/pull/244:148,security,team,team,148,"Added new blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/244
https://github.com/google/deepvariant/pull/245:0,deployability,Updat,Updated,0,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/245:104,deployability,updat,update,104,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/245:149,integrability,sub,submitted,149,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/245:0,safety,Updat,Updated,0,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/245:104,safety,updat,update,104,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/245:0,security,Updat,Updated,0,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/245:104,security,updat,update,104,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/245:176,security,team,team,176,"Updated the introduction for the ML4H blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/245
https://github.com/google/deepvariant/pull/246:89,deployability,updat,update,89,"Fixing typo in name on blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/246
https://github.com/google/deepvariant/pull/246:134,integrability,sub,submitted,134,"Fixing typo in name on blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/246
https://github.com/google/deepvariant/pull/246:89,safety,updat,update,89,"Fixing typo in name on blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/246
https://github.com/google/deepvariant/pull/246:89,security,updat,update,89,"Fixing typo in name on blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/246
https://github.com/google/deepvariant/pull/246:161,security,team,team,161,"Fixing typo in name on blog post.; Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by a DeepVariant team member.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/246
https://github.com/google/deepvariant/issues/247:837,availability,down,down,837,"Question on resolving overlapping variants; Hi, My question is regarding the following comment: https://github.com/google/deepvariant/blob/43e54207bbf37dc511d3ea092cc84cd0476e5efe/deepvariant/haplotypes.py#L335. Does ""biallelic deletion ... and inside it a biallelic SNP"" refer to something like this? ```. REF: ACATTACGATC. READ1 AC----CGA. READ2 ACAGTACG. ```. where we have the combined variant; ref = CATTA -> C/CAGTA. In this case, following the comment, it seems the recommended variant representation is (assuming reference starts at position 1 (1-based index for VCF)). ```. POS REF ALT GT field. 2 CATTA C 0/1. 4 T G 0/1. ```. However, I am wondering whether this is a valid VCF representation, since at position 4, we do not have the ref allele, but 0/1 indicates that ref allele is present at position 4. Apologize if this is down to my misunderstanding of the VCF format.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:876,interoperability,format,format,876,"Question on resolving overlapping variants; Hi, My question is regarding the following comment: https://github.com/google/deepvariant/blob/43e54207bbf37dc511d3ea092cc84cd0476e5efe/deepvariant/haplotypes.py#L335. Does ""biallelic deletion ... and inside it a biallelic SNP"" refer to something like this? ```. REF: ACATTACGATC. READ1 AC----CGA. READ2 ACAGTACG. ```. where we have the combined variant; ref = CATTA -> C/CAGTA. In this case, following the comment, it seems the recommended variant representation is (assuming reference starts at position 1 (1-based index for VCF)). ```. POS REF ALT GT field. 2 CATTA C 0/1. 4 T G 0/1. ```. However, I am wondering whether this is a valid VCF representation, since at position 4, we do not have the ref allele, but 0/1 indicates that ref allele is present at position 4. Apologize if this is down to my misunderstanding of the VCF format.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:212,reliability,Doe,Does,212,"Question on resolving overlapping variants; Hi, My question is regarding the following comment: https://github.com/google/deepvariant/blob/43e54207bbf37dc511d3ea092cc84cd0476e5efe/deepvariant/haplotypes.py#L335. Does ""biallelic deletion ... and inside it a biallelic SNP"" refer to something like this? ```. REF: ACATTACGATC. READ1 AC----CGA. READ2 ACAGTACG. ```. where we have the combined variant; ref = CATTA -> C/CAGTA. In this case, following the comment, it seems the recommended variant representation is (assuming reference starts at position 1 (1-based index for VCF)). ```. POS REF ALT GT field. 2 CATTA C 0/1. 4 T G 0/1. ```. However, I am wondering whether this is a valid VCF representation, since at position 4, we do not have the ref allele, but 0/1 indicates that ref allele is present at position 4. Apologize if this is down to my misunderstanding of the VCF format.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:678,safety,valid,valid,678,"Question on resolving overlapping variants; Hi, My question is regarding the following comment: https://github.com/google/deepvariant/blob/43e54207bbf37dc511d3ea092cc84cd0476e5efe/deepvariant/haplotypes.py#L335. Does ""biallelic deletion ... and inside it a biallelic SNP"" refer to something like this? ```. REF: ACATTACGATC. READ1 AC----CGA. READ2 ACAGTACG. ```. where we have the combined variant; ref = CATTA -> C/CAGTA. In this case, following the comment, it seems the recommended variant representation is (assuming reference starts at position 1 (1-based index for VCF)). ```. POS REF ALT GT field. 2 CATTA C 0/1. 4 T G 0/1. ```. However, I am wondering whether this is a valid VCF representation, since at position 4, we do not have the ref allele, but 0/1 indicates that ref allele is present at position 4. Apologize if this is down to my misunderstanding of the VCF format.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:764,usability,indicat,indicates,764,"Question on resolving overlapping variants; Hi, My question is regarding the following comment: https://github.com/google/deepvariant/blob/43e54207bbf37dc511d3ea092cc84cd0476e5efe/deepvariant/haplotypes.py#L335. Does ""biallelic deletion ... and inside it a biallelic SNP"" refer to something like this? ```. REF: ACATTACGATC. READ1 AC----CGA. READ2 ACAGTACG. ```. where we have the combined variant; ref = CATTA -> C/CAGTA. In this case, following the comment, it seems the recommended variant representation is (assuming reference starts at position 1 (1-based index for VCF)). ```. POS REF ALT GT field. 2 CATTA C 0/1. 4 T G 0/1. ```. However, I am wondering whether this is a valid VCF representation, since at position 4, we do not have the ref allele, but 0/1 indicates that ref allele is present at position 4. Apologize if this is down to my misunderstanding of the VCF format.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/248:159,availability,avail,available,159,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1789,availability,avail,available,1789,"=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:13,deployability,fail,fails,13,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1958,deployability,modul,module,1958,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1670,energy efficiency,core,core,1670,"ublic/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/qui",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:617,integrability,pub,public,617,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:671,integrability,pub,public,671,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:809,integrability,pub,public,809,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:892,integrability,pub,public,892,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1021,integrability,pub,public,1021,"quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packag",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1091,integrability,pub,public,1091,"w library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1231,integrability,buffer,buffer,1231,"le/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1299,integrability,pub,public,1299," using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, execu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1381,integrability,pub,public,1381,"machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2254,integrability,sub,subprocess,2254,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2347,integrability,sub,subprocess,2347,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2428,integrability,sub,subprocess,2428,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2502,integrability,buffer,buffer,2502,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2567,integrability,pub,public,2567,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2649,integrability,pub,public,2649,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1675,interoperability,platform,platform,1675,"ome/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1958,modifiability,modul,module,1958,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2018,modifiability,pac,packages,2018,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2118,modifiability,pac,packages,2118,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1197,performance,time,time,1197,"start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1212,performance,parallel,parallel,1212,"://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2468,performance,time,time,2468,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2483,performance,parallel,parallel,2483,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:13,reliability,fail,fails,13,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:159,reliability,availab,available,159,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1789,reliability,availab,available,1789,"=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:159,safety,avail,available,159,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:352,safety,permiss,permission,352,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:419,safety,permiss,permission,419,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:648,safety,test,testdata,648,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:658,safety,input,input,658,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:840,safety,test,testdata,840,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:923,safety,test,testdata,923,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1330,safety,test,testdata,1330," do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1412,safety,test,testdata,1412,"up permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(ret",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1789,safety,avail,available,1789,"=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1958,safety,modul,module,1958,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2598,safety,test,testdata,2598,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2680,safety,test,testdata,2680,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:159,security,availab,available,159,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1789,security,availab,available,1789,"=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:648,testability,test,testdata,648,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:840,testability,test,testdata,840,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:865,testability,unit,unittest,865,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:923,testability,test,testdata,923,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1330,testability,test,testdata,1330," do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1355,testability,unit,unittest,1355,"ion on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1412,testability,test,testdata,1412,"up permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(ret",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1860,testability,Trace,Traceback,1860,"unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2598,testability,test,testdata,2598,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2623,testability,unit,unittest,2623,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2680,testability,test,testdata,2680,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:205,usability,guid,guide,205,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:658,usability,input,input,658,"docker image fails with quick start data; Any idea why I can not run the docker? The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1182,usability,command,command,1182,"In the quick start guide https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md . They show using sudo to run the docker. I do not have sudo permission on this machine. The machine is set up to use the group permission. I do not think this is the issue. . Any suggestions would be greatly appreciated. Andy. ```. (base) -bash-4.2$ groups. giuser kimlab docker. (base) -bash-4.2$ . ```. ```. docker run -v /public/home/dkim142/quickstart-testdata:/input \. -v /public/home/dkim142/quickstart-output:/output google/deepvariant:0.9.0 \. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:1831,usability,user,user,1831,"kstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2276,usability,command,command,2276,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2459,usability,Command,Command,2459,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:2920,usability,statu,status,2920,"0p1mb.bam \. --regions chr20:10,000,000-10,010,000 \. --output_vcf=/public/home/dkim142/quickstart-output/output.vcf.gz \. --output_gvcf=/public/home/dkim142/quickstart-output/output.g.vcf.gz \. --num_shards=1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling \. --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2019-12-08 02:35:44.105906: F tensorflow/core/platform/cpu_feature_guard.cc:37] . The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m1.146s. user	0m1.709s. sys	0m4.191s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/public/home/dkim142/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/public/home/dkim142/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 1. (base) -bash-4.2$ . ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/249:206,deployability,fail,failed,206,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:796,deployability,log,log,796,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4562,deployability,modul,module,4562," 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5521,deployability,fail,failed,5521,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:876,integrability,buffer,buffer,876,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4858,integrability,sub,subprocess,4858,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4951,integrability,sub,subprocess,4951,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5032,integrability,sub,subprocess,5032,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5107,integrability,buffer,buffer,5107,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2357,modifiability,deco,decode,2357,"5 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3728,modifiability,deco,decode,3728,"6 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4562,modifiability,modul,module,4562," 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4622,modifiability,pac,packages,4622,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4722,modifiability,pac,packages,4722,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:841,performance,time,time,841,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:857,performance,parallel,parallel,857,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5072,performance,time,time,5072,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5088,performance,parallel,parallel,5088,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5465,performance,time,times,5465,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:206,reliability,fail,failed,206,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5521,reliability,fail,failed,5521,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:305,safety,test,testdata,305,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:410,safety,input,input,410,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:585,safety,input,input,585,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:615,safety,input,input,615,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:796,safety,log,log,796,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:941,safety,input,input,941,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:968,safety,input,input,968,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1411,safety,input,input,1411,"t"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1528,safety,input,inputs,1528,"bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1607,safety,input,input,1607,"ads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2332,safety,input,input,2332,"ENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2782,safety,input,input,2782,"', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2899,safety,input,inputs,2899,"3:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2978,safety,input,input,2978,"pvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3703,safety,input,input,3703,"..). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3970,safety,input,input,3970,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4087,safety,input,input,4087,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4562,safety,modul,module,4562," 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5172,safety,input,input,5172,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5199,safety,input,input,5199,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:796,security,log,log,796,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:305,testability,test,testdata,305,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:796,testability,log,log,796,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4464,testability,Trace,Traceback,4464,"1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several time",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:82,usability,guid,guide,82,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:193,usability,command,commands,193,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:410,usability,input,input,410,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:585,usability,input,input,585,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:615,usability,input,input,615,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:826,usability,command,command,826,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:941,usability,input,input,941,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:968,usability,input,input,968,"No output vcf after long run ; Dears, . I just followed ""DeepVariant quick start"" guide, which was successful. . Then, I've replaced the reference and reads with my own files and ran following commands but failed to get vcf files. . > OUTPUT_DIR=""${PWD}/quickstart-output"". > INPUT_DIR=""${PWD}/quickstart-testdata"". > mkdir -p ""${OUTPUT_DIR}"". > BIN_VERSION=""0.9.0"". > sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1411,usability,input,input,1411,"t"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1528,usability,input,inputs,1528,"bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1607,usability,input,input,1607,"ads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=12. Here is a log: . ```. ***** Running the command:*****. time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1208 07:03:00.340749 140610455504640 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2332,usability,input,input,2332,"ENT. I1208 07:03:00.598805 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.619033 140610455504640 make_examples.py:1324] Preparing inputs. I1208 07:03:00.814711 140610455504640 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.841161 140610455504640 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2782,usability,input,input,2782,"', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2899,usability,input,inputs,2899,"3:00.851603 140610455504640 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2978,usability,input,input,2978,"pvariant_tmp_output/make_examples.tfrecord-00000-of-00012.gz. I1208 07:03:00.852047 140610455504640 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00012.gz. I1208 07:03:00.870843 140610455504640 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.878937: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:00.416043 139802617698048 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. (skip...). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3703,usability,input,input,3703,"..). I1208 07:03:00.650166 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.666655 140516170581760 make_examples.py:1324] Preparing inputs. I1208 07:03:00.855743 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3970,usability,input,input,3970,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:00.888984 140516170581760 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4087,usability,input,input,4087,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1208 07:03:00.901866 140516170581760 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00011-of-00012.gz. I1208 07:03:00.902448 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4433,usability,user,user,4433," 140516170581760 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00011-of-00012.gz. I1208 07:03:00.955504 140516170581760 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4880,usability,command,command,4880,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5063,usability,Command,Command,5063,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5172,usability,input,input,5172,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5199,usability,input,input,5199,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5422,usability,statu,status,5422,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5548,usability,help,help,5548,"_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-08 07:03:00.994095: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1208 07:03:22.274698 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:22.779856 140516170581760 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1208 07:03:32.588432 140516170581760 make_examples.py:1363] Task 11: 0 candidates (0 examples) [31.68s elapsed]. I1208 07:03:33.147475 140516170581760 make_examples.py:1380] Found 4 candidate variants. I1208 07:03:33.259099 140516170581760 make_examples.py:1381] Created 4 examples. real	0m50.885s. user	0m34.940s. sys	2m45.810s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 11 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@12.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@12.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 3. ```. I've actually tried several times with a small changes (like no regions) which also failed. . Could you please help me to solve this problem. . Thank you in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/250:1142,availability,error,error,1142,"9.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:133,deployability,version,version,133,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:150,deployability,build,build,150,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:417,deployability,releas,release-,417,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1148,deployability,log,log,1148,"build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2281,deployability,modul,module,2281,"ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:3485,deployability,build,build,3485,"nt/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 30",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4050,deployability,build,builds,4050,"re_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4142,deployability,build,builds-,4142,"google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4216,deployability,build,build,4216,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4398,deployability,modul,module,4398,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:133,integrability,version,version,133,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:413,integrability,pub,pub,413,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1225,integrability,buffer,buffer,1225,"s. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4694,integrability,sub,subprocess,4694,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4787,integrability,sub,subprocess,4787,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4868,integrability,sub,subprocess,4868,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4942,integrability,buffer,buffer,4942,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2367,interoperability,platform,platform,2367,"ariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:133,modifiability,version,version,133,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2281,modifiability,modul,module,2281,"ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2340,modifiability,pac,packages,2340,"bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4398,modifiability,modul,module,4398,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4458,modifiability,pac,packages,4458,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4558,modifiability,pac,packages,4558,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1142,performance,error,error,1142,"9.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1191,performance,time,time,1191,"Variant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1206,performance,parallel,parallel,1206,"iginal source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4908,performance,time,time,4908,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4923,performance,parallel,parallel,4923,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:94,safety,input,input,94,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:867,safety,input,input,867,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1023,safety,input,input,1023,"84600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1059,safety,input,input,1059," were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 gen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1142,safety,error,error,1142,"9.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1148,safety,log,log,1148,"build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1290,safety,input,input,1290,"vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1328,safety,input,input,1328,"read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1672,safety,input,input,1672,"2634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1812,safety,input,input,1812,"v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2013,safety,input,inputs,2013,"--ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2092,safety,input,input,2092,"tput/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fracti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2281,safety,modul,module,2281,"ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:3407,safety,input,input,3407,"it(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4198,safety,input,input,4198,"703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me wh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4235,safety,input,input,4235,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4398,safety,modul,module,4398,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:5007,safety,input,input,5007,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:5045,safety,input,input,5045,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1148,security,log,log,1148,"build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1148,testability,log,log,1148,"build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2134,testability,Trace,Traceback,2134,"of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:3264,testability,coverag,coverage,3264,"ne 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4300,testability,Trace,Traceback,4300,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:94,usability,input,input,94,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:781,usability,command,command,781,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:867,usability,input,input,867,"Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:132",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1023,usability,input,input,1023,"84600 bases but only 0 bases (0.00%) were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1059,usability,input,input,1059," were found in common among our input files; Elementary OS 5.1. Docker version 18.09.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 gen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1142,usability,error,error,1142,"9.7, build 2d0083d. Bowtie 2. Samtools 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1176,usability,command,command,1176,"ols 1.9. DeepVariant 0.9.0. Original source files. - _SRR062634.filt.fastq_ from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1290,usability,input,input,1290,"vol1/ftp/phase3/data/HG00096/sequence_read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1328,usability,input,input,1328,"read/. - _Homo_sapiens.GRCh38.dna.primary_assembly.fa_ from ftp://ftp.ensembl.org/pub/release-98/fasta/homo_sapiens/dna/. Actions. 1. Bowtie 2: indexing _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 2. Bowtie 2: aligning _SRR062634.filt.fastq_ on _Homo_sapiens.GRCh38.dna.primary_assembly.fa_. 3. Samtools: converting _SRR062634.sam_ to _SRR062634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1672,usability,input,input,1672,"2634.bam_. 4. Samtools: indexing _SRR062634.filt.fastq_. 5. DeepVariant: trying to call SNPs. DeepVariant command syntax. `sudo docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:1812,usability,input,input,1812,"v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/input"" -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/output"" google/deepvariant:""0.9.0"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2013,usability,input,inputs,2013,"--ref=/input/SRR062634.filt.fastq --reads=/input/SRR062634.bam --output_vcf=/output/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:2092,usability,input,input,2092,"tput/SRR062634.vcf.gz --num_shards=4`. Part of error log. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}. I1208 19:49:03.680470 140573386819328 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1208 19:49:03.681448 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. W1208 19:49:03.681570 140573386819328 make_examples.py:558] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument. I1208 19:49:03.742767 140573386819328 make_examples.py:1324] Preparing inputs. I1208 19:49:05.745795 140573386819328 genomics_reader.py:223] Reading /input/SRR062634.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fracti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:3407,usability,input,input,3407,"it(main(argv)). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1247, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 625, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_pllyfZ/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4198,usability,input,input,4198,"703, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me wh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4235,usability,input,input,4235,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4269,usability,user,user,4269,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4716,usability,command,command,4716,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:4899,usability,Command,Command,4899,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:5007,usability,input,input,5007,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:5045,usability,input,input,5045,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/250:5169,usability,statu,status,5169,"e_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 30884600 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""SRR062634.321"" is 100 bp and IS MISSING, . ""SRR062634.488"" is 100 bp and IS MISSING, . ""SRR062634.849"" is 100 bp and IS MISSING, . ""SRR062634.850"" is 100 bp and IS MISSING, . ""SRR062634.1455"" is 100 bp and IS MISSING, . <...>. ""SRR062634.24476105"" is 100 bp and IS MISSING, . ""SRR062634.24476106"" is 100 bp and IS MISSING, . ""SRR062634.24476107"" is 100 bp and IS MISSING, . ""SRR062634.24476108"" is 100 bp and IS MISSING, . ""SRR062634.24476109"" is 100 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. real	4m17.584s. user	15m16.628s. sys	0m4.274s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/SRR062634.filt.fastq"" --reads ""/input/SRR062634.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. ```. Please tell me what I did wrong.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/250
https://github.com/google/deepvariant/issues/251:2284,availability,error,error,2284,"-train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:43,energy efficiency,current,currently,43,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:85,energy efficiency,model,model,85,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:375,energy efficiency,GPU,GPU,375,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:1402,energy efficiency,model,models,1402,"g homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:1413,energy efficiency,model,model,1413,"s reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2297,energy efficiency,GPU,GPU,2297,"{training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2431,energy efficiency,model,model,2431,"r_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_pat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:3393,energy efficiency,estimat,estimator,3393,"rd stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 0: ./model_training/model.ckpt-0. I1209 06:57:08.678164 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.19607843, 'TNs/Indels': 0.0, 'Recall/Het': 0.0, 'F1/All': 0.39246467, 'FPs/Indels': 164.0, 'Accuracy/SNPs': 0.19634147, 'Recall/Indels': 1.0, 'TNs/SNPs': 0.0, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'Precision/HomRef': 0.24414062, 'F1/Het': 0.0, 'FPs/All': 774.0, 'TPs/All': 250.0, 'TPs/SNPs': 210.0, 'FNs/Indels': 0.0, 'Recall/HomRef': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:3481,energy efficiency,model,model,3481,"ocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 0: ./model_training/model.ckpt-0. I1209 06:57:08.678164 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.19607843, 'TNs/Indels': 0.0, 'Recall/Het': 0.0, 'F1/All': 0.39246467, 'FPs/Indels': 164.0, 'Accuracy/SNPs': 0.19634147, 'Recall/Indels': 1.0, 'TNs/SNPs': 0.0, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'Precision/HomRef': 0.24414062, 'F1/Het': 0.0, 'FPs/All': 774.0, 'TPs/All': 250.0, 'TPs/SNPs': 210.0, 'FNs/Indels': 0.0, 'Recall/HomRef': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:4336,energy efficiency,estimat,estimator,4336,"s = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 0: ./model_training/model.ckpt-0. I1209 06:57:08.678164 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.19607843, 'TNs/Indels': 0.0, 'Recall/Het': 0.0, 'F1/All': 0.39246467, 'FPs/Indels': 164.0, 'Accuracy/SNPs': 0.19634147, 'Recall/Indels': 1.0, 'TNs/SNPs': 0.0, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'Precision/HomRef': 0.24414062, 'F1/Het': 0.0, 'FPs/All': 774.0, 'TPs/All': 250.0, 'TPs/SNPs': 210.0, 'FNs/Indels': 0.0, 'Recall/HomRef': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0, F1/Het = 0.0, F1/HomRef = 0.0, F1/HomVar = 0.0, FNs/All = 434.0, FNs/Indels = 62.0, FNs/SNPs = 372.0, FPs/All = 0.0, FPs/Indels = 0.0, FPs/SNPs = 0.0, Precision/All = 0.0, Precision/Het = 0.0, Precision/HomRef = 0.0, Precision/HomVar = 0.0, Precision/Indels = 0.0, Precision/SNPs = 0.0, Recall/All = 0.0, Recall/Het = 0.0, Recall/HomRef = 0.0, Recall/HomVar = 0.0, Recall/Indels = 0.0, Recall/SNPs = 0.0, TNs/All = 1358.0, TNs/Indels = 279.0, TNs/SNPs = 1079.0, TPs/All = 0.0, TPs/Indels = 0.0, TPs/SNPs = 0.0, global_step = 3123, loss = 0.9064512. I1209 07:22:13.039522 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3123: ./model_training/model.ckpt-3123. I1209 07:22:13.040343 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.0, 'TNs/Indels': 279.0, 'Recall/Het': 0.0, 'F1/All': 0.0, 'FPs/Indels",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:5071,energy efficiency,estimat,estimator,5071,"': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0, F1/Het = 0.0, F1/HomRef = 0.0, F1/HomVar = 0.0, FNs/All = 434.0, FNs/Indels = 62.0, FNs/SNPs = 372.0, FPs/All = 0.0, FPs/Indels = 0.0, FPs/SNPs = 0.0, Precision/All = 0.0, Precision/Het = 0.0, Precision/HomRef = 0.0, Precision/HomVar = 0.0, Precision/Indels = 0.0, Precision/SNPs = 0.0, Recall/All = 0.0, Recall/Het = 0.0, Recall/HomRef = 0.0, Recall/HomVar = 0.0, Recall/Indels = 0.0, Recall/SNPs = 0.0, TNs/All = 1358.0, TNs/Indels = 279.0, TNs/SNPs = 1079.0, TPs/All = 0.0, TPs/Indels = 0.0, TPs/SNPs = 0.0, global_step = 3123, loss = 0.9064512. I1209 07:22:13.039522 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3123: ./model_training/model.ckpt-3123. I1209 07:22:13.040343 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.0, 'TNs/Indels': 279.0, 'Recall/Het': 0.0, 'F1/All': 0.0, 'FPs/Indels': 0.0, 'Accuracy/SNPs': 0.7436251, 'Recall/Indels': 0.0, 'TNs/SNPs': 1079.0, 'global_step': 3123, 'TNs/All': 1358.0, 'FNs/All': 434.0, 'Precision/HomRef': 0.0, 'F1/Het': 0.0, 'FPs/All': 0.0, 'TPs/All': 0.0, 'TPs/SNPs': 0.0, 'FNs/Indels': 62.0, 'Recall/HomRef': 0.0, 'F1/HomVar': 0.0, 'F1/HomRef': 0.0, 'Accuracy/Indels': 0.8181818, 'Precision/Het': 0.0, 'Precision/SNPs': 0.0, 'Recall/All': 0.0, 'Precision/HomVar': 0.0, 'loss': 0.9064512, 'FNs/SNPs': 372.0, 'Recall/HomVar': 0.0, 'TPs/Indels': 0.0, 'Recall/SNPs': 0.0, 'Accuracy/All': 0.7578125, 'FPs/SNPs': 0.0, 'Precision/All': 0.0}. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:5162,energy efficiency,model,model,5162,"': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0, F1/Het = 0.0, F1/HomRef = 0.0, F1/HomVar = 0.0, FNs/All = 434.0, FNs/Indels = 62.0, FNs/SNPs = 372.0, FPs/All = 0.0, FPs/Indels = 0.0, FPs/SNPs = 0.0, Precision/All = 0.0, Precision/Het = 0.0, Precision/HomRef = 0.0, Precision/HomVar = 0.0, Precision/Indels = 0.0, Precision/SNPs = 0.0, Recall/All = 0.0, Recall/Het = 0.0, Recall/HomRef = 0.0, Recall/HomVar = 0.0, Recall/Indels = 0.0, Recall/SNPs = 0.0, TNs/All = 1358.0, TNs/Indels = 279.0, TNs/SNPs = 1079.0, TPs/All = 0.0, TPs/Indels = 0.0, TPs/SNPs = 0.0, global_step = 3123, loss = 0.9064512. I1209 07:22:13.039522 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3123: ./model_training/model.ckpt-3123. I1209 07:22:13.040343 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.0, 'TNs/Indels': 279.0, 'Recall/Het': 0.0, 'F1/All': 0.0, 'FPs/Indels': 0.0, 'Accuracy/SNPs': 0.7436251, 'Recall/Indels': 0.0, 'TNs/SNPs': 1079.0, 'global_step': 3123, 'TNs/All': 1358.0, 'FNs/All': 434.0, 'Precision/HomRef': 0.0, 'F1/Het': 0.0, 'FPs/All': 0.0, 'TPs/All': 0.0, 'TPs/SNPs': 0.0, 'FNs/Indels': 62.0, 'Recall/HomRef': 0.0, 'F1/HomVar': 0.0, 'F1/HomRef': 0.0, 'Accuracy/Indels': 0.8181818, 'Precision/Het': 0.0, 'Precision/SNPs': 0.0, 'Recall/All': 0.0, 'Precision/HomVar': 0.0, 'loss': 0.9064512, 'FNs/SNPs': 372.0, 'Recall/HomVar': 0.0, 'TPs/Indels': 0.0, 'Recall/SNPs': 0.0, 'Accuracy/All': 0.7578125, 'FPs/SNPs': 0.0, 'Precision/All': 0.0}. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2245,integrability,Batch,Batch,2245,"${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:296,performance,time,times,296,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:375,performance,GPU,GPU,375,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:885,performance,time,time,885,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2245,performance,Batch,Batch,2245,"${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2277,performance,memor,memory,2277,"56 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2284,performance,error,error,2284,"-train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2297,performance,GPU,GPU,2297,"{training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2441,performance,perform,performing,2441,"0000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:212,safety,valid,validation,212,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:935,safety,input,inputs,935,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:1572,safety,test,testing,1572," --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2284,safety,error,error,2284,"-train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:85,security,model,model,85,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:212,security,validat,validation,212,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:612,security,access,accession,612,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:667,security,access,accession,667,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:719,security,access,accession,719,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:762,security,access,accession,762,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:1402,security,model,models,1402,"g homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:1413,security,model,model,1413,"s reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2201,security,loss,loss,2201,"nt/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Reca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2431,security,model,model,2431,"r_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_pat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:3338,security,loss,loss,3338,"nce or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 0: ./model_training/model.ckpt-0. I1209 06:57:08.678164 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.19607843, 'TNs/Indels': 0.0, 'Recall/Het': 0.0, 'F1/All': 0.39246467, 'FPs/Indels': 164.0, 'Accuracy/SNPs': 0.19634147, 'Recall/Indels': 1.0, 'TNs/SNPs': 0.0, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'Precision/HomRef': 0.24414062, 'F1/Het': 0.0, 'FPs/All': 774.0, 'TPs/All': 250.0, 'TPs/SNPs': 210.0, 'FNs/Indels': 0.0, 'Recall/HomRef': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:3481,security,model,model,3481,"ocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 0: ./model_training/model.ckpt-0. I1209 06:57:08.678164 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.19607843, 'TNs/Indels': 0.0, 'Recall/Het': 0.0, 'F1/All': 0.39246467, 'FPs/Indels': 164.0, 'Accuracy/SNPs': 0.19634147, 'Recall/Indels': 1.0, 'TNs/SNPs': 0.0, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'Precision/HomRef': 0.24414062, 'F1/Het': 0.0, 'FPs/All': 774.0, 'TPs/All': 250.0, 'TPs/SNPs': 210.0, 'FNs/Indels': 0.0, 'Recall/HomRef': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:4125,security,loss,loss,4125,"t = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 0: ./model_training/model.ckpt-0. I1209 06:57:08.678164 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.19607843, 'TNs/Indels': 0.0, 'Recall/Het': 0.0, 'F1/All': 0.39246467, 'FPs/Indels': 164.0, 'Accuracy/SNPs': 0.19634147, 'Recall/Indels': 1.0, 'TNs/SNPs': 0.0, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'Precision/HomRef': 0.24414062, 'F1/Het': 0.0, 'FPs/All': 774.0, 'TPs/All': 250.0, 'TPs/SNPs': 210.0, 'FNs/Indels': 0.0, 'Recall/HomRef': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0, F1/Het = 0.0, F1/HomRef = 0.0, F1/HomVar = 0.0, FNs/All = 434.0, FNs/Indels = 62.0, FNs/SNPs = 372.0, FPs/All = 0.0, FPs/Indels = 0.0, FPs/SNPs = 0.0, Precision/All = 0.0, Precision/Het = 0.0, Precision/HomRef = 0.0, Precision/HomVar = 0.0, Precision/Indels = 0.0, Precision/SNPs = 0.0, Recall/All = 0.0, Recall/Het = 0.0, Recall/HomRef = 0.0, Recall/HomVar = 0.0, Recall/Indels = 0.0, Recall/SNPs = 0.0, TNs/All = 1358.0, TNs/Indels = 279.0, TNs/SNPs = 1079.0, TPs/All = 0.0, TPs/Indels = 0.0, TPs/SNPs = 0.0, global_step = 3123, loss = 0.9064512. I1209 07:22:13.039522 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:5016,security,loss,loss,5016,"': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0, F1/Het = 0.0, F1/HomRef = 0.0, F1/HomVar = 0.0, FNs/All = 434.0, FNs/Indels = 62.0, FNs/SNPs = 372.0, FPs/All = 0.0, FPs/Indels = 0.0, FPs/SNPs = 0.0, Precision/All = 0.0, Precision/Het = 0.0, Precision/HomRef = 0.0, Precision/HomVar = 0.0, Precision/Indels = 0.0, Precision/SNPs = 0.0, Recall/All = 0.0, Recall/Het = 0.0, Recall/HomRef = 0.0, Recall/HomVar = 0.0, Recall/Indels = 0.0, Recall/SNPs = 0.0, TNs/All = 1358.0, TNs/Indels = 279.0, TNs/SNPs = 1079.0, TPs/All = 0.0, TPs/Indels = 0.0, TPs/SNPs = 0.0, global_step = 3123, loss = 0.9064512. I1209 07:22:13.039522 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3123: ./model_training/model.ckpt-3123. I1209 07:22:13.040343 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.0, 'TNs/Indels': 279.0, 'Recall/Het': 0.0, 'F1/All': 0.0, 'FPs/Indels': 0.0, 'Accuracy/SNPs': 0.7436251, 'Recall/Indels': 0.0, 'TNs/SNPs': 1079.0, 'global_step': 3123, 'TNs/All': 1358.0, 'FNs/All': 434.0, 'Precision/HomRef': 0.0, 'F1/Het': 0.0, 'FPs/All': 0.0, 'TPs/All': 0.0, 'TPs/SNPs': 0.0, 'FNs/Indels': 62.0, 'Recall/HomRef': 0.0, 'F1/HomVar': 0.0, 'F1/HomRef': 0.0, 'Accuracy/Indels': 0.8181818, 'Precision/Het': 0.0, 'Precision/SNPs': 0.0, 'Recall/All': 0.0, 'Precision/HomVar': 0.0, 'loss': 0.9064512, 'FNs/SNPs': 372.0, 'Recall/HomVar': 0.0, 'TPs/Indels': 0.0, 'Recall/SNPs': 0.0, 'Accuracy/All': 0.7578125, 'FPs/SNPs': 0.0, 'Precision/All': 0.0}. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:5162,security,model,model,5162,"': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0, F1/Het = 0.0, F1/HomRef = 0.0, F1/HomVar = 0.0, FNs/All = 434.0, FNs/Indels = 62.0, FNs/SNPs = 372.0, FPs/All = 0.0, FPs/Indels = 0.0, FPs/SNPs = 0.0, Precision/All = 0.0, Precision/Het = 0.0, Precision/HomRef = 0.0, Precision/HomVar = 0.0, Precision/Indels = 0.0, Precision/SNPs = 0.0, Recall/All = 0.0, Recall/Het = 0.0, Recall/HomRef = 0.0, Recall/HomVar = 0.0, Recall/Indels = 0.0, Recall/SNPs = 0.0, TNs/All = 1358.0, TNs/Indels = 279.0, TNs/SNPs = 1079.0, TPs/All = 0.0, TPs/Indels = 0.0, TPs/SNPs = 0.0, global_step = 3123, loss = 0.9064512. I1209 07:22:13.039522 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3123: ./model_training/model.ckpt-3123. I1209 07:22:13.040343 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.0, 'TNs/Indels': 279.0, 'Recall/Het': 0.0, 'F1/All': 0.0, 'FPs/Indels': 0.0, 'Accuracy/SNPs': 0.7436251, 'Recall/Indels': 0.0, 'TNs/SNPs': 1079.0, 'global_step': 3123, 'TNs/All': 1358.0, 'FNs/All': 434.0, 'Precision/HomRef': 0.0, 'F1/Het': 0.0, 'FPs/All': 0.0, 'TPs/All': 0.0, 'TPs/SNPs': 0.0, 'FNs/Indels': 62.0, 'Recall/HomRef': 0.0, 'F1/HomVar': 0.0, 'F1/HomRef': 0.0, 'Accuracy/Indels': 0.8181818, 'Precision/Het': 0.0, 'Precision/SNPs': 0.0, 'Recall/All': 0.0, 'Precision/HomVar': 0.0, 'loss': 0.9064512, 'FNs/SNPs': 372.0, 'Recall/HomVar': 0.0, 'TPs/Indels': 0.0, 'Recall/SNPs': 0.0, 'Accuracy/All': 0.7578125, 'FPs/SNPs': 0.0, 'Precision/All': 0.0}. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:5764,security,loss,loss,5764,"': 1.0, 'F1/HomVar': 0.2947544, 'F1/HomRef': 0.39246467, 'Accuracy/Indels': 0.078431375, 'Precision/Het': 0.0, 'Precision/SNPs': 0.25609756, 'Recall/All': 1.0, 'Precision/HomVar': 0.17285156, 'loss': 1.3173751, 'FNs/SNPs': 0.0, 'Recall/HomVar': 1.0, 'TPs/Indels': 40.0, 'Recall/SNPs': 1.0, 'Accuracy/All': 0.17285156, 'FPs/SNPs': 610.0, 'Precision/All': 0.24414062}. I1209 07:22:13.038631 46912496317632 estimator.py:1979] Saving dict for global step 3123: Accuracy/All = 0.7578125, Accuracy/Indels = 0.8181818, Accuracy/SNPs = 0.7436251, F1/All = 0.0, F1/Het = 0.0, F1/HomRef = 0.0, F1/HomVar = 0.0, FNs/All = 434.0, FNs/Indels = 62.0, FNs/SNPs = 372.0, FPs/All = 0.0, FPs/Indels = 0.0, FPs/SNPs = 0.0, Precision/All = 0.0, Precision/Het = 0.0, Precision/HomRef = 0.0, Precision/HomVar = 0.0, Precision/Indels = 0.0, Precision/SNPs = 0.0, Recall/All = 0.0, Recall/Het = 0.0, Recall/HomRef = 0.0, Recall/HomVar = 0.0, Recall/Indels = 0.0, Recall/SNPs = 0.0, TNs/All = 1358.0, TNs/Indels = 279.0, TNs/SNPs = 1079.0, TPs/All = 0.0, TPs/Indels = 0.0, TPs/SNPs = 0.0, global_step = 3123, loss = 0.9064512. I1209 07:22:13.039522 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3123: ./model_training/model.ckpt-3123. I1209 07:22:13.040343 46912496317632 model_eval.py:251] Eval results: {'Precision/Indels': 0.0, 'TNs/Indels': 279.0, 'Recall/Het': 0.0, 'F1/All': 0.0, 'FPs/Indels': 0.0, 'Accuracy/SNPs': 0.7436251, 'Recall/Indels': 0.0, 'TNs/SNPs': 1079.0, 'global_step': 3123, 'TNs/All': 1358.0, 'FNs/All': 434.0, 'Precision/HomRef': 0.0, 'F1/Het': 0.0, 'FPs/All': 0.0, 'TPs/All': 0.0, 'TPs/SNPs': 0.0, 'FNs/Indels': 62.0, 'Recall/HomRef': 0.0, 'F1/HomVar': 0.0, 'F1/HomRef': 0.0, 'Accuracy/Indels': 0.8181818, 'Precision/Het': 0.0, 'Precision/SNPs': 0.0, 'Recall/All': 0.0, 'Precision/HomVar': 0.0, 'loss': 0.9064512, 'FNs/SNPs': 372.0, 'Recall/HomVar': 0.0, 'TPs/Indels': 0.0, 'Recall/SNPs': 0.0, 'Accuracy/All': 0.7578125, 'FPs/SNPs': 0.0, 'Precision/All': 0.0}. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:1572,testability,test,testing,1572," --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2325,testability,simpl,simply,2325,"e=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:935,usability,input,inputs,935,"Training leads to HomRef calls; Hello, I'm currently attempting to train DV on a non-model organism. I believe I have the training examples being made properly. For ~170 samples, I take 30 out randomly to use as validation and shuffle both sets by splitting into 4096 files, then repeating a few times (shuffling the iterator as well). Training proceeds quickly on the Tesla GPU, but all stats end up being homozygous reference. I can't tell what is going wrong. Here's my make_examples. ```. /opt/deepvariant/bin/make_examples \. --mode=training \. --use_ref_for_cram=true \. --ref=${reference} \. --examples ${accession}.ds0.with_labels.examples \. --sample_name ${accession} \. --reads ${cram} \. --truth_variants=${accession}.vcf.gz \. --confident_regions=${accession}.bed \. --regions CM0XXXXXX.1 \. --write_run_info. ```. Shuffling code is similar to this, but repeated multiple time:. ```. raw_dataset = tf.data.TFRecordDataset(inputs). for raw_record in itershuffle(raw_dataset, 2000):. example = tf.train.Example(). example.ParseFromString(raw_record.numpy()). writer = random.choice(out_fhs). writer.write(example.SerializeToString()). ```. And training code is like this:. ```. /opt/deepvariant/bin/model_train \. --dataset_config_pbtxt=${config_path} \. --batch_size=256 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2277,usability,memor,memory,2277,"56 \. --train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2284,usability,error,error,2284,"-train_dir=${training_dir} \. --model_name=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2325,usability,simpl,simply,2325,"e=""inception_v3"" \. --learning_rate=0.008 \. --start_from_checkpoint=/opt/models/wgs/model.ckpt \. --number_of_steps=50000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/251:2441,usability,perform,performing,2441,"0000 \. --save_interval_secs 300. ```. Here is the run info for just one sample's examples set (only a single chromosome, for testing purposes, from the .run_info.pbtxt file):. ```. labeling_metrics {. n_truth_variant_sites: 3469. n_truth_variant_alleles: 3474. n_candidate_variant_sites: 9778. n_candidate_variant_alleles: 9943. n_non_confident_candidate_variant_sites: 2219. n_true_positive_sites: 3468. n_true_positive_alleles: 3845. n_false_negative_sites: 1. n_false_negative_alleles: 1. n_false_positive_sites: 6309. n_false_positive_alleles: 6469. n_inexact_position_matches: 1. n_exact_position_matches: 3469. n_exact_position_and_allele_matches: 3443. n_exact_position_and_allele_and_genotype_matches: 3443. }. ```. Training runs just fine, with loss starting at ~1.2 and dropping to 0.04. Batch size is relatively small (memory error on the GPU with any larger). Is it simply my patience or is something else going on? I can provide tensorboard stats as well, but taking any model and performing make_examples(calling) -> postprocess results in only refcalls. Thanks, and let me know what other info I can provide. Edit: Here is some of the output from model_eval. ```. Saving dict for global step 0: Accuracy/All = 0.17285156, Accuracy/Indels = 0.078431375, Accuracy/SNPs = 0.19634147, F1/All = 0.39246467, F1/Het = 0.0, F1/HomRef = 0.39246467, F1/HomVar = 0.2947544, FNs/All = 0.0, FNs/Indels = 0.0, FNs/SNPs = 0.0, FPs/All = 774.0, FPs/Indels = 164.0, FPs/SNPs = 610.0, Precision/All = 0.24414062, Precision/Het = 0.0, Precision/HomRef = 0.24414062, Precision/HomVar = 0.17285156, Precision/Indels = 0.19607843, Precision/SNPs = 0.25609756, Recall/All = 1.0, Recall/Het = 0.0, Recall/HomRef = 1.0, Recall/HomVar = 1.0, Recall/Indels = 1.0, Recall/SNPs = 1.0, TNs/All = 0.0, TNs/Indels = 0.0, TNs/SNPs = 0.0, TPs/All = 250.0, TPs/Indels = 40.0, TPs/SNPs = 210.0, global_step = 0, loss = 1.3173751. I1209 06:57:08.677582 46912496317632 estimator.py:2039] Saving 'checkpoint_path' summary f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/251
https://github.com/google/deepvariant/issues/252:3513,availability,state,state,3513,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4231,availability,down,download,4231,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:0,deployability,Instal,Install,0,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:76,deployability,instal,install,76,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:175,deployability,instal,install,175,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:210,deployability,instal,install,210,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:595,deployability,gateway,gateways,595,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1414,deployability,fail,failed,1414,"k.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . Du",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1563,deployability,fail,failed,1563,"ython3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anacond",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2132,deployability,fail,failed,2132,"ript(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in inst",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2281,deployability,fail,failed,2281,"ite-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/cond",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2981,deployability,instal,install,2981,"conda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide addition",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3004,deployability,instal,install,3004,".6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. locatio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3105,deployability,instal,install,3105,"rror: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3131,deployability,instal,install,3131,"led for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3864,deployability,fail,failed,3864,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4013,deployability,fail,failed,4013,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4167,deployability,instal,installed,4167,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4198,deployability,depend,dependencies,4198,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4315,deployability,instal,install,4315,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4380,deployability,instal,install,4380,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:409,energy efficiency,core,core,409,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1083,energy efficiency,core,core,1083,"eepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1303,energy efficiency,core,core,1303,"cent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1888,energy efficiency,core,core,1888,"During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2031,energy efficiency,core,core,2031,"/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/app",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3771,energy efficiency,core,core,3771,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:604,integrability,sub,subprocess,604,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:712,integrability,sub,subprocess,712,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1359,integrability,messag,message,1359,"conda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1669,integrability,messag,messages,1669,"mmand_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_valu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2387,integrability,messag,messages,2387,"rror: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3513,integrability,state,state,3513,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4119,integrability,messag,messages,4119,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4198,integrability,depend,dependencies,4198,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:595,interoperability,gateway,gateways,595,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1359,interoperability,messag,message,1359,"conda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1669,interoperability,messag,messages,1669,"mmand_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_valu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2387,interoperability,messag,messages,2387,"rror: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4119,interoperability,messag,messages,4119,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:394,modifiability,pac,packages,394,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:580,modifiability,pac,packages,580,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1068,modifiability,pac,packages,1068," to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_acti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1288,modifiability,pac,packages,1288,"back (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed scri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1425,modifiability,pac,package,1425,"497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handlin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1873,modifiability,pac,packages,1873," status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applicatio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2016,modifiability,pac,packages,2016,"ions/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2143,modifiability,pac,package,2143,"prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2593,modifiability,pac,packages,2593,"Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2771,modifiability,pac,packages,2771," (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2923,modifiability,pac,packages,2923,"g_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3086,modifiability,pac,packages,3086,". conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3271,modifiability,pac,packages,3271,"on of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3441,modifiability,pac,packages,3441,"xception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3597,modifiability,pac,packages,3597,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3756,modifiability,pac,packages,3756,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3875,modifiability,pac,package,3875,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4198,modifiability,depend,dependencies,4198,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1414,reliability,fail,failed,1414,"k.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . Du",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1563,reliability,fail,failed,1563,"ython3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anacond",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2132,reliability,fail,failed,2132,"ript(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in inst",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2281,reliability,fail,failed,2281,"ite-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/cond",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3864,reliability,fail,failed,3864,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4013,reliability,fail,failed,4013,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:919,safety,except,exception,919,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:938,safety,except,exception,938,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1375,safety,except,exceptions,1375,"ython3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1724,safety,except,exception,1724,"ProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1743,safety,except,exception,1743,"nd '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2444,safety,except,exception,2444,"riant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2463,safety,except,exception,2463,"33d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2608,safety,except,exceptions,2608,"a/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4198,safety,depend,dependencies,4198,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:287,testability,Trace,Traceback,287,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:961,testability,Trace,Traceback,961,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1766,testability,Trace,Traceback,1766," '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2486,testability,Trace,Traceback,2486,"ommand again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in exec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3184,testability,context,context,3184,"d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfull",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3286,testability,plan,plan,3286,"script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but could",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3347,testability,plan,plan,3347,".deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page wher",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4198,testability,depend,dependencies,4198,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:743,usability,Command,Command,743,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:878,usability,statu,status,878,"Install precompiled binaries; Hello,. I'm writing you because I'm trying to install deepvariant, but I'm encountering several difficulties in doing so. I've tried at first to install through anaconda (```conda install -c bioconda deepvariant```), but I alway get the same problem:. ```. Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 497, in run_script. subprocess_call(command_args, env=env, path=dirname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:1490,usability,command,command,1490,"irname(path)). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/gateways/subprocess.py"", line 56, in subprocess_call. output=_format_output(command_str, path, rc, stdout, stderr)). subprocess.CalledProcessError: Command '['/bin/bash', '-x', '/PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh']' returned non-zero exit status 1. . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 327, in _execute_actions. run_script(target_prefix, Dist(pkg_data), 'post-unlink' if is_unlink else 'post-link'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Tracebac",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:2208,usability,command,command,2208,"k'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 513, in run_script. raise LinkError(message). conda.exceptions.LinkError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 281, in execute. pkg_data, actions). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 344, in _execute_actions. reverse_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. . . . During handling of the above exception, another exception occurred:. . Traceback (most recent call last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/expor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:3940,usability,command,command,3940,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4299,usability,guid,guide,4299,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/252:4359,usability,guid,guidelines,4359,"all last):. File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler. return_value = func(*args, **kwargs). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main.py"", line 140, in _main. exit_code = args.func(args, p). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/main_install.py"", line 80, in execute. install(args, parser, 'install'). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/cli/install.py"", line 326, in install. execute_actions(actions, index, verbose=not context.quiet). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/plan.py"", line 828, in execute_actions. execute_instructions(plan, index, verbose). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 247, in execute_instructions. cmd(state, arg). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/instructions.py"", line 108, in UNLINKLINKTRANSACTION_CMD. txn.execute(). File ""/exports/applications/apps/SL7/anaconda/5.0.1/lib/python3.6/site-packages/conda/core/link.py"", line 297, in execute. rollback_excs,. conda.CondaMultiError: post-link script failed for package bioconda::deepvariant-0.9.0-py27h7333d49_0. running your command again with `-v` will provide additional information. location of failed script: /PATH/TO/MY/FOLDER/Andrea/myanaconda/deepvariant/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ```. Hovewer, since conda installed successfully all the dependencies, I've then tried to download the precompiled binaries and use them, but couldn't find a guide on how to install them. Is there a page where to find guidelines on how to install the precompiled deepvariant? If not, is there a way to fix the anaconda environment issue? Thank you in advance,. Andrea .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/252
https://github.com/google/deepvariant/issues/253:839,availability,error,error,839,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:884,availability,error,error,884,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:845,integrability,messag,message,845,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:845,interoperability,messag,message,845,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:745,performance,cach,cache,745,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:839,performance,error,error,839,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:884,performance,error,error,884,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:839,safety,error,error,839,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:884,safety,error,error,884,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:137,usability,tool,tool,137,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:156,usability,command,command,156,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:839,usability,error,error,839,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/253:884,usability,error,error,884,"Redirect output to another program; Is there a way to redirect the DeepVariant output to another program? For example, to any annotation tool. I tried this command:. ```. sudo -S docker run -v ""/home/platon/_0_Диссертация/Exp/seq1/bowtie2/"":""/ref"" -v ""/home/platon/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/trg"" \. > google/deepvariant /opt/deepvariant/bin/run_deepvariant \. > --num_shards=4 --model_type=WGS \. > --ref=/ref/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \. > --reads=/trg/SRR062634.filt_srtd.bam |. > sudo docker run -a stdin -v $HOME/vep_data:/opt/vep/.vep -v ""$HOME/_0_Диссертация/Exp/Рез/новая_папка/SRR062634.filt/"":""/SRR062634_filt"" \. > ensemblorg/ensembl-vep ./vep \. > --tab --quiet --no_stats --offline --cache --dir_cache /opt/vep/.vep/ \. > -o /SRR062634_filt/SRR062634.filt_ann.tsv. ```. Then an error message appears:. `FATAL Flags parsing error: flag --output_vcf=None: Flag --output_vcf must have a value other than None.`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/253
https://github.com/google/deepvariant/issues/254:21,deployability,contain,container,21,"newbie unable to run container ReadRequirements are: min_mapping_quality: 10 min_base_quality: 10 min_base_quality_mode: ENFORCED_BY_CLIENT; Hi . I am a student learning about bioinformatics. I am able to us the docker image to run the quick start data, however, I am not able to run on my data. . I used samtools 1.9 to filter out low quality reads as follows. ```. quality=11. samtools view -bSq ${quality} ""${originalBAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2438,deployability,Fail,Failed,2438,"utput google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2689,deployability,modul,module,2689,"put_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4067,deployability,Fail,Failed,4067,"iant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4318,deployability,modul,module,4318,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:5696,deployability,Fail,Failed,5696,"iant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:5947,deployability,modul,module,5947,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7325,deployability,Fail,Failed,7325,"iant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7576,deployability,modul,module,7576,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:8903,deployability,modul,module,8903,"p/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68el",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9914,energy efficiency,CPU,CPU,9914,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:321,integrability,filter,filter,321,"newbie unable to run container ReadRequirements are: min_mapping_quality: 10 min_base_quality: 10 min_base_quality_mode: ENFORCED_BY_CLIENT; Hi . I am a student learning about bioinformatics. I am able to us the docker image to run the quick start data, however, I am not able to run on my data. . I used samtools 1.9 to filter out low quality reads as follows. ```. quality=11. samtools view -bSq ${quality} ""${originalBAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:435,integrability,filter,filteredBAMFile,435,"newbie unable to run container ReadRequirements are: min_mapping_quality: 10 min_base_quality: 10 min_base_quality_mode: ENFORCED_BY_CLIENT; Hi . I am a student learning about bioinformatics. I am able to us the docker image to run the quick start data, however, I am not able to run on my data. . I used samtools 1.9 to filter out low quality reads as follows. ```. quality=11. samtools view -bSq ${quality} ""${originalBAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:472,integrability,filter,filteredBAMFile,472,"newbie unable to run container ReadRequirements are: min_mapping_quality: 10 min_base_quality: 10 min_base_quality_mode: ENFORCED_BY_CLIENT; Hi . I am a student learning about bioinformatics. I am able to us the docker image to run the quick start data, however, I am not able to run on my data. . I used samtools 1.9 to filter out low quality reads as follows. ```. quality=11. samtools view -bSq ${quality} ""${originalBAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:1887,integrability,buffer,buffer,1887,"up.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9199,integrability,sub,subprocess,9199,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9292,integrability,sub,subprocess,9292,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9373,integrability,sub,subprocess,9373,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9447,integrability,buffer,buffer,9447,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2775,interoperability,platform,platform,2775,"19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Coul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4404,interoperability,platform,platform,4404,".runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Coul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:6033,interoperability,platform,platform,6033,".runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Coul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7662,interoperability,platform,platform,7662,".runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Coul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2689,modifiability,modul,module,2689,"put_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2748,modifiability,pac,packages,2748,"_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4318,modifiability,modul,module,4318,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4377,modifiability,pac,packages,4377,"**kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:5947,modifiability,modul,module,5947,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:6006,modifiability,pac,packages,6006,"**kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7576,modifiability,modul,module,7576,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7635,modifiability,pac,packages,7635,"**kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:8903,modifiability,modul,module,8903,"p/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68el",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:8963,modifiability,pac,packages,8963,"ariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9063,modifiability,pac,packages,9063,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:625,performance,disk,disk,625,"newbie unable to run container ReadRequirements are: min_mapping_quality: 10 min_base_quality: 10 min_base_quality_mode: ENFORCED_BY_CLIENT; Hi . I am a student learning about bioinformatics. I am able to us the docker image to run the quick start data, however, I am not able to run on my data. . I used samtools 1.9 to filter out low quality reads as follows. ```. quality=11. samtools view -bSq ${quality} ""${originalBAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:1853,performance,time,time,1853,". ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:1868,performance,parallel,parallel,1868,"1-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9413,performance,time,time,9413,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9428,performance,parallel,parallel,9428,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9914,performance,CPU,CPU,9914,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2438,reliability,Fail,Failed,2438,"utput google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4067,reliability,Fail,Failed,4067,"iant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:5696,reliability,Fail,Failed,5696,"iant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7325,reliability,Fail,Failed,7325,"iant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:1417,safety,input,input,1417,"BAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2689,safety,modul,module,2689,"put_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4318,safety,modul,module,4318,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:5947,safety,modul,module,5947,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7576,safety,modul,module,7576,"in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:8903,safety,modul,module,8903,"p/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68el",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:2542,testability,Trace,Traceback,2542,"/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:4171,testability,Trace,Traceback,4171,"(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 140612092569344 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:5800,testability,Trace,Traceback,5800,"(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_8pjzb6/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.935748 139746404648704 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:7429,testability,Trace,Traceback,7429,"(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_4dYajH/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. I1219 00:20:56.936666 139723052500736 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:8805,testability,Trace,Traceback,8805,"s.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' retur",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:161,usability,learn,learning,161,"newbie unable to run container ReadRequirements are: min_mapping_quality: 10 min_base_quality: 10 min_base_quality_mode: ENFORCED_BY_CLIENT; Hi . I am a student learning about bioinformatics. I am able to us the docker image to run the quick start data, however, I am not able to run on my data. . I used samtools 1.9 to filter out low quality reads as follows. ```. quality=11. samtools view -bSq ${quality} ""${originalBAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:1417,usability,input,input,1417,"BAMFile}"" > ""${filteredBAMFile}"". samtools index ""${filteredBAMFile}"". ```. Note the output from the docker run script bellow is a little misleading. I copied all the data from an aws s3 buck to the local disk before the run. Also, the data is RNA not DNA. I was asked to ""see if it would just work"". I think maybe we have to change Uracil to look like Thymine. . Any suggestions would be greatly appreciated. Happy Holidays. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:1838,usability,command,command,1838,"ys. Andy. ```. ubuntu@ip-172-31-1-186:~$ cat nohup.out . + BIN_VERSION=0.9.0. + s3Root=/data. + INPUT_DIR=/data/aligned. + OUTPUT_DIR=/data/output. + quality=q11. + ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. + reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. + date +%Y-%m-%d-%H.%M.%S-%Z%n. + dateStamp=2019-12-19-00.20.49-UTC. + output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz. + output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz. + nproc. + num_shards=4. + sudo docker run -v /data/aligned:/input -v /data/output:/output google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --reads=/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam --output_vcf=/data/output/2019-12-19-00.20.49-UTC.vcf.gz --output_gvcf=/data/output/2019-12-19-00.20.49-UTC.g.vcf.gz --num_shards=4. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}. I1219 00:20:56.935748 140093586556672 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_YufZXM/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:8776,usability,user,user,8776,"variant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9221,usability,command,command,9221,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9404,usability,Command,Command,9404,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9828,usability,statu,status,9828,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9838,usability,Command,Command,9838,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/254:9867,usability,statu,status,9867,"with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_FlmiHS/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam. real	0m4.864s. user	0m7.056s. sys	0m2.308s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/data/reference/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna"" --reads ""/data/aligned/84773251_trimmed.AH77TTBBXX_DS-229105_GCCAAT.sorted.rg.final.q11.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 4. Command exited with non-zero status 1. 0.04user 0.03system 0:07.68elapsed 0%CPU (0avgtext+0avgdata 62828maxresident)k. 123448inputs+24outputs (242major+8435minor)pagefaults 0swaps. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/254
https://github.com/google/deepvariant/issues/255:8,availability,error,error,8,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:97,availability,error,error,97,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:330,availability,error,error,330,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:742,deployability,fail,failed,742,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:886,deployability,instal,installed,886,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1000,deployability,fail,failed,1000,"time error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1144,deployability,instal,installed,1144," start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:2154,deployability,modul,module,2154,"your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 168, in from_contigs. contigs). File ""/tmp/Bazel.runfiles_UJ59",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:404,integrability,buffer,buffer,404,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:947,interoperability,standard,standard,947,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1205,interoperability,standard,standard,1205," argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:2240,interoperability,platform,platform,2240,"62234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 168, in from_contigs. contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 125, in __",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:2154,modifiability,modul,module,2154,"your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 168, in from_contigs. contigs). File ""/tmp/Bazel.runfiles_UJ59",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:2213,modifiability,pac,packages,2213,"ale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 168, in from_contigs. contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:8,performance,error,error,8,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:97,performance,error,error,97,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:330,performance,error,error,330,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:370,performance,time,time,370,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:385,performance,parallel,parallel,385,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:742,reliability,fail,failed,742,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1000,reliability,fail,failed,1000,"time error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:8,safety,error,error,8,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:97,safety,error,error,97,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:330,safety,error,error,330,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:469,safety,input,input,469,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:504,safety,input,input,504,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1469,safety,input,input,1469,"ut/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1615,safety,input,inputs,1615,"ord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_option",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1693,safety,input,input,1693,"""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:2154,safety,modul,module,2154,"your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 168, in from_contigs. contigs). File ""/tmp/Bazel.runfiles_UJ59",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:315,testability,context,context,315,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:2007,testability,Trace,Traceback,2007,": warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:3404,testability,Trace,Traceback,3404,"_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 168, in from_contigs. contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 125, in __init__. tree.merge_overlaps(strict=False). TypeError: merge_overlaps() got an unexpected keyword argument 'strict'. real 0m8.948s. user 0m1.033s. sys 0m2.422s. Traceback (most recent call last):. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:8,usability,error,error,8,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:97,usability,error,error,97,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:156,usability,document,document,156,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:330,usability,error,error,330,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:355,usability,command,command,355,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:469,usability,input,input,469,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:504,usability,input,input,504,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:872,usability,support,supported,872,"Runtime error: merge_overlaps() got an unexpected keyword argument 'strict'; I get the following error when running the example provided in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1130,usability,support,supported,1130,"d in the quick start document:. merge_overlaps() got an unexpected keyword argument 'strict'. Any advice as to how I can resolve the issue is greatly appreciated. ```. This is the context of the error. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1469,usability,input,input,1469,"ut/data/hs37d5.fa.gz"" --reads ""/input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1615,usability,input,inputs,1615,"ord@1.gz"" `--gvcf` ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_option",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:1693,usability,input,input,1693,"""20"" --task {}. perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. LANGUAGE = (unset),. LC_ALL = (unset),. LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). I1220 08:40:22.262234 46912496321664 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1220 08:40:22.268675 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/255:3375,usability,user,user,3375,"_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.272100 46912496321664 make_examples.py:1324] Preparing inputs. I1220 08:40:22.280786 46912496321664 genomics_reader.py:223] Reading /input/data/HG002_NIST_150bp_chr20_downsampled_30x.bam with NativeSamReader. I1220 08:40:22.292714 46912496321664 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1250, in processing_regions_from_options. options.exclude_calling_regions). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 168, in from_contigs. contigs). File ""/tmp/Bazel.runfiles_UJ59Z1/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 125, in __init__. tree.merge_overlaps(strict=False). TypeError: merge_overlaps() got an unexpected keyword argument 'strict'. real 0m8.948s. user 0m1.033s. sys 0m2.422s. Traceback (most recent call last):. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/255
https://github.com/google/deepvariant/issues/256:128,deployability,releas,release,128,"What's the difference between VCF_caller and very_sensitive_caller?; The very_sensitive_caller seems to be a new feature in the release 0.9.0, what's the difference between the very sensitive caller and the usual one?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/256
https://github.com/google/deepvariant/issues/257:194,testability,understand,understanding,194,"Deepvariant on a diploid asexual?; Hello, . out of curiosity, I wondered if any of you had tried out deepvariant in an asexual diploid organism. I know some people have tried it on bacteria. My understanding is that deepvariant will technically work, i.e produce a vcf. The biological relevance of the calls might not be guaranteed (but anyway that would be true for any methods). I will compare it with GATK and probably Octopus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/257
https://github.com/google/deepvariant/issues/258:0,reliability,Doe,Does,0,"Does deepvariant support python3?; Hi! According to [README.md](https://github.com/google/deepvariant/blob/r0.9/README.md) deepvariant is still using python 2.7, is it true? I'm questioning because support of python2 officially stopped January 1 2020.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/258
https://github.com/google/deepvariant/issues/258:17,usability,support,support,17,"Does deepvariant support python3?; Hi! According to [README.md](https://github.com/google/deepvariant/blob/r0.9/README.md) deepvariant is still using python 2.7, is it true? I'm questioning because support of python2 officially stopped January 1 2020.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/258
https://github.com/google/deepvariant/issues/258:198,usability,support,support,198,"Does deepvariant support python3?; Hi! According to [README.md](https://github.com/google/deepvariant/blob/r0.9/README.md) deepvariant is still using python 2.7, is it true? I'm questioning because support of python2 officially stopped January 1 2020.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/258
https://github.com/google/deepvariant/issues/258:228,usability,stop,stopped,228,"Does deepvariant support python3?; Hi! According to [README.md](https://github.com/google/deepvariant/blob/r0.9/README.md) deepvariant is still using python 2.7, is it true? I'm questioning because support of python2 officially stopped January 1 2020.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/258
https://github.com/google/deepvariant/issues/259:6,deployability,version,version,6,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:76,deployability,version,version,76,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:117,deployability,updat,update,117,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:6,integrability,version,version,6,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:76,integrability,version,version,76,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:6,modifiability,version,version,6,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:76,modifiability,version,version,76,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:117,safety,updat,update,117,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/259:117,security,updat,update,117,bazel version 0.21.0 --> 2.0.0; Hello! Should deepvariant work with a newer version of `bazel`? It would be great to update it from `0.21.0` to fresh `2.0.0`:. https://github.com/google/deepvariant/blob/master/settings.sh#L42,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/259
https://github.com/google/deepvariant/issues/260:46,deployability,resourc,resources,46,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:153,deployability,version,version,153,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:749,deployability,resourc,resources,749,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:971,deployability,log,log,971,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:16,energy efficiency,estimat,estimate,16,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:46,energy efficiency,resourc,resources,46,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:582,energy efficiency,cpu,cpu,582,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:663,energy efficiency,estimat,estimate,663,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:749,energy efficiency,resourc,resources,749,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:879,energy efficiency,CPU,CPU,879,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1332,energy efficiency,cpu,cpu,1332,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:153,integrability,version,version,153,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:370,integrability,batch,batch,370,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:434,integrability,batch,batch,434,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:828,integrability,coupl,couple,828,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:975,integrability,messag,message,975,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1000,integrability,Event,Eventually,1000,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:975,interoperability,messag,message,975,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:153,modifiability,version,version,153,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:828,modifiability,coupl,couple,828,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:29,performance,time,time,29,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:38,performance,compute resourc,compute resources,38,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:370,performance,batch,batch,370,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:434,performance,batch,batch,434,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:582,performance,cpu,cpu,582,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:622,performance,memor,memory,622,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:633,performance,disk,disk,633,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:689,performance,time,time,689,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:741,performance,compute resourc,compute resources,741,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:879,performance,CPU,CPU,879,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:994,performance,time,time,994,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1112,performance,time,time,1112,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1332,performance,cpu,cpu,1332,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:109,reliability,pra,practices,109,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:46,safety,resourc,resources,46,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:749,safety,resourc,resources,749,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:971,safety,log,log,971,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1023,safety,compl,completed,1023,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1149,safety,compl,completions,1149,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:274,security,control,control,274,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:971,security,log,log,971,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1023,security,compl,completed,1023,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:1149,security,compl,completions,1149,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:46,testability,resourc,resources,46,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:274,testability,control,control,274,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:749,testability,resourc,resources,749,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:828,testability,coupl,couple,828,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:971,testability,log,log,971,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:622,usability,memor,memory,622,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/260:797,usability,progress,progress,797,"any idea how to estimate run time and compute resources required; Hi . I am a Newbie/Student with some ""best practices"" questions. I am using the docker version 0.9.0 and following the script in the quick start example. I have two data sets of Illumina reads one was from a control group, the other from a treatment group. I think the number of reads is comparable. One batch has been generating examples for over 3.5 days. The other batch is running on 32 vCPU machine. It is still generating images after 1.5 days. I checked the OS level stats, the machines are not swapping. all cpu's are at 100%. Still alot of unused memory and disk. 1) Any idea how I might estimate the expected run time? . 2) Any idea of how I do a better job sizing compute resources? 3) How do I know if docker is making progress or not? I did a run a couple of weeks ago. I think it took a total of 66 CPU hrs. It seemed like after all the examples where constructed the docker did not produce log message for a long time. Eventually, the docker completed. The results were really good! 4) I run on ubuntu and use nohub. I want to run time, my script, report 'data up' on completions. I always put nohub job in the background. It seems like after examples have been constructed I will not see my nohub in the jobs list, however, if I use top I see all my cpu's are running python and are at 100%. Is there a better way to run my script. thanks. Andy. p.s. I am running in AWS . not sure if that makes a difference or not. p.p.s. Is there a better place to ask questions like this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/260
https://github.com/google/deepvariant/issues/261:281,usability,experien,experience,281,"Any recommendation on normalization?; Hello,. For comparing call on different samples made with Deepvariant, is vcf normalization required? There seems to be many opinions on that question ... and the answer seems to vary also if you want to use the vcf OR the gvcf. . So, in your experience, what would be recommended with DeepVariant? . Bcftools norm with the fasta reference to provide a left-aligned and parsimonious representation? . would this also be needed for the gvcf? . Thank you :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/261
https://github.com/google/deepvariant/issues/262:0,availability,Error,Error,0,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:130,availability,error,error,130,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:221,availability,Error,Error,221,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:74,deployability,contain,containers,74,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:212,energy efficiency,current,current,212,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:342,energy efficiency,current,current,342,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:295,interoperability,specif,specification,295,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:0,performance,Error,Error,0,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:130,performance,error,error,130,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:221,performance,Error,Error,221,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:0,safety,Error,Error,0,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:25,safety,test,test,25,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:130,safety,error,error,130,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:168,safety,test,test,168,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:221,safety,Error,Error,221,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:272,safety,input,input,272,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:313,safety,input,input,313,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:25,testability,test,test,25,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:168,testability,test,test,168,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:0,usability,Error,Error,0,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:30,usability,command,command,30,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:57,usability,experien,experience,57,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:130,usability,error,error,130,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:185,usability,command,command,185,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:221,usability,Error,Error,221,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:272,usability,input,input,272,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:313,usability,input,input,313,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/262:356,usability,help,help,356,"Error running quickstart test command; I don't have much experience using containers so it's difficult for me to troubleshoot the error I'm getting back when I run the test DeepVariant command:. `/usr/bin/docker-current: Error response from daemon: invalid volume spec "":/input"": invalid volume specification: ':/input'. See '/usr/bin/docker-current run --help'`. As it might be relevant, the OS i'm using is CentOS Linux 7. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/262
https://github.com/google/deepvariant/issues/263:13,availability,error,error,13,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:184,availability,error,error,184,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:300,availability,ERROR,ERROR,300,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:0,deployability,Instal,Installation,0,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:118,deployability,instal,install,118,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:195,deployability,instal,installing,195,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:274,deployability,instal,install,274,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:827,deployability,instal,installed,827,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:114,energy efficiency,CPU,CPU,114,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:874,energy efficiency,GPU,GPU,874,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:901,energy efficiency,CPU,CPU,901,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:149,modifiability,pac,package,149,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:211,modifiability,pac,package,211,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:705,modifiability,variab,variable,705,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:847,modifiability,variab,variable,847,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:13,performance,error,error,13,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:114,performance,CPU,CPU,114,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:184,performance,error,error,184,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:300,performance,ERROR,ERROR,300,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:874,performance,GPU,GPU,874,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:901,performance,CPU,CPU,901,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:13,safety,error,error,13,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:184,safety,error,error,184,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:300,safety,ERROR,ERROR,300,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:937,security,Team,Team,937,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:13,usability,error,error,13,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:184,usability,error,error,184,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/issues/263:300,usability,ERROR,ERROR,300,"Installation error with intel-tensorflow; Hi all,. The DeepVariant case study scripts for running via binaries on CPU install the `intel-tensorflow` package. We have noticed the below error when installing this package and are looking into how this can be fixed. ```. $ pip install intel-tensorflow. ERROR: intel-tensorflow has an invalid wheel, multiple .dist-info directories found: intel_tensorflow-2.0.0.dist-info, tensorflow-2.0.0.dist-info. ```. If you run into this issue, we recommend one of the following options in the meantime:. * Use the Docker scripts instead of the binaries scripts. * Set the [`DV_USE_GCP_OPTIMIZED_TF_WHL`](https://github.com/google/deepvariant/blob/r0.9/settings.sh#L90) variable to 0 prior to setting up DeepVariant and running the case study scripts for binaries. `intel-tensorflow` is only installed when this variable is set. * Use the GPU scripts instead of the CPU scripts. Best,. The DeepVariant Team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/263
https://github.com/google/deepvariant/pull/264:0,deployability,Instal,Install,0,Install intel-tensorflow with custom wheel.; This is a pull request from the DeepVariant team to fix the issue described in https://github.com/google/deepvariant/issues/263 for the v0.9 branch.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/264
https://github.com/google/deepvariant/pull/264:89,security,team,team,89,Install intel-tensorflow with custom wheel.; This is a pull request from the DeepVariant team to fix the issue described in https://github.com/google/deepvariant/issues/263 for the v0.9 branch.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/264
https://github.com/google/deepvariant/pull/264:30,usability,custom,custom,30,Install intel-tensorflow with custom wheel.; This is a pull request from the DeepVariant team to fix the issue described in https://github.com/google/deepvariant/issues/263 for the v0.9 branch.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/264
https://github.com/google/deepvariant/issues/265:141,availability,cluster,cluster,141,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:213,availability,error,errors,213,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:141,deployability,cluster,cluster,141,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1171,deployability,log,login,1171,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1444,deployability,modul,module,1444,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1492,deployability,modul,module,1492,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1566,deployability,fail,failed,1566,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1614,deployability,fail,failed,1614,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1712,deployability,fail,failed,1712,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1157,energy efficiency,Power,Power,1157,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1543,energy efficiency,core,core,1543,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1603,energy efficiency,core,core,1603,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1684,energy efficiency,core,core,1684,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:528,integrability,buffer,buffer,528,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1081,integrability,pub,publication,1081,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1444,modifiability,modul,module,1444,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1492,modifiability,modul,module,1492,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:213,performance,error,errors,213,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:494,performance,time,time,494,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:509,performance,parallel,parallel,509,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1052,performance,Parallel,Parallel,1052,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1129,performance,Parallel,Parallel,1129,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1343,performance,Parallel,Parallel,1343,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1406,performance,parallel,parallel,1406,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1566,reliability,fail,failed,1566,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1614,reliability,fail,failed,1614,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1712,reliability,fail,failed,1712,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:114,safety,test,tested,114,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:156,safety,test,test,156,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:213,safety,error,errors,213,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:614,safety,test,test,614,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:636,safety,test,testdata,636,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:708,safety,test,test,708,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:730,safety,test,testdata,730,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1171,safety,log,login,1171,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1444,safety,modul,module,1444,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1492,safety,modul,module,1492,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1144,security,Command-Lin,Command-Line,1144,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1171,security,log,login,1171,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:114,testability,test,tested,114,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:156,testability,test,test,156,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:614,testability,test,test,614,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:636,testability,test,testdata,636,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:661,testability,unit,unittest,661,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:708,testability,test,test,708,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:730,testability,test,testdata,730,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1171,testability,log,login,1171,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:213,usability,error,errors,213,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:358,usability,help,help,358,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:432,usability,close,closed,432,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:479,usability,command,command,479,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1144,usability,Command,Command-Line,1144,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1163,usability,Tool,Tool,1163,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1225,usability,help,helps,1225,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/265:1772,usability,user,user,1772,"DeepVariant with Singularity image: ImportErrors; Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! (I realized posting in a new issue made more sense than adding to a closed issue). . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```. _Originally posted by @ksw9 in https://github.com/google/deepvariant/issues/243#issuecomment-579406829_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/265
https://github.com/google/deepvariant/issues/266:555,performance,content,content,555,"DeepVariant calling homozygote at obvious heterozygote sites; Hello, . the following sites are all called with high confidence (GQ >=20) to be RefCall. ![RefCall](https://user-images.githubusercontent.com/23341393/73534867-8211c180-4422-11ea-9521-162cfbe215d2.png). However, they seem rather obviously to be het sites, the VAF is 0.5. . But, they are all close to each other and on the same reads actually ... Is this the reason, would deepvariant regard those as ""too close""? My genome is much smaller than the human genome and has a very low repetitive content (~3%). .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/266
https://github.com/google/deepvariant/issues/266:171,usability,user,user-images,171,"DeepVariant calling homozygote at obvious heterozygote sites; Hello, . the following sites are all called with high confidence (GQ >=20) to be RefCall. ![RefCall](https://user-images.githubusercontent.com/23341393/73534867-8211c180-4422-11ea-9521-162cfbe215d2.png). However, they seem rather obviously to be het sites, the VAF is 0.5. . But, they are all close to each other and on the same reads actually ... Is this the reason, would deepvariant regard those as ""too close""? My genome is much smaller than the human genome and has a very low repetitive content (~3%). .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/266
https://github.com/google/deepvariant/issues/266:355,usability,close,close,355,"DeepVariant calling homozygote at obvious heterozygote sites; Hello, . the following sites are all called with high confidence (GQ >=20) to be RefCall. ![RefCall](https://user-images.githubusercontent.com/23341393/73534867-8211c180-4422-11ea-9521-162cfbe215d2.png). However, they seem rather obviously to be het sites, the VAF is 0.5. . But, they are all close to each other and on the same reads actually ... Is this the reason, would deepvariant regard those as ""too close""? My genome is much smaller than the human genome and has a very low repetitive content (~3%). .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/266
https://github.com/google/deepvariant/issues/266:469,usability,close,close,469,"DeepVariant calling homozygote at obvious heterozygote sites; Hello, . the following sites are all called with high confidence (GQ >=20) to be RefCall. ![RefCall](https://user-images.githubusercontent.com/23341393/73534867-8211c180-4422-11ea-9521-162cfbe215d2.png). However, they seem rather obviously to be het sites, the VAF is 0.5. . But, they are all close to each other and on the same reads actually ... Is this the reason, would deepvariant regard those as ""too close""? My genome is much smaller than the human genome and has a very low repetitive content (~3%). .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/266
https://github.com/google/deepvariant/issues/267:9,usability,tool,tool,9,"Plotting tool not working properly; Hello, I tried the plotting tool of DeepVariant on the vcf produced by the Octopus caller. ![ARCcestor octopus visual_report](https://user-images.githubusercontent.com/23341393/73610464-c8f4e800-45d7-11ea-834a-78603d414f80.png). As you see many plots are empty. Well, it's not critical as of course I can redo these plots but I thought you might like to know. . Cheers. EDIT: is it because octopus produces phased genotypes?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/267
https://github.com/google/deepvariant/issues/267:64,usability,tool,tool,64,"Plotting tool not working properly; Hello, I tried the plotting tool of DeepVariant on the vcf produced by the Octopus caller. ![ARCcestor octopus visual_report](https://user-images.githubusercontent.com/23341393/73610464-c8f4e800-45d7-11ea-834a-78603d414f80.png). As you see many plots are empty. Well, it's not critical as of course I can redo these plots but I thought you might like to know. . Cheers. EDIT: is it because octopus produces phased genotypes?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/267
https://github.com/google/deepvariant/issues/267:170,usability,user,user-images,170,"Plotting tool not working properly; Hello, I tried the plotting tool of DeepVariant on the vcf produced by the Octopus caller. ![ARCcestor octopus visual_report](https://user-images.githubusercontent.com/23341393/73610464-c8f4e800-45d7-11ea-834a-78603d414f80.png). As you see many plots are empty. Well, it's not critical as of course I can redo these plots but I thought you might like to know. . Cheers. EDIT: is it because octopus produces phased genotypes?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/267
https://github.com/google/deepvariant/issues/268:516,availability,Restor,Restoring,516,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:21,energy efficiency,model,model,21,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:116,energy efficiency,model,model,116,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:286,energy efficiency,model,model,286,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:364,energy efficiency,model,model,364,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:547,energy efficiency,model,models,547,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:558,energy efficiency,model,model,558,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:635,energy efficiency,model,model,635,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:691,energy efficiency,model,model,691,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:738,energy efficiency,model,model-type,738,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:859,energy efficiency,model,model,859,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:1066,energy efficiency,model,model,1066,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:1126,energy efficiency,schedul,schedule,1126,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:1025,integrability,messag,messages,1025,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:1025,interoperability,messag,messages,1025,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:259,modifiability,PAC,PACBIO,259,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:526,modifiability,paramet,parameters,526,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:1126,performance,schedul,schedule,1126,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:516,reliability,Restor,Restoring,516,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:706,reliability,doe,doesn,706,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:7,safety,input,input,7,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:21,security,model,model,21,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:116,security,model,model,116,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:286,security,model,model,286,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:364,security,model,model,364,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:547,security,model,models,547,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:558,security,model,model,558,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:635,security,model,model,635,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:691,security,model,model,691,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:738,security,model,model-type,738,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:859,security,model,model,859,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:1066,security,model,model,1066,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:7,usability,input,input,7,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:127,usability,help,help,127,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:680,usability,custom,customized-model,680,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:904,usability,behavi,behaviour,904,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/268:982,usability,help,help,982,"How to input another model with v0.9; Hello guys,. following an email discussion ... I am unable to use a different model. The help seems to suggest one can set --model_type=WGS and then use --customized_model=""PATH_to_model.cpk"". ```. --model_type: <WGS|WES|PACBIO>: Required. Type of model to use for variant . calling. Each model_type has an associated default model, which can be . overridden by the --customized_model flag. ```. But then the run produces. `""I0206 11:58:24.997612 140003716306688 saver.py:1270] Restoring parameters from /opt/models/wgs/model.ckpt"". `. which I interpret as deepvariant falling back on its default model. . What I notice is that even with the customized-model flag, it doesn't run if I don't set up --model-type. It seems like when both flags are set (and there is no way to do otherwise) it gives priority to its default model, which is the opposite of the intended behaviour right? . Or is there something I am missing? . Thanks a lot for any help or suggestion (and sorry for the many messages, I just really want to try that model because it seems very promising and have it fit in my schedule)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/268
https://github.com/google/deepvariant/issues/269:285,availability,avail,available,285,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2800,availability,checkpoint,checkpoint,2800,"c/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3227,availability,Restor,Restoring,3227,"les.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3581,availability,Restor,Restoring,3581,"* Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search fo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4164,availability,avail,avail,4164,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:327,deployability,log,log,327,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:778,deployability,contain,containers,778,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:835,deployability,log,log,835,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3077,deployability,version,version,3077,"9:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3103,deployability,updat,updating,3103,"8 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3132,deployability,API,APIs,3132,"sk 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3814,deployability,resourc,resources,3814,"dels/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:5150,deployability,log,log,5150,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:224,energy efficiency,cpu,cpu,224,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:505,energy efficiency,model,models,505,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:546,energy efficiency,predict,predictions,546,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2564,energy efficiency,predict,predictions,2564,"reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 save",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2817,energy efficiency,model,models,2817,".5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resour",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2828,energy efficiency,model,model,2828,"tar.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3258,energy efficiency,model,models,3258,"didates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3269,energy efficiency,model,model,3269,"1 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3494,energy efficiency,model,modeling,3494,"er	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3612,energy efficiency,model,models,3612,"time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ``",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3623,energy efficiency,model,model,3623,"eepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3814,energy efficiency,resourc,resources,3814,"dels/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3870,energy efficiency,load,load,3870,"s not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3970,energy efficiency,Cpu,Cpu,3970,"ts (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4207,energy efficiency,CPU,CPU,4207,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3077,integrability,version,version,3077,"9:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3132,integrability,API,APIs,3132,"sk 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3721,integrability,batch,batches,3721,"z"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3118,interoperability,standard,standard,3118,".py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. Ki",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3132,interoperability,API,APIs,3132,"sk 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:1548,modifiability,deco,decode,1548,"ctions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2906,modifiability,pac,packages,2906,"755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3077,modifiability,version,version,3077,"9:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3237,modifiability,paramet,parameters,3237,"3] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3591,modifiability,paramet,parameters,3591,"the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:224,performance,cpu,cpu,224,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:295,performance,memor,memory,295,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:377,performance,time,times,377,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:525,performance,time,time,525,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2615,performance,time,time,2615,"03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3721,performance,batch,batches,3721,"z"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3806,performance,compute resourc,compute resources,3806,"t/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3870,performance,load,load,3870,"s not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3970,performance,Cpu,Cpu,3970,"ts (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4113,performance,cach,cache,4113,"e standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are se",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4207,performance,CPU,CPU,4207,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4216,performance,TIME,TIME,4216,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:285,reliability,availab,available,285,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2800,reliability,checkpoint,checkpoint,2800,"c/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3227,reliability,Restor,Restoring,3227,"les.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3581,reliability,Restor,Restoring,3581,"* Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search fo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:285,safety,avail,available,285,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:327,safety,log,log,327,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:546,safety,predict,predictions,546,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:835,safety,log,log,835,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:961,safety,input,input,961,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:1067,safety,compl,completed,1067,"uick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:1523,safety,input,input,1523,"ime, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2564,safety,predict,predictions,2564,"reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 save",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3103,safety,updat,updating,3103,"8 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3814,safety,resourc,resources,3814,"dels/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4164,safety,avail,avail,4164,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:5150,safety,log,log,5150,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:285,security,availab,available,285,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:327,security,log,log,327,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:505,security,model,models,505,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:835,security,log,log,835,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:1067,security,compl,completed,1067,"uick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2817,security,model,models,2817,".5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resour",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2828,security,model,model,2828,"tar.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3103,security,updat,updating,3103,"8 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3258,security,model,models,3258,"didates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3269,security,model,model,3269,"1 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3494,security,model,modeling,3494,"er	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3612,security,model,models,3612,"time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ``",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3623,security,model,model,3623,"eepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4597,security,modif,modified,4597,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:5150,security,log,log,5150,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:327,testability,log,log,327,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:835,testability,log,log,835,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3814,testability,resourc,resources,3814,"dels/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:5150,testability,log,log,5150,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:40,usability,progress,progress,40,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:295,usability,memor,memory,295,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:485,usability,experien,experience,485,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:859,usability,tip,tips,859,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:961,usability,input,input,961,"how can I tell if DeepVariant is making progress?; Hi . I am using the quick start docker image. I think all the examples have been created at this point. When it first started creating examples top showed that all 64 of my cpu's where at 100% utilization, and there was still lots of available memory. I have not seen any new log files in over a day. I have check top several times over the last 2 days. It only shows 2 python processes and each of them is at 800% utilization. In my experience training models takes a long time, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:1523,usability,input,input,1523,"ime, however making predictions is quick. Should I kill my job and try and start over again? I ran into a problem like this before on a much smaller machine. After 11 days I killed the jobs. I do not know much about docker. I looked in /var/lib/docker/containers. I did not find anything that looked a like a log file. any debugging tips would be appreciated. Andy. config . ```. google/deepvariant:0.9.0. --model_type=WES. --regions=/input/agilent_sureselect_human_all_exon_v5_b37_targets.bed. --num_shards=64. ```. Looks like make_example completed. ```. I0208 03:49:00.939260 140440947410688 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz. I0208 03:49:00.940793 140440947410688 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00063-of-00064.gz. I0208 03:49:01.427521 140440947410688 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2496,usability,user,user,2496,"e. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 mode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:2600,usability,command,command,2600,". 2020-02-08 03:49:01.428281: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0208 03:49:01.743115 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:01.755232 140440947410688 genomics_reader.py:223] Reading /kimLab/kras.ipsc/bulk.data/day.5/ctrl.1/star.out/pass.2/Aligned.out.q11.sorted.bam with NativeSamReader. I0208 03:49:02.136116 140440947410688 make_examples.py:1363] Task 63: 0 candidates (0 examples) [1.19s elapsed]. I0208 06:50:01.437930 140440947410688 make_examples.py:1363] Task 63: 101 candidates (101 examples) [10859.30s elapsed]. I0208 07:30:38.055526 140440947410688 make_examples.py:1380] Found 176 candidate variants. I0208 07:30:38.056374 140440947410688 make_examples.py:1381] Created 178 examples. real	346m1.860s. user	7558m17.436s. sys	11m12.192s. ```. looks like it starts making predictions. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". ```. the tail of my noup.out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3864,usability,user,user,3864,"out has not changed in over a day. ```. packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:3950,usability,stop,stopped,3950,"6: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4180,usability,USER,USER,4180,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/269:4222,usability,COMMAND,COMMAND,4222,"h this prefix. I0208 09:29:54.405941 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:55.469674 139859027293952 session_manager.py:491] Running local_init_op. I0208 09:29:55.510524 139859027293952 session_manager.py:493] Done running local_init_op. I0208 09:29:55.864006 139859027293952 modeling.py:410] Reloading EMA... I0208 09:29:55.864634 139859027293952 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I0208 09:29:59.699455 139859027293952 call_variants.py:399] Processed 1 examples in 1 batches [827.229 sec per 100]. ```. top. Looks like there is a lot of under utilized compute resources. ```. top - 00:16:22 up 1 day, 23:24, 1 user, load average: 16.03, 16.02, 16.00. Tasks: 621 total, 1 running, 620 sleeping, 0 stopped, 0 zombie. %Cpu(s): 25.0 us, 0.0 sy, 0.0 ni, 75.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st. KiB Mem : 52262400+total, 48358937+free, 8878616 used, 30156016 buff/cache. KiB Swap: 0 total, 0 free, 0 used. 51216832+avail Mem . PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND . 23437 root 20 0 27.319g 3.709g 136440 S 800.0 0.7 18646:29 python . 23944 root 20 0 27.259g 3.687g 137396 S 799.7 0.7 18613:17 python . 1 root 20 0 119604 5788 4112 S 0.0 0.0 0:03.37 systemd . 2 root 20 0 0 0 0 S 0.0 0.0 0:00.01 kthreadd . 3 root 20 0 0 0 0 S 0.0 0.0 0:00.06 ksoftirqd/0 . 4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0 . ```. search for recently modified files. ```. ubuntu@ip-172-31-21-181:/deepTmp$ sudo find . -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -f2- -d"" "". ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ ls -l ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. -rw-r--r-- 1 root 0 Feb 8 09:29 ./deepvariant_tmp_output/call_variants_output.tfrecord.gz. ubuntu@ip-172-31-21-181:/deepTmp$ date. Mon Feb 10 00:22:46 UTC 2020. ubuntu@ip-172-31-21-181:/deepTmp$ . ```. I also noticed there are several deprecation warnings in the log file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/269
https://github.com/google/deepvariant/issues/270:99,availability,error,error,99,"Analysis from fasta file; Hello,. I've been trying to run deepvariant, but I keep getting the same error:. d not read base quality scores. 2020-02-10 20:52:23.436669: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/0_2762: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436770: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/22518_26356: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436874: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/2839_6783: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437269: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/14677_18575: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437378: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base qual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2168,deployability,fail,failed,2168,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2796,interoperability,coordinat,coordinate,2796,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2922,interoperability,format,format,2922,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2238,modifiability,pac,packages,2238,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2621,modifiability,pac,pacbio,2621,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:99,performance,error,error,99,"Analysis from fasta file; Hello,. I've been trying to run deepvariant, but I keep getting the same error:. d not read base quality scores. 2020-02-10 20:52:23.436669: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/0_2762: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436770: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/22518_26356: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436874: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/2839_6783: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437269: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/14677_18575: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437378: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base qual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2168,reliability,fail,failed,2168,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:99,safety,error,error,99,"Analysis from fasta file; Hello,. I've been trying to run deepvariant, but I keep getting the same error:. d not read base quality scores. 2020-02-10 20:52:23.436669: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/0_2762: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436770: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/22518_26356: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436874: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/2839_6783: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437269: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/14677_18575: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437378: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base qual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2261,safety,test,test,2261,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2288,safety,test,testing,2288,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2726,safety,INPUT,INPUT,2726,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2261,testability,test,test,2261,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2288,testability,test,testing,2288,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:99,usability,error,error,99,"Analysis from fasta file; Hello,. I've been trying to run deepvariant, but I keep getting the same error:. d not read base quality scores. 2020-02-10 20:52:23.436669: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/0_2762: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436770: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/22518_26356: Not found: Could not read base quality scores. 2020-02-10 20:52:23.436874: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/2839_6783: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437269: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/14677_18575: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437378: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base qual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/270:2726,usability,INPUT,INPUT,2726,"m54191_180528_182730/29557366/26432_30218: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437453: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/34281_36602: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437552: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/6879_10765: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437662: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/30289_34208: Not found: Could not read base quality scores. 2020-02-10 20:52:23.437766: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29557366/18650_22440: Not found: Could not read base quality scores. 2020-02-10 20:52:23.438311: W third_party/nucleus/io/sam_reader.cc:474] Could not read base quality scores m54191_180528_182730/29163785/119_9105: Not found: Could not read base quality scores. 2020-02-10 20:52:23.440373: F deepvariant/allelecounter.cc:103] Check failed: offset + len <= read.aligned_quality_size() (4265 vs. 0). The packages work with the test Illumina files. After testing several options, I notice what I got as raw data is either the bam file (without quality scores, only ""!"") or a fasta files. However, it seems that using those reads during the mapping wuth BWA (or with pbmm2) produces bam files without mapping scores which seems to be the problem. . This is how I mapped reads:. bwa mem -x pacbio -t 8 -R $ReadGroup $1 $2 | java -jar /sw/apps/bioinfo/picard/2.20.4/rackham/picard.jar SortSam \. INPUT=/dev/stdin \. OUTPUT=""$sample.bwa.picardSort.bam"" \. SORT_ORDER=coordinate. I feel this is a very basic question, but it is actually possible to run DeepVariant maping PB reads but in fasta format? Am I missing somthing to get the mapping scores in the bam file? Thanks a lot,. Cheers,. /Sergio.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/270
https://github.com/google/deepvariant/issues/271:214,usability,clear,clearly,214,"threads per shard; Hello,. It seems that 1 shard = 1 thread, however at some point in its run it seems that DeepVariant takes more threads N_SHARD is set to 20, no one else is using the computer at this moment and clearly more than 20 threads are taken. ![higdpgpplenjbaao](https://user-images.githubusercontent.com/23341393/74519762-a12a4c00-4f16-11ea-986c-b785044a618b.png). Is it expected?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/271
https://github.com/google/deepvariant/issues/271:282,usability,user,user-images,282,"threads per shard; Hello,. It seems that 1 shard = 1 thread, however at some point in its run it seems that DeepVariant takes more threads N_SHARD is set to 20, no one else is using the computer at this moment and clearly more than 20 threads are taken. ![higdpgpplenjbaao](https://user-images.githubusercontent.com/23341393/74519762-a12a4c00-4f16-11ea-986c-b785044a618b.png). Is it expected?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/271
https://github.com/google/deepvariant/issues/272:402,modifiability,inherit,inherits,402,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:420,modifiability,variab,variable,420,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:2856,modifiability,scenario,scenarios,2856,"rolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:MIN_DP:PL	0/0:48:16:0,48,479. chr8	75144983	.	T	TG,<*>	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17,0:0.485714,0:49,0,64,990,990,990. chr8	75144984	.	G	<*>	0	.	END=75145000	GT:GQ:MIN_DP:PL	0/0:50:31:0,105,1049. ```. and kid:. ```. chr8	75144981	.	T	A,<*>	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16,0:0.592593,0:71,0,67,990,990,990. chr8	75144982	.	A	T,<*>	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16,0:0.592593,0:63,0,63,990,990,990. chr8	75144983	.	T	G,<*>	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16,0:0.592593,0:67,0,71,990,990,990. chr8	75144984	.	G	<*>	0	.	END=75145000	GT:GQ:MIN_DP:PL	0/0:50:25:0,75,749. ```. I am attaching a small sam for kid and dad aligned to hg38. [kid.sam.gz](https://github.com/google/deepvariant/files/4206576/kid.sam.gz). [dad.sam.gz](https://github.com/google/deepvariant/files/4206577/dad.sam.gz). I have other scenarios, but this one is one that seems clearly a deep variant issue and not a problem with glnexus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:1023,performance,content,content,1023,"pes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:MIN_DP:PL	0/0:48:16:0,48,479",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:1813,performance,content,content,1813," single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:MIN_DP:PL	0/0:48:16:0,48,479. chr8	75144983	.	T	TG,<*>	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17,0:0.485714,0:49,0,64,990,990,990. chr8	75144984	.	G	<*>	0	.	END=75145000	GT:GQ:MIN_DP:PL	0/0:50:31:0,105,1049. ```. and kid:. ```. chr8	75144981	.	T	A,<*>	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16,0:0.592593,0:71,0,67,990,990,990. chr8	75144982	.	A	T,<*>	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16,0:0.592593,0:63,0,63,990,990,990. chr8	75144983	.	T	G,<*>	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16,0:0.592593,0:67,0,71,990,990,990. chr8	75144984	.	G	<*>	0	.	END=75145000	GT:GQ:MIN_DP:PL	0/0:50:25:0,75,749. ```. I am attaching a small sam for kid and dad aligned to hg38. [kid.sam.gz](https://github.com/google/deepvariant/files/4206576/kid.sam.gz). [dad.sam.gz](https://github.com/google/deepvariant/f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:12,safety,compl,complex,12,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:12,security,compl,complex,12,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:146,security,team,team,146,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:977,testability,verif,verified,977,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:191,usability,document,document,191,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:692,usability,user,user-images,692,"issues with complex haplotypes; hi, I am using DV 0.9 to find *de novo* variants in trios and so I am enriching for weird stuff. . I am sure your team is aware of some/all of these, but I'll document at least 1 case here for the record. Nearly all obvious false positive de novo calls follow the same pattern. Mostly there is a haplotype from mom , and a haplotype from dad that are different. The kid inherits both the variable haplotypes, but the combination of DV and glnexus gentoype such that the variant appears as de novo. But, here is an example where there is just an incorrect call from DV that leads to 3 neighboring spurious de novo calls in the kid (top row):. ![bad-dn](https://user-images.githubusercontent.com/1739/74561469-d68a6600-4f25-11ea-8c71-105596810ace.png). note that dad in the 3rd row has a single read with a 1-base deletion (dash) followed by an insertion (purple tick). I can't show all of the reads in this image, but I have scrolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/272:2898,usability,clear,clearly,2898,"rolled through and verified that is the only read. . here is the content of the dad's VCF for that region (the mom's is actually very similar):. ```. chr8	75144980	.	CT	C	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18:0.529412:44,0,53. chr8	75144983	.	T	TG	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17:0.485714:49,0,64. ```. note that that is the single-base del and the insertion that occurs in only 1 read. Since the mom's is the same, maybe there's something akin to realignment going on, but. by contrast, here is the kid's (seemingly more sensible) VCF for that region:. ```. chr8	75144981	.	T	A	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:71,0,67. chr8	75144982	.	A	T	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16:0.592593:63,0,63. chr8	75144983	.	T	G	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16:0.592593:67,0,71. ```. here is the content of the gvcf for dad:. ```. chr8	75144980	.	CT	C,<*>	44.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:34:16,18,0:0.529412,0:44,0,53,990,990,990. chr8	75144982	.	A	<*>	0	.	END=75144982	GT:GQ:MIN_DP:PL	0/0:48:16:0,48,479. chr8	75144983	.	T	TG,<*>	49.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:49:35:18,17,0:0.485714,0:49,0,64,990,990,990. chr8	75144984	.	G	<*>	0	.	END=75145000	GT:GQ:MIN_DP:PL	0/0:50:31:0,105,1049. ```. and kid:. ```. chr8	75144981	.	T	A,<*>	71.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16,0:0.592593,0:71,0,67,990,990,990. chr8	75144982	.	A	T,<*>	63.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:61:27:11,16,0:0.592593,0:63,0,63,990,990,990. chr8	75144983	.	T	G,<*>	67.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:27:11,16,0:0.592593,0:67,0,71,990,990,990. chr8	75144984	.	G	<*>	0	.	END=75145000	GT:GQ:MIN_DP:PL	0/0:50:25:0,75,749. ```. I am attaching a small sam for kid and dad aligned to hg38. [kid.sam.gz](https://github.com/google/deepvariant/files/4206576/kid.sam.gz). [dad.sam.gz](https://github.com/google/deepvariant/files/4206577/dad.sam.gz). I have other scenarios, but this one is one that seems clearly a deep variant issue and not a problem with glnexus.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/272
https://github.com/google/deepvariant/issues/273:2273,availability,restor,restore,2273,"verableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_outp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2416,availability,restor,restore,2416,"1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2503,availability,checkpoint,checkpoint,2503,"cal/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3386,availability,checkpoint,checkpoint,3386,"saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:384,deployability,modul,module,384,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2691,deployability,modul,module,2691,"7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is ther",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3524,deployability,contain,contains,3524,"to_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""$",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3935,deployability,log,logs,3935,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4636,deployability,log,log,4636,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:22,energy efficiency,model,model,22,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:792,energy efficiency,predict,prediction,792,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:810,energy efficiency,predict,predictions,810,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:897,energy efficiency,estimat,estimator,897,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:907,energy efficiency,estimat,estimator,907,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:935,energy efficiency,predict,predict,935,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2537,energy efficiency,model,model,2537,"tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3420,energy efficiency,model,model,3420,". + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3535,energy efficiency,model,model,3535,"odel.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3572,energy efficiency,model,model,3572,"3s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3595,energy efficiency,model,model,3595,"back (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3623,energy efficiency,model,model,3623,":. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4582,energy efficiency,model,model,4582,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2987,integrability,sub,subprocess,2987,"nit_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCce",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3080,integrability,sub,subprocess,3080,"ger.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3161,integrability,sub,subprocess,3161,"n2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:470,interoperability,platform,platform,470,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:384,modifiability,modul,module,384,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:443,modifiability,pac,packages,443,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:860,modifiability,pac,packages,860,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:1011,modifiability,pac,packages,1011,"puting model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:1177,modifiability,pac,packages,1177,"e tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:1356,modifiability,pac,packages,1356,"ants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:1531,modifiability,pac,packages,1531,"/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_mode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:1701,modifiability,pac,packages,1701,"iles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:1880,modifiability,pac,packages,1880,"mator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2037,modifiability,pac,packages,2037,"ining/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2176,modifiability,pac,packages,2176,"kages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledPr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2355,modifiability,pac,packages,2355,"kages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2691,modifiability,modul,module,2691,"7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is ther",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2751,modifiability,pac,packages,2751,"py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2851,modifiability,pac,packages,2851,"local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3201,performance,time,time,3201,"training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4176,performance,time,time,4176,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:206,reliability,doe,doesn,206,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2273,reliability,restor,restore,2273,"verableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_outp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2416,reliability,restor,restore,2416,"1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2503,reliability,checkpoint,checkpoint,2503,"cal/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3386,reliability,checkpoint,checkpoint,3386,"saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3509,reliability,doe,does,3509,"nt: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:13,safety,input,inputing,13,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:384,safety,modul,module,384,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:792,safety,predict,prediction,792,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:810,safety,predict,predictions,810,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:935,safety,predict,predict,935,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2497,safety,valid,valid,2497,"""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosqui",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2516,safety,input,input,2516,"hon2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2691,safety,modul,module,2691,"7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is ther",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3399,safety,input,input,3399,"line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3935,safety,log,logs,3935,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4213,safety,input,input,4213,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4344,safety,input,input,4344,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4376,safety,input,input,4376,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4416,safety,input,input,4416,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4561,safety,input,input,4561,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4636,safety,log,log,4636,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:22,security,model,model,22,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
