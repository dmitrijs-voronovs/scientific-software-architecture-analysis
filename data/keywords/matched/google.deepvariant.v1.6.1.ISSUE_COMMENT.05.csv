id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/123:5267,interoperability,share,shared,5267,"stall advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5978,interoperability,share,shared,5978,"f Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6011,interoperability,protocol,protocolbuffers,6011," # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuff",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6082,interoperability,protocol,protocolbuffers,6082,"k gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6192,interoperability,share,shared,6192,"mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6269,interoperability,protocol,protocolbuffers,6269,"isable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6468,interoperability,share,share,6468,"PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6652,interoperability,share,shared,6652,"//bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6812,interoperability,share,shared,6812,"pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7007,interoperability,protocol,protocolbuffers,7007,"ocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-tool",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7081,interoperability,protocol,protocolbuffers,7081,"lbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" instal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7234,interoperability,share,share,7234,"e code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10789,interoperability,format,format,10789,"c. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10842,interoperability,interfac,interfaces,10842,"N_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:12023,interoperability,Repositor,Repository,12023,"#endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:14265,interoperability,wrapper,wrapper,14265,"nk@307315 clang. ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15093,interoperability,repositor,repository,15093,"tory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15209,interoperability,repositor,repository,15209,"os/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ###########################################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15341,interoperability,repositor,repository,15341,"to_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16734,interoperability,api,api-python-client,16734,"te. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17515,interoperability,Repositor,Repository,17515,"all 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19624,interoperability,messag,message,19624,"named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resourc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:22819,interoperability,API,API,22819,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:432,modifiability,modul,module,432,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:653,modifiability,pac,packages,653,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:776,modifiability,pac,packages,776,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2061,modifiability,configur,configure,2061,"-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2360,modifiability,version,version,2360,"ffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2439,modifiability,version,versions,2439,"lt from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/ad",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2525,modifiability,version,versions,2525,"github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3732,modifiability,Configur,Configure,3732,.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3861,modifiability,configur,configuration,3861,.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4165,modifiability,configur,configuration,4165,"sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4614,modifiability,modul,modules,4614,"b/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4644,modifiability,modul,module,4644,"hat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -q",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4664,modifiability,modul,module,4664,"-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5224,modifiability,configur,configure,5224," advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # downlo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5571,modifiability,pac,packages,5571,"ironment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5615,modifiability,version,version,5615,"es. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5789,modifiability,upgrad,upgrade,5789,"cs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5834,modifiability,version,version,5834,"hon 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /op",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5931,modifiability,upgrad,upgrade,5931,"/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6609,modifiability,configur,configure,6609,"-version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6920,modifiability,version,version,6920,"tall --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/bo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7267,modifiability,version,version,7267,"otocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7307,modifiability,version,version,7307,"/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biop",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8588,modifiability,pac,packages,8588,"y. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8640,modifiability,depend,dependency,8640,"AS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9053,modifiability,depend,dependecy,9053,"ath=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9452,modifiability,pac,package,9452,"nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9460,modifiability,depend,dependencies,9460,"93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9748,modifiability,configur,configure,9748,"ps -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-poi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9893,modifiability,pac,packages,9893,"enblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && define",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10547,modifiability,configur,configure,10547,"4. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10842,modifiability,interfac,interfaces,10842,"N_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:11716,modifiability,pac,package,11716,"vocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:12135,modifiability,version,version,12135,". #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees. mkdir -p $LLVM_DIR. cd $LLVM_DIR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:12159,modifiability,version,version,12159,"8 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees. mkdir -p $LLVM_DIR. cd $LLVM_DIR. svn co https://llvm.or",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:12771,modifiability,pac,packages,12771,"ackage $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees. mkdir -p $LLVM_DIR. cd $LLVM_DIR. svn co https://llvm.org/svn/llvm-project/llvm/trunk@307315 llvm. cd llvm/tools. svn co https://llvm.org/svn/llvm-project/cfe/trunk@307315 clang. ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:13014,modifiability,upgrad,upgrade,13014," Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees. mkdir -p $LLVM_DIR. cd $LLVM_DIR. svn co https://llvm.org/svn/llvm-project/llvm/trunk@307315 llvm. cd llvm/tools. svn co https://llvm.org/svn/llvm-project/cfe/trunk@307315 clang. ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:13047,modifiability,upgrad,upgrade,13047,"com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees. mkdir -p $LLVM_DIR. cd $LLVM_DIR. svn co https://llvm.org/svn/llvm-project/llvm/trunk@307315 llvm. cd llvm/tools. svn co https://llvm.org/svn/llvm-project/cfe/trunk@307315 clang. ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15494,modifiability,Depend,Dependency,15494,"l.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'reques",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15924,modifiability,pac,packages,15924,"hl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16003,modifiability,pac,packages,16003,"ariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. #########################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16145,modifiability,pac,packages,16145,"tps://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ##############################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16263,modifiability,version,version,16263,"vark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. #################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16288,modifiability,version,version,16288,"d opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ##########################################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16316,modifiability,pac,packages,16316,"e tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependenc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16719,modifiability,upgrad,upgrade,16719,"``. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all ta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16825,modifiability,depend,depend,16825,"misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17054,modifiability,depend,depend,17054,"heel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17311,modifiability,depend,dependencies,17311,"ackages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17976,modifiability,pac,packages,17976,". ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18058,modifiability,pac,packages,18058,"n - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18181,modifiability,pac,packages,18181,"tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTH",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18621,modifiability,modul,module,18621,"ut source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20794,modifiability,depend,depending,20794,"$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21357,modifiability,pac,packages,21357,"():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. #######################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:229,performance,CPU,CPU,229,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:423,performance,profil,profile,423,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:439,performance,load,load,439,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:955,performance,failur,failure,955,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:1759,performance,CPU,CPU,1759,"python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2000,performance,CPU,CPU,2000,"https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. exp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2012,performance,CPU,CPU,2012,"ub.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=powe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2038,performance,CPU,CPU,2038,"ses/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2050,performance,CPU,CPU,2050,"/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. expo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2267,performance,cach,cache,2267,"//github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3006,performance,CPU,CPU,3006,"ne=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4402,performance,Load,Load,4402,"tps://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4567,performance,Load,Load,4567,"h. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/sit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4635,performance,profil,profile,4635,"n/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4651,performance,load,load,4651,"EL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc http",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5072,performance,CPU,CPU,5072,"unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://git",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5163,performance,CPU,CPU,5163,"configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5175,performance,CPU,CPU,5175,"n file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built fro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5201,performance,CPU,CPU,5201,"nce Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5213,performance,CPU,CPU,5213,"n. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6548,performance,CPU,CPU,6548,"t/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6560,performance,CPU,CPU,6560,"2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6586,performance,CPU,CPU,6586,"y 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6598,performance,CPU,CPU,6598,"ho ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. pytho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6827,performance,cach,cache,6827,"p --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ``",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8424,performance,error,error,8424,"ariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8699,performance,CPU,CPU,8699,"m/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8711,performance,CPU,CPU,8711,"nBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tens",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9095,performance,CPU,CPU,9095,"## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9107,performance,CPU,CPU,9107,"w 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10491,performance,CPU,CPU,10491,"ix wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10503,performance,CPU,CPU,10503,"k. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10570,performance,error,error,10570,"applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_AB",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:11087,performance,error,error,11087,"TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/goo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:13490,performance,cach,cache,13490,". export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees. mkdir -p $LLVM_DIR. cd $LLVM_DIR. svn co https://llvm.org/svn/llvm-project/llvm/trunk@307315 llvm. cd llvm/tools. svn co https://llvm.org/svn/llvm-project/cfe/trunk@307315 clang. ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/pro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15435,performance,load,load,15435,"ython/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18585,performance,GPU,GPU,18585,"ogle/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19369,performance,CPU,CPU,19369,"=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19827,performance,Error,Error,19827,"v=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; mak",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20047,performance,CPU,CPU,20047,"THON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20295,performance,resourc,resources,20295,"_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20893,performance,resourc,resources,20893,"#########################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20950,performance,resourc,resources,20950,"st_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20960,performance,Resourc,ResourceMonitor,20960,"V_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:955,reliability,fail,failure,955,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4009,reliability,failov,failovermethod,4009,. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20981,reliability,monitor,monitor,20981,"""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21009,reliability,monitor,monitor,21009,"t. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21081,reliability,monitor,monitor,21081,"######################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ################################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:22416,reliability,fail,fail,22416,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:432,safety,modul,module,432,"Hi @DiableJambe ,. Sorry for my late response, I do not have a docker image yet. And I attached the detailed steps here for your reference. It's a bit long :). # DeepVariant. ## Environment. ```bash. # Power8 environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # AT 11.0 environment. source /etc/profile. module load at11.0. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # python2 and pip environment. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. ```. ## Cmake 3.13.3. Build and install doc: [https://cmake.org/install/](https://cmake.org/install/). >Note: only can be built with system gcc, AT11.0 will cause build failure. ```bash. # download source code. wget https://github.com/Kitware/CMake/releases/download/v3.13.3/cmake-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4614,safety,modul,modules,4614,"b/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4644,safety,modul,module,4644,"hat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -q",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4664,safety,modul,module,4664,"-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7391,safety,test,test,7391,"f-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8424,safety,error,error,8424,"ariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8640,safety,depend,dependency,8640,"AS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9053,safety,depend,dependecy,9053,"ath=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9460,safety,depend,dependencies,9460,"93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10570,safety,error,error,10570,"applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_AB",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:11087,safety,error,error,11087,"TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/goo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15465,safety,updat,update,15465,"ols/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as insta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15494,safety,Depend,Dependency,15494,"l.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'reques",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16825,safety,depend,depend,16825,"misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17054,safety,depend,depend,17054,"heel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17311,safety,depend,dependencies,17311,"ackages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17893,safety,test,test,17893,"#################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18621,safety,modul,module,18621,"ut source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18719,safety,test,test,18719,"tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19198,safety,log,log,19198,"ZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19216,safety,test,test,19216,"ilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19385,safety,test,test,19385,"# export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19827,safety,Error,Error,19827,"v=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; mak",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19933,safety,test,test,19933,"v=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_valu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20295,safety,resourc,resources,20295,"_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20527,safety,log,logical,20527," --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # rein",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20794,safety,depend,depending,20794,"$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20880,safety,patch,patch,20880,"########################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archiv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20893,safety,resourc,resources,20893,"#########################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20950,safety,resourc,resources,20950,"st_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20960,safety,Resourc,ResourceMonitor,20960,"V_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20981,safety,monitor,monitor,20981,"""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21009,safety,monitor,monitor,21009,"t. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21081,safety,monitor,monitor,21081,"######################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ################################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:22169,safety,test,test,22169,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:22634,safety,test,test,22634,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2061,security,configur,configure,2061,"-3.13.3.tar.gz. tar -zxvf cmake-3.13.3.tar.gz. cd cmake-3.13.3. # build scirpt. ./bootstrap. make -j20. make -j20 install. export PATH=/usr/local/bin:$PATH. ```. ## Protobuf 3.6.1 C++ static. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3732,security,Configur,Configure,3732,.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3861,security,configur,configuration,3861,.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4165,security,configur,configuration,4165,"sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5224,security,configur,configure,5224," advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # downlo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5697,security,certif,certificate,5697,"and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6609,security,configur,configure,6609,"-version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9748,security,configur,configure,9748,"ps -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-poi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10547,security,configur,configure,10547,"4. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15465,security,updat,update,15465,"ols/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as insta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15689,security,session,session,15689,"lif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip inst",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18292,security,sign,sign-compare,18292,"####. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --acti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18440,security,sign,sign-compare,18440,"p2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19198,security,log,log,19198,"ZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20527,security,log,logical,20527," --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # rein",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20880,security,patch,patch,20880,"########################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archiv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2311,testability,verif,verify,2311,"aster/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from /usr/bin/gcc, static for bazel. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --disable-shared --enable-static. make clean. make -j20. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3338,testability,verif,verification,3338,"cho ""$(protoc --version)"". ```. ## Bazel 0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5583,testability,verif,verify,5583,"udo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:5911,testability,mock,mock,5911,"https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. # verify 2.7.15. echo ""$(python --version)"". # Pip 19.0.2. wget -qc https://bootstrap.pypa.io/get-pip.py --no-check-certificate. $HOMEPATH/inst/bin/python ./get-pip.py --prefix $HOMEPATH/inst. #pip install --upgrade --force-reinstall pip. echo ""$(pip --version)"". pip install setuptools nose asv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(pr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:6871,testability,verif,verify,6871,"sv cython future protobuf==3.6.1 six mock. pip install --upgrade setuptools. ```. ## Protobuf 3.6.1 C++ shared. C++: [https://github.com/protocolbuffers/protobuf/blob/master/src/README.md](https://github.com/protocolbuffers/protobuf/blob/master/src/README.md). > Note: Protobuf 3.6.1 should be built from AT 11.0, C++ shared for TF 1.12. ```bash. # download source code. wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.tar.gz. tar -zxvf protobuf-all-3.6.1.tar.gz. cd protobuf-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7391,testability,test,test,7391,"f-3.6.1/. # clean static protobuf build. make uninstall. make distclean. # share build for C++. # install under /usr instead of /usr/local. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CXXFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:7587,testability,verif,verify,7587,"-mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make clean. make -j20. # optional. make -j20 check # check if protobuf build is good. # install. make install. sudo ldconfig # refresh shared library cache - /opt/at11.0/sbin/ldconfig. #cd .. # verify. echo ""$(which protoc)"". echo ""$(protoc --version)"". ```. ## Protobuf 3.6.1 Python from source code. Python: [https://github.com/protocolbuffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8640,testability,depend,dependency,8640,"AS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9017,testability,verif,verify,9017,"cc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NE",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9053,testability,depend,dependecy,9053,"ath=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9412,testability,verif,verify,9412,"Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9460,testability,depend,dependencies,9460,"93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:9502,testability,mock,mock,9502,"//gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python -c ""import scipy"". # pip package dependencies. # pip install pip six wheel mock. pip install wheel autograd h5py==2.9.0 enum34. pip install keras_applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:11891,testability,verif,verification,11891,"d __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:14934,testability,verif,verify,14934," # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15494,testability,Depend,Dependency,15494,"l.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'reques",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:15673,testability,Verif,Verify,15673,"CESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16410,testability,mock,mock,16410,"it checkout tags/20. # load submoduel. git submodule update --init --recursive. # Dependency. pip install pyparsing. yum install qt-devel. # Build. python setup.py bdist_wheel. # Insatll. pip install dist/opencv_python-3.4.5.20-cp27-cp27mu-linux_ppc64le.whl. # Verify in a new session. python -c ""import cv2"". ```. ## DV Prerequisite. ```bash. ####################################################################. # misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install opens",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:16825,testability,depend,depend,16825,"misc setup. ####################################################################. # development packages. yum install python2-pkgconfig zip zlib-devel unzip curl -y. # python packages. yum install python-devel python-pip python-wheel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17054,testability,depend,depend,17054,"heel -y. ####################################################################. # python packages. ####################################################################. # python 2 required. echo ""$(python --version)"". echo ""$(pip --version)"". # Install python packages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17311,testability,depend,dependencies,17311,"ackages. pip install contextlib2. pip install enum34. pip install intervaltree. pip install 'mock>=2.0.0'. # pip install 'numpy==1.14' => skip as installed in TF. pip install 'requests>=2.18'. # pip install 'scipy==1.0' => skip as installed in TF. pip install 'oauth2client>=4.0.0'. pip install 'crcmod>=1.7'. pip install six. pip install sklearn. pip install pandas. pip install psutil. pip install --upgrade google-api-python-client. ####################################################################. # depend on opencv-python wheel - build from source. ####################################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:17893,testability,test,test,17893,"#################################################. pip install 'tensor2tensor>=1.9.0'. ####################################################################. # depend on - TensorFlow - 1.12 build from source. ####################################################################. pip install tensorflow-1.12.0-cp27-cp27mu-linux_ppc64le.whl. ####################################################################. # Misc dependencies. ####################################################################. yum install openssl-devel curl-devel zlib-devel bzip2-devel xz-devel. yum install boost-devel. ```. ## DeepVariant. Git Repository [https://github.com/google/deepvariant](https://github.com/google/deepvariant). ```bash. # check out source code. git clone https://github.com/google/deepvariant.git. cd deepvariant. # fetch all tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:18719,testability,test,test,18719,"tags. git fetch --all --tags --prune. # check out tag. git checkout tags/v0.7.2. # Edit ctx.action with use_default_shell_env=True. vim ./third_party/clif.bzl. # Build and test. export LD_LIBRARY_PATH=/home/qilibj/inst/lib:/qilibj/inst/lib/python2.7/site-packages:$LD_LIBRARY_PATH. export PYTHONPATH=/home/qilibj/inst/lib/python2.7/site-packages. export PYTHON_BIN_PATH=/home/qilibj/inst/bin/python. export PYTHON_LIB_PATH=/home/qilibj/inst/lib/python2.7/site-packages. export BAZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19198,testability,log,log,19198,"ZEL_PYTHON=/home/qilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19216,testability,test,test,19216,"ilibj/inst/bin/python. export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11"". # export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19385,testability,test,test,19385,"# export DV_COPT_FLAGS=""--copt=-maltivec --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS --cxxopt=-std=gnu++11 --copt=-fsigned-char --cxxopt=-fsigned-char"". # for GPU enabled. # fix ""ImportError: No module named google.protobuf"" by install protobuf from source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19933,testability,test,test,19933,"v=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_valu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20295,testability,resourc,resources,20295,"_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20527,testability,log,logical,20527," --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # rein",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20794,testability,depend,depending,20794,"$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20875,testability,mock,mock,20875,"##############################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20893,testability,resourc,resources,20893,"#########################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20950,testability,resourc,resources,20950,"st_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20960,testability,Resourc,ResourceMonitor,20960,"V_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20981,testability,monitor,monitor,20981,"""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:20997,testability,assert,assertEqual,20997,"ources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21009,testability,monitor,monitor,21009,"t. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21069,testability,assert,assertEqual,21069,"################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ######################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21081,testability,monitor,monitor,21081,"######################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ################################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21979,testability,verif,verify,21979,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:22169,testability,test,test,22169,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:22428,testability,mock,mock,22428,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:22634,testability,test,test,22634,"urces.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'intervaltree==2.1.0'. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3380,usability,Tool,Toolchain,3380,0.15.0. Build instructions: [https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3449,usability,tool,toolchain,3449,/install-compile-source.html#bootstrap-bazel](https://docs.bazel.build/versions/master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3529,usability,tool,toolchain,3529,master/install-compile-source.html#bootstrap-bazel). Edit crosstool: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/l,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3631,usability,tool,toolchain,3631,yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). > Note: Bazel 0.15.0 should be built from /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/p,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3754,usability,Tool,Toolchain,3754,m /usr/bin/gcc. ```bash. # download source code. wget https://github.com/bazelbuild/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3835,usability,tool,toolchain,3835,ld/bazel/releases/download/0.15.0/bazel-0.15.0-dist.zip. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Pytho,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3890,usability,tool,toolchain,3890,. mkdir bazel-0.15.0. unzip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download s,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3915,usability,Tool,Toolchain,3915,ip -n bazel-0.15.0-dist.zip -d ./bazel-0.15.0. cd bazel-0.15.0. # environment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https:/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:3982,usability,tool,toolchain,3982,nvironment. export CPU=power8. export HOMEPATH=/home/qilibj. export JAVA_HOME=/usr/lib/jvm/java-1.8.0. export PATH=$HOMEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Pyth,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4100,usability,tool,toolchain,4100,MEPATH/inst/bin:$JAVA_HOME/bin:/usr/local/cuda-10.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before bu,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4207,usability,Tool,Toolchain,4207,"root/bin. # build from scratch. PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4238,usability,tool,toolchain-,4238," PROTOC=$HOMEPATH/inst/bin/protoc ./compile.sh. rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4284,usability,tool,toolchain-,4284,". rsync -avP output/bazel $HOMEPATH/inst/bin/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-stati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4328,usability,tool,toolchain-,4328,"/. # verification. bazel info. ```. ## Advance Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environmen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:4371,usability,tool,toolchain-,4371,"nce Toolchain 11.0. Doc: [https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/](https://developer.ibm.com/linuxonpower/advance-toolchain/advtool-installation/). ```bash. # gpg public key. wget ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. rpm --import gpg-pubkey-6976a827-5164221b. # Configure the Advance Toolchain repositories. [root@cit1074 deepvariant]# cat /etc/yum.repos.d/advance-toolchain.repo. #Begin of configuration file. [advance-toolchain]. name=Advance Toolchain Unicamp FTP. baseurl=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7. failovermethod=priority. enabled=1. gpgcheck=1. gpgkey=ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/redhat/RHEL7/gpg-pubkey-6976a827-5164221b. # End of configuration file. # Install the Advance Toolchain. yum install advance-toolchain-at11.0-runtime. yum install advance-toolchain-at11.0-devel. yum install advance-toolchain-at11.0-perf. yum install advance-toolchain-at11.0-mcore-libs. # Load enviroment. export PATH=/opt/at11.0/bin:/opt/at11.0/sbin:$PATH. # Do not need to export. # export LD_LIBRARY_PATH=/opt/at11.0/lib64:/lib64:$LD_LIBRARY_PATH . # Load environment. sudo yum install environment-modules. source /etc/profile. module load at11.0. module unload at11.0. ```. ## Python 2 and Pip 19.0.1. Build instructions: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html). > Note: Python 2 should be built from AT 11.0. ```bash. # download source code . wget https://www.python.org/ftp/python/2.7.15/Python-2.7.15.tgz. tar -zxvf Python-2.7.15.tgz. cd Python-2.7.15. # environment. export HOMEPATH=/home/qilibj. export CPU=power8. # check gcc before build, should be AT11.0. which gcc. # build. CFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" CPPFLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" ./configure --prefix=$HOMEPATH/inst --enable-shared --disable-static. make -j20. make install. # set environment. export PATH=$HOMEPATH/inst/bin:/usr/loca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8011,usability,tool,toolset,8011,"buffers/protobuf/blob/master/python/README.md](https://github.com/protocolbuffers/protobuf/blob/master/python/README.md). > Note: Protobuf 3.6.1 should be built from source code or CLIF cannot find protobuf. ```bash. # share build for Python. python --version # python 2.7 or newer. protoc --version. # build. cd protobuf-3.6.1/python/. python setup.py build. python setup.py test. # install from source as deepvariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:8424,usability,error,error,8424,"ariant needed. python setup.py install. # install from wheel. python setup.py bdist_wheel. pip install protobuf-3.6.1-py2.py3-none-any.whl --force-reinstall. # verify. python -c ""import google.protobuf"". ```. ## OpenBLAS 0.3.5. ```bash. git clone -b v0.3.5 https://github.com/xianyi/OpenBLAS.git OpenBLAS-0.3.5. cd OpenBLAS-0.3.5. make TARGET=power8. make TARGET=power8 PREFIX=$HOMEPATH/inst install. ```. ## Boost 1.66.0. ```bash. wget -qc https://dl.bintray.com/boostorg/release/1.66.0/source/boost_1_66_0.tar.gz. tar xzf boost_1_66_0.tar.gz. cd boost_1_66_0. ./bootstrap.sh --with-toolset=gcc --prefix=$HOMEPATH/inst. ./b2 dll-path=""$HOMEPATH/inst/lib"" install. ```. ## TensorFlow 1.12.0. > Note: Tensorflow 1.12.0 can be built with AT 11.0. Build instructions: [https://www.tensorflow.org/install/source](https://www.tensorflow.org/install/source). Edit instructions: [http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html](http://biophysics.med.jhmi.edu/~yliu120/tensorflow.html). Floatn.h error: [https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f](https://gist.github.com/nonchip/2c93ff2d9bc1bf2cd12bc6e76010da0f). ```bash. # development packages. yum install python-devel python-pip -y. # dependency of numpy 1.14.6. OPT=""-D_XLOCALE_H=1 -O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install numpy==1.14.6. # verify. python -c ""import numpy"". # dependecy of scipy 1.2.0. OPT=""-O3 -mcpu=$CPU -mtune=$CPU -maltivec -mvsx -ffast-math -fpeel-loops -funroll-loops -ftree-vectorize -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free"" BLAS=$HOMEPATH/inst/lib/libopenblas.so LAPACK=$HOMEPATH/inst/lib/libopenblas.so ATLAS=$HOMEPATH/inst/lib/libopenblas.so pip install scipy==1.2.0. # verify. python ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:10570,usability,error,error,10570,"applications==1.0.6 keras_preprocessing==1.0.5. # download source code. git clone -b r1.12 https://github.com/tensorflow/tensorflow.git tensorflow-1.12. cd tensorflow-1.12. # configure in tensorflow/.tf_configure.bazelrc. PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"" \. PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"" \. TF_NEED_IGNITE=""0"" \. TF_ENABLE_XLA=""0"" \. TF_NEED_OPENCL_SYCL=""0"" \. TF_NEED_ROCM=""0"" \. TF_NEED_MPI=""0"" \. TF_NEED_TENSORRT=""0"" \. TF_NEED_CUDA=""1"" \. TF_CUDA_VERSION=""10.0"" \. CUDA_TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_AB",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:11087,usability,error,error,11087,"TOOLKIT_PATH=""/usr/local/cuda"" \. TF_CUDNN_VERSION=""7"" \. CUDNN_INSTALL_PATH=""/usr/local/cuda-10.0"" \. TF_NCCL_VERSION=""2"" \. NCCL_INSTALL_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib"" \. NCCL_HDR_PATH=""/usr/local/cuda-10.0/targets/ppc64le-linux/lib/../include"" \. TF_CUDA_COMPUTE_CAPABILITIES=""3.7"" \. TF_CUDA_CLANG=""0"" \. GCC_HOST_COMPILER_PATH=""/opt/at11.0/bin/gcc"" \. CC_OPT_FLAGS=""-mcpu=$CPU -mtune=$CPU -O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/goo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:11504,usability,tool,tools,11504,"-O3"" \. TF_SET_ANDROID_WORKSPACE=0 \. ./configure. # fix build error. vim /opt/at11.0/include/bits/floatn.h. -------------------------------------. #include <features.h>. /* Defined to 1 if the current compiler invocation provides a. floating-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:11746,usability,tool,tools,11746,"-point type with the IEEE 754 binary128 format, and this glibc. includes corresponding *f128 interfaces for it. */. #if defined _ARCH_PWR8 && defined __LITTLE_ENDIAN__ && (_CALL_ELF == 2) \. && defined __FLOAT128__. # define __HAVE_FLOAT128 1. #else. # define __HAVE_FLOAT128 0. #endif. /* add the following block of fix tensorflow build error */. #if CUDART_VERSION. #undef __HAVE_FLOAT128. #define __HAVE_FLOAT128 0. #endif. /* Defined to 1 if __HAVE_FLOAT128 is 1 and the type is ABI-distinct. from the default float, double and long double types in this glibc. */. #if __HAVE_FLOAT128. -------------------------------------. # build. bazel clean. export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --distinct_host_configuration=false. # generate package. bazel-bin/tensorflow/tools/pip_package/build_pip_package $HOMEPATH/tensorflow_package. # install. pip install $HOMEPATH/tensorflow_package/tensorflow-1.12.0-*.whl. # verification. python -c ""import tensorflow as tf; print(tf.__version__)"". ```. ## CLIF. > Note: CLIF can be built with AT 11.0. Git Repository: [https://github.com/google/clif](https://github.com/google/clif). ```bash. # Prerequisites. cmake --version #3.5+. protoc --version # 3.2.0+ build from source code for both C++ and Python. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:13214,usability,tool,tools,13214,"ython. pip install virtualenv. pip install pyparsing. yum install subversion. yum install ocaml. pip install 'pyparsing>=2.2.0'. pkg-config --libs python # workable. # download source code. cd $HOMEPATH. git clone https://github.com/google/clif.git. cd clif. # set environment. export INSTALL_DIR=""$HOMEPATH/inst"". export CLIFSRC_DIR=""$HOMEPATH/clif"". export LLVM_DIR=""$CLIFSRC_DIR/../clif_backend"". export BUILD_DIR=""$LLVM_DIR/build_matcher"". export PYTHON_BIN_PATH=""$HOMEPATH/inst/bin/python"". export PYTHON_LIB_PATH=""$HOMEPATH/inst/lib/python2.7/site-packages"". export PROTOC_PREFIX_PATH=""$(dirname ""$(dirname ""$(which protoc)"")"")"". export CLIF_VIRTUALENV=""$INSTALL_DIR""/clif. export CLIF_PIP=""$CLIF_VIRTUALENV/bin/pip"". virtualenv -p ""$PYTHON_BIN_PATH"" ""$CLIF_VIRTUALENV"". $CLIF_PIP install --upgrade pip. $CLIF_PIP install --upgrade setuptools. # Checkout LLVM and Clang source trees. mkdir -p $LLVM_DIR. cd $LLVM_DIR. svn co https://llvm.org/svn/llvm-project/llvm/trunk@307315 llvm. cd llvm/tools. svn co https://llvm.org/svn/llvm-project/cfe/trunk@307315 clang. ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:14199,usability,tool,tools,14199,"vm. cd llvm/tools. svn co https://llvm.org/svn/llvm-project/cfe/trunk@307315 clang. ln -s -f -n $CLIFSRC_DIR/clif clif. # Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Ch",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:14319,usability,tool,tools,14319,"# Builds must be done outside of the LLVM tree. mkdir -p $BUILD_DIR. cd $BUILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:14393,usability,tool,tools,14393,"UILD_DIR. # Note to remove -DLLVM_TARGETS_TO_BUILD=X86. # ""rm CMakeCache.txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:14466,usability,tool,tools,14466,"txt"" to remove cmake cache. cmake -DCMAKE_INSTALL_PREFIX=""$CLIF_VIRTUALENV/clang"" \. -DCMAKE_PREFIX_PATH=""$PROTOC_PREFIX_PATH"" \. -DLLVM_INSTALL_TOOLCHAIN_ONLY=true \. -DCMAKE_BUILD_TYPE=Release \. -DLLVM_BUILD_DOCS=false \. -DLLVM_TARGETS_TO_BUILD=PowerPC \. -DPYTHON_INCLUDE_DIR=""$HOMEPATH/inst/include/python2.7"" \. -DPYTHON_LIBRARY=""$HOMEPATH/inst/lib/libpython2.7.so"" \. -DPYTHON_EXECUTABLE=""$HOMEPATH/inst/bin/python"" \. ""$LLVM_DIR/llvm"". make -j20 clif-matcher. # export LD_LIBRARY_PATH=/home/qilibj/inst/lib:$LD_LIBRARY_PATH. make -j20 clif_python_utils_proto_util. make -j20 install. ## Get back to the CLIF Python directory and have pip run setup.py. cd ""$CLIFSRC_DIR"". # Grab the python compiled .proto. cp ""$BUILD_DIR/tools/clif/protos/ast_pb2.py"" clif/protos/. # Grab CLIF generated wrapper implementation for proto_util. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.cc"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.h"" clif/python/utils/. cp ""$BUILD_DIR/tools/clif/python/utils/proto_util.init.cc"" clif/python/utils/. # install. export C_INCLUDE_PATH=/home/qilibj/inst/include. export CPLUS_INCLUDE_PATH=/home/qilibj/inst/include. ""$CLIF_PIP"" install . # echo ""SUCCESS - To use pyclif, run $CLIF_VIRTUALENV/bin/pyclif."". python setup.py bdist_wheel. # Note: pyclif should be installed into virtualenv. ""$CLIF_PIP"" install pyclif-0.3-cp27-none-linux_ppc64le.whl. pip install dist/pyclif-0.3-cp27-cp27m-linux_ppc64le.whl. # verify. python -c ""from clif.python.proto import start"". # link for deepvariant. ln -s /home/qilibj/inst/clif /usr/local/. ```. ## Opencv-python 3.4.5.20. Git repository: [https://github.com/skvark/opencv-python](https://github.com/skvark/opencv-python). ```bash. # Checkout repository and submodules. git clone https://github.com/skvark/opencv-python.git. cd opencv-python/. # fetch the tags to your local repository. git fetch --all --tags --prune. # check out tag 3.4.5.20. git checkout tags/20. # load submoduel. git submodule upda",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19674,usability,help,help,19674,"source. bazel clean. bazel shutdown. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant/... \. --action_env=LD_LIBRARY_PATH --test_env=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:19827,usability,Error,Error,19827,"v=LD_LIBRARY_PATH \. --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH \. --action_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH --test_env=PYTHON_BIN_PATH=$PYTHON_BIN_PATH \. --action_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH --test_env=PYTHON_LIB_PATH=$PYTHON_LIB_PATH \. --action_env=BAZEL_PYTHON=$BAZEL_PYTHON --test_env=BAZEL_PYTHON=$BAZEL_PYTHON >& output.log 2>&1 &. bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" deepvariant:gpu_tests --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # for CPU only. bazel test -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant/... # build binary. bazel build -c opt ${DV_COPT_FLAGS} ""$@"" deepvariant:binaries --build_python_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. echo 'Expect a usage message:'. (bazel-bin/deepvariant/call_variants --help || : ) | grep '/call_variants.py:'. bazel build :licenses_zip --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ```. ## Fix DV Error. ```bash. ################################################################################. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:resources_test. # use lscpu to show the actual CPU number. ################################################################################. python -c ""import multiprocessing; print(multiprocessing.cpu_count())"" #160. python -c ""import psutil;print(p/sutil.cpu_count. ())"" #160. vim deepvariant/resources.py. --------------------------------. def _get_cpu_count():. """"""Gets the number of physical cores in this machine. Returns:. int >= 1 if the call to get the cpu_count succeeded, or 0 if not. """""". # return psutil.cpu_count(logical=False) or 0 ==> comment. return 20. --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; mak",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21567,usability,learn,learn,21567," --------------------------------. vim deepvariant/resources_test.py. --------------------------------. def test_metrics_is_ok_when_cpu_count_returns_none(self):. # Some psutil functions, such as cpu_freq(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ########################################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21771,usability,learn,learn,21771,"(), can return None depending on. # the environment; make sure we don't crash when that occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21858,usability,learn,learn,21858," occurs. with mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. #####################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21871,usability,learn,learn,21871," mock.patch.object(resources.psutil, 'cpu_count', return_value=None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##################################",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:21934,usability,learn,learn-,21934,"None):. with resources.ResourceMonitor() as monitor:. #self.assertEqual(monitor.metrics().physical_core_count, 0) ==> comment. self.assertEqual(monitor.metrics().physical_core_count, 20). --------------------------------. ##########################################################################. # //deepvariant/realigner/allele_count_linear:generate_trained_model_test. # ImportError: /root/.local/lib/python2.7/site-packages/sklearn/__check_build/_check_build.so: undefined symbol: PyUnicodeUCS4_DecodeUTF8. ##########################################################################. # reinstall numpy, scipy, Cpython, scikit-learn to fix with AT built Python. python -c ""import numpy"" # prequests of TF 1.12.0. python -c ""import scipy"" # prequests of TF 1.12.0. pip install Cython --force-reinstall --no-deos. pip install scikit-learn --force-reinstall --no-deos. # build from source. wget https://github.com/scikit-learn/scikit-learn/archive/0.20.2.tar.gz. tar zxvf 0.20.2.tar.gz. cd scikit-learn-0.20.2. python setup.py bdist_wheel. # verify. python -c ""from sklearn.externals import joblib"". ##########################################################################. # //deepvariant/labeler:haplotype_labeler_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant/labeler:haplotype_labeler_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. ##########################################################################. # fail due to mock data, open an issue in github. https://github.com/google/deepvariant/issues/154. ##########################################################################. # //deepvariant:make_examples_test. # bazel test -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@""//deepvariant:make_examples_test --action_env=PYTHONPATH=$PYTHONPATH --test_env=PYTHONPATH=$PYTHONPATH. # internvaltree v3 has some API changes with v2. ##########################################################################. pip install 'interval",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:98,deployability,updat,update,98,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:284,deployability,version,version,284,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:329,deployability,version,versions,329,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:345,deployability,depend,dependencies,345,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:505,deployability,version,version,505,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:284,integrability,version,version,284,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:329,integrability,version,versions,329,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:345,integrability,depend,dependencies,345,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:505,integrability,version,version,505,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:284,modifiability,version,version,284,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:329,modifiability,version,versions,329,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:345,modifiability,depend,dependencies,345,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:505,modifiability,version,version,505,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:98,safety,updat,update,98,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:345,safety,depend,dependencies,345,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:98,security,updat,update,98,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:345,testability,depend,dependencies,345,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:109,usability,close,close,109,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:398,usability,help,helped,398,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:442,usability,close,close,442,"Hi @DiableJambe ,. I noticed this issue is still open from a while ago. So I want to give a quick update and close this issue. DeepVariant 0.8.0 is out yesterday. It might still not solve your original issue, but I just want to give you a heads up in case you want to try out the new version. From @qili93 's last response, many versions of the dependencies will be different now. But hopefully it helped resolved your original problem. I'll close this issue now. If you have more questions about the new version, please feel to open another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:255,deployability,Toolchain,Toolchain,255,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:286,deployability,version,version,286,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:286,integrability,version,version,286,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:286,modifiability,version,version,286,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:69,performance,time,time,69,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:90,safety,reme,remember,90,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:41,testability,understand,understand,41,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:255,usability,Tool,Toolchain,255,"@qili93 I am trying your method above. I understand it's from a long time ago, but do you remember having issues with glibc and bazel? I am running into some issues because on CentOS7 (and RHEL7 I guess?) the default system gcc is very old, while Advance Toolchain has a much newer gcc version. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:67,deployability,version,versions,67,The above issue was due to a problem with numpy compilation. Newer versions of numpy need to be compiled from source for POWER platforms.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:121,energy efficiency,POWER,POWER,121,The above issue was due to a problem with numpy compilation. Newer versions of numpy need to be compiled from source for POWER platforms.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:67,integrability,version,versions,67,The above issue was due to a problem with numpy compilation. Newer versions of numpy need to be compiled from source for POWER platforms.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:127,interoperability,platform,platforms,127,The above issue was due to a problem with numpy compilation. Newer versions of numpy need to be compiled from source for POWER platforms.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:67,modifiability,version,versions,67,The above issue was due to a problem with numpy compilation. Newer versions of numpy need to be compiled from source for POWER platforms.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/pull/125:0,usability,Close,Closed,0,Closed in favor of https://github.com/google/deepvariant/pull/126,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/125
https://github.com/google/deepvariant/issues/127:48,availability,checkpoint,checkpoints,48,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:209,availability,checkpoint,checkpoint,209,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:30,energy efficiency,load,loading,30,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:42,energy efficiency,model,model,42,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:199,energy efficiency,load,loads,199,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:105,interoperability,share,share,105,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:30,performance,load,loading,30,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:199,performance,load,loads,199,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:48,reliability,checkpoint,checkpoints,48,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:209,reliability,checkpoint,checkpoint,209,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:42,security,model,model,42,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:265,usability,help,helpful,265,"Hi Masaru,. we have not tried loading the model checkpoints this way before. Since it's a colab, can you share the colab so we can try it out as well? I might have some older colab lying around that loads the checkpoint, but probably not using Keras. Would that be helpful? If so I can try to find it again. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:168,usability,user,user,168,"Hi,. Thank you for your comments. I prepared the colab in https://colab.research.google.com/drive/1eYpUciVLEwR5YujPJ2NyH0hfRRCZ3Vg2 . Actually, I'm basically a Pytorch user and a beginner of Keras and tensorflow. . Then if i/we can use DeepVariant easily, I think it would be helpful for many users! Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:276,usability,help,helpful,276,"Hi,. Thank you for your comments. I prepared the colab in https://colab.research.google.com/drive/1eYpUciVLEwR5YujPJ2NyH0hfRRCZ3Vg2 . Actually, I'm basically a Pytorch user and a beginner of Keras and tensorflow. . Then if i/we can use DeepVariant easily, I think it would be helpful for many users! Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:293,usability,user,users,293,"Hi,. Thank you for your comments. I prepared the colab in https://colab.research.google.com/drive/1eYpUciVLEwR5YujPJ2NyH0hfRRCZ3Vg2 . Actually, I'm basically a Pytorch user and a beginner of Keras and tensorflow. . Then if i/we can use DeepVariant easily, I think it would be helpful for many users! Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:335,availability,checkpoint,checkpoint,335,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:524,availability,checkpoint,checkpoint,524,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:662,deployability,API,API,662,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1014,deployability,updat,update,1014,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:326,energy efficiency,load,load,326,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:623,energy efficiency,model,modeling,623,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:652,energy efficiency,Estimat,Estimator,652,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:774,energy efficiency,model,models,774,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:792,energy efficiency,model,model,792,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:662,integrability,API,API,662,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:662,interoperability,API,API,662,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:971,interoperability,share,share,971,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:110,performance,time,time,110,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:326,performance,load,load,326,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:335,reliability,checkpoint,checkpoint,335,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:524,reliability,checkpoint,checkpoint,524,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1014,safety,updat,update,1014,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:623,security,model,modeling,623,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:774,security,model,models,774,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:792,security,model,model,792,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:834,security,team,team,834,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1014,security,updat,update,1014,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:260,usability,help,help,260,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:738,usability,help,help,738,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:884,usability,help,helps,884,"I assign this to my self, but --. since we're not using Keras in DeepVariant, it will take a uncertain amount time for me to prioritize this on my list of things. I will also open an internal bug to track, but this is something that we likely won't be able to help with in the short term. If you want to take a look at how we load the checkpoint, you can find examples in the inference code here:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L346. And for training, in order to start from a checkpoint, you can see code in this:. https://github.com/google/deepvariant/blob/r0.7/deepvariant/modeling.py#L408. We use the Estimator API. So, another possibility to find more information for things that might help with converting any TensorFlow models to a Keras model, such as:. https://github.com/keras-team/keras/issues/5273. (I don't know if this one helps, but worth a look). I will keep this issue open for a while. Please feel free to share back if you find anything. I'll also update if I find anything useful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:310,availability,checkpoint,checkpoints,310,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:144,deployability,build,building,144,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:25,energy efficiency,current,current,25,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:168,energy efficiency,model,model,168,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:73,modifiability,paramet,parameters,73,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:310,reliability,checkpoint,checkpoints,310,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:507,safety,test,testing,507,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:168,security,model,model,168,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:33,testability,understand,understanding,33,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:507,testability,test,testing,507,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:123,usability,learn,learning,123,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:281,usability,confirm,confirmation,281,"Thank you so much. In my current understanding, if I use the pre-trained parameters for DeepVariant in Keras or other deep learning frameworks, building the equivalent model in each library is required. Anyway, I'll try which approach is the easiest for my aim. Please let another confirmation. For saving the checkpoints ""DeepVariant-inception_v3-0.7.0+data-wgs_standard"", did you used the function in this?:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/deepvariant/testing/tf_test_utils.py#L48. Best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:132,availability,checkpoint,checkpoints,132,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:337,availability,checkpoint,checkpoints,337,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:616,availability,checkpoint,checkpoint,616,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:102,deployability,API,API,102,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:92,energy efficiency,Estimat,Estimator,92,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:126,energy efficiency,model,model,126,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:175,energy efficiency,estimat,estimator,175,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:102,integrability,API,API,102,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:102,interoperability,API,API,102,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:363,interoperability,specif,specified,363,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:132,reliability,checkpoint,checkpoints,132,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:337,reliability,checkpoint,checkpoints,337,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:616,reliability,checkpoint,checkpoint,616,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:573,safety,test,test,573,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:645,safety,test,tests,645,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:126,security,model,model,126,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:573,testability,test,test,573,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:640,testability,unit,unit,640,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:645,testability,test,tests,645,"Hi @koido ,. sorry that it took me a while to get back to this again. Our training uses the Estimator API, so the place where model checkpoints are saved are actually done by estimator.train:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L227. And the location where the checkpoints are saved was specified earlier:. https://github.com/google/deepvariant/blob/c2167e7c90f016905f309f118eb3897935ee7c5f/deepvariant/model_train.py#L200. The place you pointed to was not related to the main code - it is in the test util, and it is used to create a fake checkpoint so we can do unit tests.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:114,availability,sli,slim,114,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:133,deployability,API,API,133,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:123,energy efficiency,Estimat,Estimator,123,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:133,integrability,API,API,133,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:171,integrability,topic,topic,171,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:133,interoperability,API,API,133,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:114,reliability,sli,slim,114,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:44,testability,understand,understand,44,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:94,usability,learn,learning,94,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:201,usability,user,users,201,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:213,usability,learn,learning,213,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:241,usability,close,close,241,"Hi @pichuan,. Thank you very much. I got to understand your excellent codes of deepvariant by learning tensorflow slim and Estimator API. Although I still think that this topic is very useful for many users (deep learning beginners), please close this issue if your prioritization in list of things is low. Best regards,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:106,deployability,API,API,106,"Hi Masaru,. I've filed an internal issue to track - we'll keep usability for beginners in mind for future API change.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:106,integrability,API,API,106,"Hi Masaru,. I've filed an internal issue to track - we'll keep usability for beginners in mind for future API change.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:106,interoperability,API,API,106,"Hi Masaru,. I've filed an internal issue to track - we'll keep usability for beginners in mind for future API change.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:63,usability,usab,usability,63,"Hi Masaru,. I've filed an internal issue to track - we'll keep usability for beginners in mind for future API change.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/128:254,safety,test,testdata,254,"Most likely what happens is that your BAM file (or truth file) has contig names that do not match contig names of the reference. Could you list all the arguments you used for running make_examples? Also, could you print the header of 'project-retraining/testdata/aligned_reads.bam'?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:254,testability,test,testdata,254,"Most likely what happens is that your BAM file (or truth file) has contig names that do not match contig names of the reference. Could you list all the arguments you used for running make_examples? Also, could you print the header of 'project-retraining/testdata/aligned_reads.bam'?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:482,deployability,log,logs,482,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:501,deployability,log,log,501,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:147,safety,test,testdata,147,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:205,safety,test,testdata,205,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:369,safety,test,testdata,369,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:434,safety,test,testdata,434,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:482,safety,log,logs,482,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:501,safety,log,log,501,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:482,security,log,logs,482,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:501,security,log,log,501,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:147,testability,test,testdata,147,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:205,testability,test,testdata,205,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:369,testability,test,testdata,369,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:434,testability,test,testdata,434,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:482,testability,log,logs,482,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:501,testability,log,log,501,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:16,usability,command,command,16,"@akolesnikov my command line for running make_examples was:. ```. python bin/make_examples.zip \. 	 --mode training \. 	 --ref ""project-retraining/testdata/sequence.fasta"" \. 	 --reads ""project-retraining/testdata/aligned_reads.bam"" \. 	 --examples ""project-retraining/training-examples/training_set.with_label.tfrecord.gz"" \. 	 --confident_regions ""project-retraining/testdata/variants.bed"" \. 	 --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and the header of the `aligned_reads.bam` file is:. ```. @HD	VN:1.3. @SQ	SN:NC_000913.3	LN:4639675	M5:05dc7a37701cdc6bcf154344a227983d. @RG	ID:343cd2783e	SM:c100278822550000001523007907041295	PU:m120131_103014_sidney_c100278822550000001523007907041295_s1_p0	PL:PacBio_RS	DT:2012-01-31T10:30:14. @PG	ID:/mnt/secondary/Smrtanalysis/opt/smrtanalysis/analysis/bin/SAMIO.py	VN:1.2.0.SF	CL:-b -o /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.sam -p /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/references/ecoli /mnt/secondary/Smrtanalysis/opt/smrtanalysis/common/jobs/034/034822/data/aligned_reads.cmp.h5. @CO	READS:39496. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:439,deployability,build,build-prereq,439,Let's try to output contig names from all 3 input files. In order to do that you would need to modify make_examples.py:. Insert the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) at line 488 (right before calling validate_reference_contig_coverage) in make_examples.py. You would need to clone the source code first:. ```. git clone https://github.com/google/deepvariant.git. cd deepvariant/. ./build-prereq.sh. ```. Once you modify make_exmaples.py run ./build_release_binaries.sh from deepvariant directory to rebuild binaries. Then run make_examples and check the output.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:44,safety,input,input,44,Let's try to output contig names from all 3 input files. In order to do that you would need to modify make_examples.py:. Insert the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) at line 488 (right before calling validate_reference_contig_coverage) in make_examples.py. You would need to clone the source code first:. ```. git clone https://github.com/google/deepvariant.git. cd deepvariant/. ./build-prereq.sh. ```. Once you modify make_exmaples.py run ./build_release_binaries.sh from deepvariant directory to rebuild binaries. Then run make_examples and check the output.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:95,security,modif,modify,95,Let's try to output contig names from all 3 input files. In order to do that you would need to modify make_examples.py:. Insert the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) at line 488 (right before calling validate_reference_contig_coverage) in make_examples.py. You would need to clone the source code first:. ```. git clone https://github.com/google/deepvariant.git. cd deepvariant/. ./build-prereq.sh. ```. Once you modify make_exmaples.py run ./build_release_binaries.sh from deepvariant directory to rebuild binaries. Then run make_examples and check the output.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:470,security,modif,modify,470,Let's try to output contig names from all 3 input files. In order to do that you would need to modify make_examples.py:. Insert the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) at line 488 (right before calling validate_reference_contig_coverage) in make_examples.py. You would need to clone the source code first:. ```. git clone https://github.com/google/deepvariant.git. cd deepvariant/. ./build-prereq.sh. ```. Once you modify make_exmaples.py run ./build_release_binaries.sh from deepvariant directory to rebuild binaries. Then run make_examples and check the output.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:44,usability,input,input,44,Let's try to output contig names from all 3 input files. In order to do that you would need to modify make_examples.py:. Insert the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) at line 488 (right before calling validate_reference_contig_coverage) in make_examples.py. You would need to clone the source code first:. ```. git clone https://github.com/google/deepvariant.git. cd deepvariant/. ./build-prereq.sh. ```. Once you modify make_exmaples.py run ./build_release_binaries.sh from deepvariant directory to rebuild binaries. Then run make_examples and check the output.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:9,deployability,build,build,9,Once you build new binaries make_examples.zip can be found at ./bazel-bin/deepvariant/make_examples.zip (the path is relative to your deepvariant directory),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:29,deployability,build,building,29,"@akolesnikov I struggle with building the binaries, I copied the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) but it keeps failing for some reason. Is there a way to print the contig names besides altering the `make_examples.py` script?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:169,deployability,fail,failing,169,"@akolesnikov I struggle with building the binaries, I copied the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) but it keeps failing for some reason. Is there a way to print the contig names besides altering the `make_examples.py` script?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:169,reliability,fail,failing,169,"@akolesnikov I struggle with building the binaries, I copied the code from the [gist](https://gist.github.com/akolesnikov/9a4b019e89087dc21cf9ba0b12eece00) but it keeps failing for some reason. Is there a way to print the contig names besides altering the `make_examples.py` script?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:219,availability,down,down,219,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:436,availability,ERROR,ERROR,436,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:506,availability,ERROR,ERROR,506,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:742,availability,ERROR,ERROR,742,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1082,availability,down,down,1082,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:63,deployability,build,build,63,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:577,deployability,BUILD,BUILD,577,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:714,deployability,fail,failed,714,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:724,deployability,build,build,724,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:813,deployability,BUILD,BUILD,813,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:958,deployability,FAIL,FAILED,958,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:966,deployability,Build,Build,966,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1465,deployability,Build,Build,1465,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:295,energy efficiency,Current,Current,295,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:381,energy efficiency,load,loaded,381,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1158,energy efficiency,Current,Current,1158,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1248,energy efficiency,load,loaded,1248,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:162,integrability,batch,batch,162,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1025,integrability,batch,batch,1025,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:372,modifiability,pac,packages,372,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1239,modifiability,pac,packages,1239,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:162,performance,batch,batch,162,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:381,performance,load,loaded,381,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:436,performance,ERROR,ERROR,436,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:506,performance,ERROR,ERROR,506,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:742,performance,ERROR,ERROR,742,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:880,performance,time,time,880,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1025,performance,batch,batch,1025,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1248,performance,load,loaded,1248,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1382,performance,time,time,1382,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:714,reliability,fail,failed,714,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:958,reliability,FAIL,FAILED,958,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:436,safety,ERROR,ERROR,436,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:451,safety,input,input,451,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:506,safety,ERROR,ERROR,506,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:651,safety,input,input,651,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:742,safety,ERROR,ERROR,742,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:827,safety,input,input,827,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:980,safety,compl,complete,980,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1471,safety,compl,completed,1471,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:95,security,modif,modifying,95,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:980,security,compl,complete,980,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1471,security,compl,completed,1471,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:252,usability,command,command,252,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:436,usability,ERROR,ERROR,436,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:451,usability,input,input,451,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:506,usability,ERROR,ERROR,506,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:651,usability,input,input,651,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:742,usability,ERROR,ERROR,742,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:827,usability,input,input,827,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1115,usability,command,command,1115,"@akolesnikov This is what I get in the terminal when trying to build the binaries even without modifying the `make_examples.py` file:. ```. (18:45:18) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:18) INFO: Current date is 2018-12-17. (18:45:40) INFO: Analysed target //:binaries (88 packages loaded). (18:45:40) INFO: Found 1 target... (18:45:40) ERROR: missing input file '@clif//:clif/bin/pyclif_proto'. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1: //third_party/nucleus/protos:reads_pyclif_clif_rule: missing input file '@clif//:clif/bin/pyclif_proto'. Target //:binaries failed to build. (18:45:41) ERROR: /home/moshvm/DeepVariant/deepvariant/third_party/nucleus/protos/BUILD:424:1 1 input file(s) do not exist. (18:45:41) INFO: Elapsed time: 22.910s, Critical Path: 0.43s. (18:45:41) INFO: 0 processes. (18:45:41) FAILED: Build did NOT complete successfully. (18:45:43) WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"". (18:45:43) INFO: Current date is 2018-12-17. (18:45:48) INFO: Analysed target //:licenses_zip (14 packages loaded). (18:45:48) INFO: Found 1 target... Target //:licenses_zip up-to-date:. bazel-genfiles/licenses.zip. (18:45:49) INFO: Elapsed time: 6.388s, Critical Path: 0.10s. (18:45:49) INFO: 0 processes. (18:45:49) INFO: Build completed successfully, 1 total action. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:193,deployability,contain,contain,193,"You already printed contigs for your BAM file. You have one contig there: NC_000913.3. Reference and truth files are text format so you just need to peek inside. In VCF file first lines should contain the list of contigs. Something like this:. ```. ##contig=<ID=chr1,length=248956422>. ```. Make sure that reference, VCF and BED contain contig 'NC_000913.3'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:329,deployability,contain,contain,329,"You already printed contigs for your BAM file. You have one contig there: NC_000913.3. Reference and truth files are text format so you just need to peek inside. In VCF file first lines should contain the list of contigs. Something like this:. ```. ##contig=<ID=chr1,length=248956422>. ```. Make sure that reference, VCF and BED contain contig 'NC_000913.3'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:122,interoperability,format,format,122,"You already printed contigs for your BAM file. You have one contig there: NC_000913.3. Reference and truth files are text format so you just need to peek inside. In VCF file first lines should contain the list of contigs. Something like this:. ```. ##contig=<ID=chr1,length=248956422>. ```. Make sure that reference, VCF and BED contain contig 'NC_000913.3'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:40,reliability,doe,doesn,40,"@akolesnikov I can see that my VCF file doesn't have a line that resemble the line you wrote. I attach the original `variants.vcf` and `variants.bed` files, I tried to change the name 'chr' to 'NC_000913.3' in both of them but that didn't work. Maybe I need to insert a line similar to the one you wrote to the VCF file? [variants.vcf.txt](https://github.com/google/deepvariant/files/2687815/variants.vcf.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2687816/variants.bed.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1271,deployability,log,logs,1271,"k Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assum",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1290,deployability,log,log,1290,"(that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_id",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1367,deployability,log,log,1367,"first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2791,deployability,modul,module,2791,"gnized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4003,deployability,build,build,4003,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4679,deployability,log,log,4679,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4750,deployability,log,log,4750,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2877,interoperability,platform,platform,2877,"er.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2791,modifiability,modul,module,2791,"gnized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2850,modifiability,pac,packages,2850,"0314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:584,reliability,doe,doesn,584,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:980,safety,test,testdata,980,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1036,safety,test,testdata,1036,"bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming S",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1160,safety,test,testdata,1160,"ecs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO fiel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1223,safety,test,testdata,1223," like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1271,safety,log,logs,1271,"k Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assum",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1290,safety,log,log,1290,"(that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_id",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1367,safety,log,log,1367,"first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1588,safety,test,testdata,1588,"work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraini",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1708,safety,input,inputs,1708,"ols index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1919,safety,test,testdata,1919,"ples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2364,safety,test,testdata,2364,"og` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2476,safety,test,testdata,2476," type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2595,safety,test,testdata,2595,"igned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2791,safety,modul,module,2791,"gnized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:3925,safety,input,input,3925,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4679,safety,log,log,4679,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4750,safety,log,log,4750,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1271,security,log,logs,1271,"k Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assum",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1290,security,log,log,1290,"(that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_id",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1367,security,log,log,1367,"first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4679,security,log,log,4679,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4750,security,log,log,4750,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:980,testability,test,testdata,980,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1036,testability,test,testdata,1036,"bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming S",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1160,testability,test,testdata,1160,"ecs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO fiel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1223,testability,test,testdata,1223," like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1271,testability,log,logs,1271,"k Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assum",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1290,testability,log,log,1290,"(that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_id",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1367,testability,log,log,1367,"first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1588,testability,test,testdata,1588,"work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraini",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1919,testability,test,testdata,1919,"ples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2364,testability,test,testdata,2364,"og` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2476,testability,test,testdata,2476," type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2595,testability,test,testdata,2595,"igned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2642,testability,Trace,Traceback,2642,"4:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:3783,testability,coverag,coverage,3783,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4679,testability,log,log,4679,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:4750,testability,log,log,4750,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:405,usability,help,help,405,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:609,usability,command,command,609,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:697,usability,command,command,697,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:795,usability,command,command,795,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:883,usability,command,command,883,"> In your variants.vcf.txt and variants.bed.txt contigs have name 'chr' when BAM file has contig name 'NC_000913.3'. > Contig names should match. Looking at [VCF Specs](https://samtools.github.io/hts-specs/VCFv4.2.pdf) it looks like '#contig' header is optional, but I think Nucleous library (that is used by DeepVariant to read VCF) relies on that field. @akolesnikov first, thank you very much for your help! I renamed all the contig names in the VCF and BED to ""NC_000913.3"" and added a ""##contig"" header to the VCF file, I indexed again the FASTA, BAM and BED files, but it still doesn't work. I used the command `samtools faidx sequence.fasta` to create `sequence.fasta.fai` file. I used the command `samtools index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An IN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1708,usability,input,inputs,1708,"ols index aligned_reads.bam` to create `aligned_reads.bam.bai` file. And I used the command `tabix -p vcf variants.vcf.gz` to create `variants.vcf.gz.tbi` file. This is my command line:. ```. python bin/make_examples.zip \. --mode training \. --ref ""project-retraining/testdata/sequence.fasta"" \. --reads ""project-retraining/testdata/aligned_reads.bam"" \. --examples ""project-retraining/training_examples"" \. --confident_regions ""project-retraining/testdata/variants.bed"" \. --truth_variants ""project-retraining/testdata/variants.vcf.gz"" > ""project-retraining/logs/make_examples.log"" 2>&1. ```. and I get the same ValueError as before (from `make_examples.log` file):. ```. 2018-12-18 13:54:44.725754: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.725832 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1218 13:54:44.726912 140314139805440 make_examples.py:1024] Preparing inputs. 2018-12-18 13:54:44.727156: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1218 13:54:44.727194 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. [W::hts_idx_load2] The index file is older than the data file: project-retraining/testdata/variants.vcf.gz.tbi. I1218 13:54:44.727533 140314139805440 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qt8ycuy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:3925,usability,input,input,3925,"t/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_qt8ycuy4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. I am attaching here all the files I used (the BAM file is too big so I attach only the header). [sequence.fasta.txt](https://github.com/google/deepvariant/files/2690298/sequence.fasta.txt). [sequence.fasta.fai.txt](https://github.com/google/deepvariant/files/2690309/sequence.fasta.fai.txt). [aligned_reads_header.sam.txt](https://github.com/google/deepvariant/files/2690312/aligned_reads_header.sam.txt). [variants.bed.txt](https://github.com/google/deepvariant/files/2690313/variants.bed.txt). [variants.vcf.gz](https://github.com/google/deepvariant/files/2690314/variants.vcf.gz). [make_examples.log](https://github.com/google/deepvariant/files/2690369/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:265,availability,error,errors,265,"Hi @mosh305 . I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:265,performance,error,errors,265,"Hi @mosh305 . I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:265,safety,error,errors,265,"Hi @mosh305 . I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:364,safety,input,input,364,"Hi @mosh305 . I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:70,testability,plan,planning,70,"Hi @mosh305 . I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:265,usability,error,errors,265,"Hi @mosh305 . I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:364,usability,input,input,364,"Hi @mosh305 . I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:268,availability,error,errors,268,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:510,deployability,continu,continue,510,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:268,performance,error,errors,268,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:268,safety,error,errors,268,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:367,safety,input,input,367,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:557,safety,input,input,557,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:73,testability,plan,planning,73,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:268,usability,error,errors,268,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:367,usability,input,input,367,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:557,usability,input,input,557,"> Hi @mosh305. > I quickly glanced through the files you have. If you're planning to train, the files you passed to `truth_variants` needs to have `GT` field (providing as true labels to the training examples). I'm not sure if this is the reason why you're having the errors you have. But either way, the variants.vcf.gz file you're providing here won't be the right input for `--truth_variants`. @pichuan Thank you for pointing that out, I am not so familiar with bioinformatics so I don't really know how to continue from here. Where can I find the right input for `--truth_variants` for my reference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:765,deployability,depend,depend,765,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:279,energy efficiency,model,model,279,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:360,energy efficiency,model,model-training,360,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:765,integrability,depend,depend,765,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:765,modifiability,depend,depend,765,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:530,reliability,doe,doesn,530,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:765,safety,depend,depend,765,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:279,security,model,model,279,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:360,security,model,model-training,360,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:461,testability,understand,understand,461,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:765,testability,depend,depend,765,"@pichuan My goal is to use **long reads** of E.Coli in order to evaluate the variant calling from such type of reads. Most of my knowledge on bioinformatics came from reading the [quick-start](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md) and [model training](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-model-training.md) of DeepVariant, and a little on the internet. From what you wrote to me earlier I understand there's a problem with my `truth_variant` files, since it doesn't have GT fields. In that case what I need to do next so I could run the training successfully? Do I need to find a different source for the VCF and BED files? Do I need to find new reads too? Do the `truth_variants` and `reads` depend on each other in any way? I hope this explains my situation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/129:42,deployability,log,logs,42,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:82,deployability,stage,stage,82,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:88,deployability,log,logs,88,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:42,safety,log,logs,42,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:88,safety,log,logs,88,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:42,security,log,logs,42,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:88,security,log,logs,88,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:42,testability,log,logs,42,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:88,testability,log,logs,88,"Hi Hagen,. Could you please attach worker logs located at gs://ms_bam/deep_output/stage/logs/call_variants/0?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:165,availability,sla,slash,165,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:47,energy efficiency,MODEL,MODEL,47,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:70,energy efficiency,model,models,70,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:183,energy efficiency,MODEL,MODEL,183,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:206,energy efficiency,model,models,206,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:165,reliability,sla,slash,165,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:47,security,MODEL,MODEL,47,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:70,security,model,models,70,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:183,security,MODEL,MODEL,183,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:206,security,model,models,206,It looks like the problem is with this path: . MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. try to remove last slash like this:. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/130:27,safety,accid,accident,27,No description. Created by accident?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/130
https://github.com/google/deepvariant/issues/131:168,deployability,instal,installs,168,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:213,deployability,version,version,213,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:287,deployability,updat,updated,287,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:320,deployability,version,version,320,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:339,deployability,instal,install,339,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:413,deployability,releas,release,413,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:558,deployability,version,version,558,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:641,deployability,version,version,641,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:661,deployability,releas,release,661,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:701,deployability,version,versions,701,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:213,integrability,version,version,213,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:320,integrability,version,version,320,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:558,integrability,version,version,558,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:641,integrability,version,version,641,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:701,integrability,version,versions,701,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:198,interoperability,specif,specifying,198,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:213,modifiability,version,version,213,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:320,modifiability,version,version,320,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:558,modifiability,version,version,558,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:641,modifiability,version,version,641,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:701,modifiability,version,versions,701,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:287,safety,updat,updated,287,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:287,security,updat,updated,287,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:520,security,modif,modify,520,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:618,testability,plan,plan,618,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:349,usability,user,user,349,"Hi @A-Tsai , . Thanks for reporting this. We also noticed this recently. It seems like intervaltree 3.0.0 came out on December 17. And previously our run-prereq script installs intervaltree without specifying the version. . We will take two actions here:. 1) Internally, we have already updated run-prereq.sh to pin the version:. ```. pip install --user 'intervaltree==2.1.0'. ```. This will come out in the next release. But for now, your workaround is the correct thing to do. 2) We will also look into whether we can modify our code to be using the newer version of intervaltree. If we can get 3.0 to work, we will plan to pin to a newer version in the next release. Meanwhile, the previous docker versions of DeepVariant should not be affect by this issue. So that is another option you can consider. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/132:29,deployability,build,build,29,I will take a look at how we build our Docker image and see what has changed. Thanks for reporting the issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:32,usability,feedback,feedback,32,Assigning to @nmousavi for some feedback on why this path changed.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:142,availability,error,error,142,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:13,deployability,updat,update,13,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:62,deployability,build,build,62,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:82,deployability,contain,container,82,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:177,deployability,version,versions,177,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:294,deployability,build,building,294,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:315,deployability,contain,containers,315,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:177,integrability,version,versions,177,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:177,modifiability,version,versions,177,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:142,performance,error,error,142,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:13,safety,updat,update,13,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:142,safety,error,error,142,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:13,security,updat,update,13,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:205,security,team,teams,205,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:229,security,access,access,229,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:142,usability,error,error,142,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:282,usability,support,support,282,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:334,usability,document,documentations,334,Is there any update regarding this issue? I am also trying to build a singularity container for deepvariant 0.7.2 and I am producing the same error. Will this be fixed on later versions? I assume a lot of teams don't have a root access when using HPC. It will be awesome if you add support for building singularity containers in your documentations as this will things a lot easier when using deepvariant on HPC either for calling or training.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:145,availability,ping,ping,145,"@melkerdawy Thanks for checking back. I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:259,deployability,contain,container,259,"@melkerdawy Thanks for checking back. I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:355,deployability,instal,installation,355,"@melkerdawy Thanks for checking back. I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:199,energy efficiency,current,currently,199,"@melkerdawy Thanks for checking back. I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:280,energy efficiency,current,currently,280,"@melkerdawy Thanks for checking back. I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:183,performance,time,time,183,"@melkerdawy Thanks for checking back. I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:290,testability,plan,plan,290,"@melkerdawy Thanks for checking back. I talked to @nmousavi a while ago and he didn't recall any changes, but said that he'll look into it. I'll ping him again. I can also spend some time later (I'm currently on vacation). We're not familiar with Singularity container, and don't currently plan to provide that yet. But we can certainly look into why the installation location changes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:64,deployability,updat,updates,64,@pichuan Thank you for the quick reply. I will wait for any new updates.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:64,safety,updat,updates,64,@pichuan Thank you for the quick reply. I will wait for any new updates.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:64,security,updat,updates,64,@pichuan Thank you for the quick reply. I will wait for any new updates.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:308,availability,error,error,308,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:39,deployability,contain,container,39,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:53,deployability,build,build,53,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:63,deployability,version,version,63,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:246,deployability,build,build,246,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:266,deployability,contain,container,266,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:63,integrability,version,version,63,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:114,interoperability,share,share,114,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:63,modifiability,version,version,63,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:363,modifiability,pac,packages,363,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:308,performance,error,error,308,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:308,safety,error,error,308,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:336,security,access,access,336,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:164,usability,document,documentation,164,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:214,usability,help,helpful,214,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:308,usability,error,error,308,"Also, @chrisfleisch is the singularity container you build for version 0.7.0 still working? If so, can you please share with me the definition file you used or any documentation you have about it? This can be very helpful for me as when I try to build a singularity container for 0.7.0, it gives me the same error in regards of needing access to the path of site-packages. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1779,availability,checkpoint,checkpoint,1779,"--name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2047,availability,echo,echo,2047,"-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Do",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2073,availability,down,download,2073,"c. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2676,availability,echo,echo,2676,"call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:92,deployability,version,version,92,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:145,deployability,version,version,145,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:213,deployability,modul,module,213,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:412,deployability,Instal,Install,412,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:531,deployability,contain,container,531,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:968,deployability,contain,container,968,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1032,deployability,build,build,1032,"is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2888,deployability,updat,update,2888,"\. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2906,deployability,instal,install,2906,"/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postproce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:427,energy efficiency,Cloud,Cloud,427,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1791,energy efficiency,model,models,1791,"istry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1802,energy efficiency,model,model,1802,"try:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2100,energy efficiency,model,models,2100,"/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2321,energy efficiency,model,models,2321,"il cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2643,energy efficiency,cloud,cloud-sdk,2643,"ts. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2702,energy efficiency,cloud,cloud,2702,"call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2785,energy efficiency,cloud,cloud-sdk,2785,"/models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval &",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2823,energy efficiency,cloud,cloud,2823,"process_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2924,energy efficiency,cloud,cloud-sdk,2924,"ittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4004,energy efficiency,model,models,4004,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4026,energy efficiency,model,models,4026,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4298,energy efficiency,model,models,4298,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4384,energy efficiency,model,models,4384,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4478,energy efficiency,model,models,4478,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4527,energy efficiency,model,models,4527,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:92,integrability,version,version,92,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:145,integrability,version,version,145,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:791,interoperability,registr,registry,791,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:800,interoperability,registr,registry,800,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2228,interoperability,bind,bind,2228,"BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2432,interoperability,bind,bind,2432,"ling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:92,modifiability,version,version,92,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:145,modifiability,version,version,145,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:213,modifiability,modul,module,213,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2228,modifiability,bind,bind,2228,"BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2432,modifiability,bind,bind,2432,"ling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2693,modifiability,pac,packages,2693,"outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2814,modifiability,pac,packages,2814,"run postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2934,performance,parallel,parallel,2934,"sta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1779,reliability,checkpoint,checkpoint,1779,"--name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:213,safety,modul,module,213,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1291,safety,test,testdata,1291,"rom: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1313,safety,input,input,1313,"0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, map",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1350,safety,input,input,1350,".github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app ca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1453,safety,input,input,1453,", then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1509,safety,input,input,1509," a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # htt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1905,safety,input,input,1905,"cker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2090,safety,input,input,2090," PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. pr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2202,safety,input,inputs,2202,"pprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2233,safety,input,input,2233,"=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. print",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2244,safety,input,input,2244,"variant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2437,safety,input,input,2437,". --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2448,safety,input,input,2448,"2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postproces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2888,safety,updat,update,2888,"\. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:326,security,Modif,Modified,326,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1791,security,model,models,1791,"istry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1802,security,model,model,1802,"try:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2100,security,model,models,2100,"/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2321,security,model,models,2321,"il cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2719,security,apt,apt,2719,"tput.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2759,security,apt,apt,2759,"les.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2840,security,apt,apt,2840,". exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2848,security,apt,apt-key,2848,"t/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2862,security,apt,apt-key,2862,"bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/cal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2877,security,apt,apt-get,2877,"_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2888,security,updat,update,2888,"\. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2898,security,apt,apt-get,2898,"v2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2965,security,apt,apt,2965,"nts_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4004,security,model,models,4004,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4026,security,model,models,4026,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4298,security,model,models,4298,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4384,security,model,models,4384,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4478,security,model,models,4478,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:4527,security,model,models,4527,"ant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_train.zip ""$@""' > \. /opt/deepvariant/bin/model_train && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/model_eval.zip ""$@""' > \. /opt/deepvariant/bin/model_eval && \. chmod +x /opt/deepvariant/bin/make_examples \. /opt/deepvariant/bin/call_variants \. /opt/deepvariant/bin/postprocess_variants \. /opt/deepvariant/bin/model_train \. /opt/deepvariant/bin/model_eval. mkdir -p /models/wgs. mkdir -p /models/wes. BIN_VERSION=""0.7.0"". MODEL_VERSION=$BIN_VERSION. BUCKET=""gs://deepvariant"". MODEL_NAME_WGS=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wgs_standard"". MODEL_NAME_WES=""DeepVariant-inception_v3-${MODEL_VERSION}+data-wes_standard"". MODEL_BUCKET_WGS=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WGS}/*"". MODEL_BUCKET_WES=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/${MODEL_NAME_WES}/*"". gsutil cp -R ""${MODEL_BUCKET_WGS}"" /models/wgs/. gsutil cp -R ""${MODEL_BUCKET_WES}"" /models/wes/. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1291,testability,test,testdata,1291,"rom: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1475,testability,unit,unittest,1475,"official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_varian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1927,testability,unit,unittest,1927,"eepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:452,usability,tool,tool,452,"I'm using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:997,usability,custom,customized,997,"m using Singularity 2.6.0. Below is what I've been using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1050,usability,custom,custom,1050,"using for my Singularity.spec file for version 0.7.0 which still works for me. Changing the version number of DeepVariant to 0.7.2 gives me the ImportError: No module named numpy when trying to run make_examples. ```. Bootstrap: localimage. From: deepvariant-0.7.0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1313,usability,input,input,1313,"0.simg. # Modified from: https://gist.github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, map",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1350,usability,input,input,1350,".github.com/pansapiens/717efcdefb51fa0ce1a6abf092bcb2f4. # Install Google Cloud SDK for the gcloud tool, then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app ca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1453,usability,input,input,1453,", then:. # We grab the official Docker image, push it to a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1509,usability,input,input,1509," a locally running container repo, then get. # Singularity to pull it back. # docker pull gcr.io/deepvariant-docker/deepvariant:0.7.0. # docker tag gcr.io/deepvariant-docker/deepvariant:0.7.0 localhost:5000/deepvariant:0.7.0. # docker run -d -p 5000:5000 --restart=always --name registry registry:2. # docker push localhost:5000/deepvariant:0.7.0. # sudo SINGULARITY_NOHTTPS=1 singularity pull docker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # htt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1905,usability,input,input,1905,"cker://localhost:5000/deepvariant:0.7.0. #. # Then use that container image to make this customized one. # sudo singularity build deepvariant-custom.simg Singularity.spec. %environment. PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2090,usability,input,input,2090," PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. DV_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. pr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2160,usability,custom,custom,2160,"_GPU_BUILD=0. export PATH DV_GPU_BUILD. %apprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/ma",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2202,usability,input,inputs,2202,"pprun download_testdata. BUCKET=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2233,usability,input,input,2233,"=""gs://deepvariant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. print",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2244,usability,input,input,2244,"variant"". DATA_BUCKET=""${BUCKET}/quickstart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2283,usability,custom,custom,2283,"tart-testdata/*"". mkdir -p input. gsutil cp -R ""${DATA_BUCKET}"" input/. %apprun make_examples. exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2377,usability,custom,custom,2377," exec /opt/deepvariant/bin/make_examples \. --mode calling \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2437,usability,input,input,2437,". --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2448,usability,input,input,2448,"2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postproces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2494,usability,custom,custom,2494,"-reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. --examples output.examples.tfrecord \. --regions ""chr20:10,000,000-10,010,000"". %apprun call_variants. exec /opt/deepvariant/bin/call_variants \. --outfile call_variants_output.tfrecord \. --examples output.examples.tfrecord \. --checkpoint /models/wgs/model.ckpt. %apprun postprocess_variants. exec /opt/deepvariant/bin/postprocess_variants \. --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. --infile call_variants_output.tfrecord \. --outfile output.vcf. %runscript. if [ $# -eq 0 ]; then. echo '''Example Usage:. # download data to input and models. singularity run --app download_testdata deepvariant-custom.simg. # make the examples, mapping inputs. singularity run --bind input:/dv2/input/ --app make_examples deepvariant-custom.simg. # call variants, mapping models. singularity run --app call_variants deepvariant-custom.simg. # postprocess variants. singularity run --bind input:/dv2/input/ --app postprocess_variants deepvariant-custom.simg. # https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md. '''. else. exec ""$@"". fi. %post. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get -y update && apt-get install -y google-cloud-sdk parallel wget. rm -rf /var/lib/apt/lists/*. # https://github.com/google/deepvariant/blob/r0.5/deepvariant/docker/Dockerfile. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/make_examples.zip ""$@""' > \. /opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/call_variants.zip ""$@""' > \. /opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. ""${BASH_HEADER}"" \. 'python /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. /opt/deepvariant/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:174,interoperability,share,share,174,@chrisfleisch this is really awesome! thanks a lot. you made my life a lot easier now :D . I will try to modify this definition file to be working on training too and I will share it here. maybe it will help somebody with the same problem I am having.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:105,security,modif,modify,105,@chrisfleisch this is really awesome! thanks a lot. you made my life a lot easier now :D . I will try to modify this definition file to be working on training too and I will share it here. maybe it will help somebody with the same problem I am having.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:203,usability,help,help,203,@chrisfleisch this is really awesome! thanks a lot. you made my life a lot easier now :D . I will try to modify this definition file to be working on training too and I will share it here. maybe it will help somebody with the same problem I am having.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:173,integrability,topic,topic,173,"This is a singularity's issue, which has been reported for other docker images. It looks like there is a workaround for it. See. https://groups.google.com/a/lbl.gov/forum/#!topic/singularity/NBNpB_2i7Hc. Regardless, the solution or fix for this issue should be sought within singularity, and not DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:75,availability,operat,operating,75,"Singularity recommends to install packages, programs, data, and files into operating system locations (e.g. not /home, /tmp , or any other directories that might get commonly binded on (like /root)). It would be great if the DeepVariant container would work nicely with Singularity in this way.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:26,deployability,instal,install,26,"Singularity recommends to install packages, programs, data, and files into operating system locations (e.g. not /home, /tmp , or any other directories that might get commonly binded on (like /root)). It would be great if the DeepVariant container would work nicely with Singularity in this way.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:237,deployability,contain,container,237,"Singularity recommends to install packages, programs, data, and files into operating system locations (e.g. not /home, /tmp , or any other directories that might get commonly binded on (like /root)). It would be great if the DeepVariant container would work nicely with Singularity in this way.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:175,interoperability,bind,binded,175,"Singularity recommends to install packages, programs, data, and files into operating system locations (e.g. not /home, /tmp , or any other directories that might get commonly binded on (like /root)). It would be great if the DeepVariant container would work nicely with Singularity in this way.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:34,modifiability,pac,packages,34,"Singularity recommends to install packages, programs, data, and files into operating system locations (e.g. not /home, /tmp , or any other directories that might get commonly binded on (like /root)). It would be great if the DeepVariant container would work nicely with Singularity in this way.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:175,modifiability,bind,binded,175,"Singularity recommends to install packages, programs, data, and files into operating system locations (e.g. not /home, /tmp , or any other directories that might get commonly binded on (like /root)). It would be great if the DeepVariant container would work nicely with Singularity in this way.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:201,deployability,build,build,201,"Thanks @nmousavi @chrisfleisch @melkerdawy . For now, please see if the workaround that @nmousavi suggested can be used. @chrisfleisch I'm actually already planning to take a closer look at the way we build the docker image. Thanks for your feedback. I will take this into account when I do that. I'll add the information in your last comment to our internal tracking bug. Note that this might be a little low on my priority list. But I'll try to get to it soon, and I might check back with you directly to make sure things work for you. I'll leave this GitHub issue open!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:156,testability,plan,planning,156,"Thanks @nmousavi @chrisfleisch @melkerdawy . For now, please see if the workaround that @nmousavi suggested can be used. @chrisfleisch I'm actually already planning to take a closer look at the way we build the docker image. Thanks for your feedback. I will take this into account when I do that. I'll add the information in your last comment to our internal tracking bug. Note that this might be a little low on my priority list. But I'll try to get to it soon, and I might check back with you directly to make sure things work for you. I'll leave this GitHub issue open!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:175,usability,close,closer,175,"Thanks @nmousavi @chrisfleisch @melkerdawy . For now, please see if the workaround that @nmousavi suggested can be used. @chrisfleisch I'm actually already planning to take a closer look at the way we build the docker image. Thanks for your feedback. I will take this into account when I do that. I'll add the information in your last comment to our internal tracking bug. Note that this might be a little low on my priority list. But I'll try to get to it soon, and I might check back with you directly to make sure things work for you. I'll leave this GitHub issue open!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:241,usability,feedback,feedback,241,"Thanks @nmousavi @chrisfleisch @melkerdawy . For now, please see if the workaround that @nmousavi suggested can be used. @chrisfleisch I'm actually already planning to take a closer look at the way we build the docker image. Thanks for your feedback. I will take this into account when I do that. I'll add the information in your last comment to our internal tracking bug. Note that this might be a little low on my priority list. But I'll try to get to it soon, and I might check back with you directly to make sure things work for you. I'll leave this GitHub issue open!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:52,deployability,Instal,Install,52,"I think the easiest way to do it is as follows:. 1. Install VirtualBox on your laptop, then Ubuntu, then Docker. 2. Pull the DeepVariant image, and then follow the instructions at the following link on how to modify the image and committing it:. https://www.techrepublic.com/article/how-to-commit-changes-to-a-docker-image/. 3. Perform `docker save` to be able to transfer it so you can convert it to a Singularity image - with a link provided below on how to use `docker save`:. https://docs.docker.com/engine/reference/commandline/save/. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:328,performance,Perform,Perform,328,"I think the easiest way to do it is as follows:. 1. Install VirtualBox on your laptop, then Ubuntu, then Docker. 2. Pull the DeepVariant image, and then follow the instructions at the following link on how to modify the image and committing it:. https://www.techrepublic.com/article/how-to-commit-changes-to-a-docker-image/. 3. Perform `docker save` to be able to transfer it so you can convert it to a Singularity image - with a link provided below on how to use `docker save`:. https://docs.docker.com/engine/reference/commandline/save/. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:209,security,modif,modify,209,"I think the easiest way to do it is as follows:. 1. Install VirtualBox on your laptop, then Ubuntu, then Docker. 2. Pull the DeepVariant image, and then follow the instructions at the following link on how to modify the image and committing it:. https://www.techrepublic.com/article/how-to-commit-changes-to-a-docker-image/. 3. Perform `docker save` to be able to transfer it so you can convert it to a Singularity image - with a link provided below on how to use `docker save`:. https://docs.docker.com/engine/reference/commandline/save/. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:328,usability,Perform,Perform,328,"I think the easiest way to do it is as follows:. 1. Install VirtualBox on your laptop, then Ubuntu, then Docker. 2. Pull the DeepVariant image, and then follow the instructions at the following link on how to modify the image and committing it:. https://www.techrepublic.com/article/how-to-commit-changes-to-a-docker-image/. 3. Perform `docker save` to be able to transfer it so you can convert it to a Singularity image - with a link provided below on how to use `docker save`:. https://docs.docker.com/engine/reference/commandline/save/. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:521,usability,command,commandline,521,"I think the easiest way to do it is as follows:. 1. Install VirtualBox on your laptop, then Ubuntu, then Docker. 2. Pull the DeepVariant image, and then follow the instructions at the following link on how to modify the image and committing it:. https://www.techrepublic.com/article/how-to-commit-changes-to-a-docker-image/. 3. Perform `docker save` to be able to transfer it so you can convert it to a Singularity image - with a link provided below on how to use `docker save`:. https://docs.docker.com/engine/reference/commandline/save/. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:548,usability,help,helps,548,"I think the easiest way to do it is as follows:. 1. Install VirtualBox on your laptop, then Ubuntu, then Docker. 2. Pull the DeepVariant image, and then follow the instructions at the following link on how to modify the image and committing it:. https://www.techrepublic.com/article/how-to-commit-changes-to-a-docker-image/. 3. Perform `docker save` to be able to transfer it so you can convert it to a Singularity image - with a link provided below on how to use `docker save`:. https://docs.docker.com/engine/reference/commandline/save/. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:249,deployability,instal,install,249,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:321,deployability,observ,observed,321,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:347,deployability,releas,release,347,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:405,deployability,instal,install,405,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:591,interoperability,convers,conversion,591,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:457,safety,test,tested,457,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:321,testability,observ,observed,321,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:364,testability,plan,plan,364,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:457,testability,test,tested,457,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:557,testability,plan,plan,557,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:236,usability,user,user,236,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:272,usability,user,user,272,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:421,usability,user,user,421,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:436,usability,user,user,436,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:565,usability,document,document,565,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:725,usability,close,close,725,"Hi @chrisfleisch . I want to follow up on this issue. The path change earlier was actually due to this commit back in Oct 2018:. https://github.com/google/deepvariant/commit/f3207bb2e4db50f858343b97fa8bdec0fb908ab7. Because we added `--user` to pip install (even when the user is root), that's what caused the change you observed. In our upcoming release, we will plan to change this so that we won't pip install with `--user` when the user is root, I have tested internally that our new docker image will be convertible to a singularity image. I will also plan to document the steps of the conversion, which is basically what you mentioned in in earlier comment in this thread. Thank you for pointing out this issue. I will close this issue now. When v0.8.0 comes out, if you're still encountering any issues, please feel free to file another issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:24,deployability,releas,released,24,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:179,deployability,build,build,179,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:625,deployability,build,building,625,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:730,deployability,instal,install,730,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:777,deployability,instal,install-linux,777,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1225,deployability,build,build,1225,"on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1940,deployability,contain,containers,1940,"er/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2370,deployability,build,build,2370,"ant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning: escape sequence `\.' treated as plain `.'. ```. messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:669,energy efficiency,CPU,CPU,669,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:677,energy efficiency,GPU,GPU,677,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:889,energy efficiency,CPU,CPU,889,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1990,energy efficiency,GPU,GPU,1990,"epvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:3041,integrability,messag,messages,3041,"ant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning: escape sequence `\.' treated as plain `.'. ```. messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1118,interoperability,registr,registry,1118,"personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1127,interoperability,registr,registry,1127,"notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/dee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2252,interoperability,registr,registry,2252,"ant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning: escape sequence `\.' treated as plain `.'. ```. messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2261,interoperability,registr,registry,2261,"ant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning: escape sequence `\.' treated as plain `.'. ```. messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:3041,interoperability,messag,messages,3041,"ant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning: escape sequence `\.' treated as plain `.'. ```. messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:55,performance,time,time,55,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:669,performance,CPU,CPU,669,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:677,performance,GPU,GPU,677,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:889,performance,CPU,CPU,889,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1990,performance,GPU,GPU,1990,"epvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:344,reliability,doe,doesn,344,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:520,security,team,team,520,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1652,testability,unit,unittest,1652,"y images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_ty",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2701,testability,unit,unittest,2701,"ant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_gpu.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. I do see this issue though:. https://github.com/sylabs/singularity/issues/1916. with the. ```. awk: warning: escape sequence `\.' treated as plain `.'. ```. messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:122,usability,person,personal,122,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:311,usability,feedback,feedback,311,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:426,usability,user,users,426,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:563,usability,support,support,563,"@chrisfleisch . We have released v0.8.0 today :). This time, I made sure to try out Singularity as well. Here are some my personal notes when I tried to pull our Docker image and build Singularity image, based on the suggestion on your comment above. I'm still new to Singularity, so I'd really appreciate more feedback if any of the following doesn't make sense, or if any of these can be improved to be more similar to what users are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1428,usability,command,command,1428,"are used to. Once this becomes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1454,usability,command,command,1454,"omes more mature (and if they become a popular use case), our team can consider adding them for official support in the future as well. ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU. If you don't have singularity on your computer, install it first:. https://singularity.lbl.gov/install-linux. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. sudo docker pull gcr.io/deepvariant-docker/deepvariant:0.8.0. sudo docker tag gcr.io/deepvariant-docker/deepvariant:0.8.0 localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. (The extra flags for singularity was added because of the locale issue: https://github.com/BioContainers/containers/issues/206#issuecomment-448698033). ## GPU image. ```. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:0.8.0 localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant_gpu.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:569,availability,echo,echo,569,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:856,availability,restor,restorecon,856,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1193,availability,echo,echo,1193,"https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1244,availability,echo,echo,1244,"suecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:26,deployability,releas,release,26,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:319,deployability,instal,installing,319,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:431,deployability,instal,install,431,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:462,deployability,updat,update,462,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:513,deployability,instal,install,513,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:561,deployability,releas,release,561,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:734,deployability,instal,install,734,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1001,deployability,instal,install,1001,"verted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. sin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1075,deployability,instal,install,1075,"ean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1091,deployability,releas,release,1091,"plet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:lat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1114,deployability,instal,install,1114," case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1342,deployability,instal,install,1342,"ocker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1620,deployability,build,builddir,1620,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1656,deployability,instal,install,1656,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2014,deployability,build,build,2014,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2480,deployability,build,build,2480,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1699,energy efficiency,CPU,CPU,1699,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2121,energy efficiency,GPU,GPU,2121,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:392,interoperability,specif,specific,392,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:536,interoperability,distribut,distribution,536,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:642,interoperability,distribut,distribution,642,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1929,interoperability,registr,registry,1929,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1938,interoperability,registr,registry,1938,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2384,interoperability,registr,registry,2384,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2393,interoperability,registr,registry,2393,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:381,modifiability,paramet,parameters,381,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1699,performance,CPU,CPU,1699,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2121,performance,GPU,GPU,2121,$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER}. sudo nvidia-docker tag gcr.io/deepvariant-docker/deepvariant_gpu:${DVVER} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. singularity build --nohttps deepvariant_gpu.${DVVER}.simg docker://localhost:5000/deepvariant_gpu:latest. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:856,reliability,restor,restorecon,856,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:462,safety,updat,update,462,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:462,security,updat,update,462,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:954,usability,statu,status,954,"I converted the new 0.8.0 release docker to a singularity image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1053,usability,Tool,Tools,1053,"y image on a Digital Ocean Centos 7 droplet and took notes, in case it's useful to anyone else. The instructions were based on [the notes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1186,usability,tool,tools,1186,"otes](https://github.com/google/deepvariant/issues/132#issuecomment-482430728) from @pichuan above, but includes instructions for installing docker, nvidia-docker, and singularity, as well as parameters specific to singularity v3.1.1. ```. # install docker. sudo yum check-update. curl -fsSL https://get.docker.com/ | sh. # install nvidia-docker. distribution=$(. /etc/os-release;echo $ID$VERSION_ID). curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \. sudo tee /etc/yum.repos.d/nvidia-docker.repo. sudo yum install -y nvidia-docker2. semanage fcontext -a -f f -t container_runtime_exec_t -s system_u /usr/bin/nvidia-docker. sudo restorecon -v /usr/bin/nvidia-docker. # start docker. sudo systemctl start docker. sudo systemctl status docker. sudo systemctl enable docker. # install deps. sudo yum groupinstall -y 'Development Tools' && \. sudo yum install -y epel-release && \. sudo yum install -y golang openssl-devel libuuid-devel libseccomp-devel squashfs-tools. echo 'export GOPATH=${HOME}/go' >> ~/.bashrc && \. echo 'export PATH=/usr/local/go/bin:${PATH}:${GOPATH}/bin' >> ~/.bashrc && \. source ~/.bashrc. # install singularity. mkdir -p ${GOPATH}/src/github.com/sylabs && \. cd ${GOPATH}/src/github.com/sylabs && \. git clone https://github.com/sylabs/singularity.git && \. cd singularity. git checkout v3.1.1. cd ${GOPATH}/src/github.com/sylabs/singularity && \. ./mconfig && \. cd ./builddir && \. make && \. sudo make install. . DVVER=0.8.0. # make deepvariant CPU image. sudo docker pull gcr.io/deepvariant-docker/deepvariant:${DVVER}. sudo docker tag gcr.io/deepvariant-docker/deepvariant:${DVVER} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. singularity build --nohttps deepvariant.${DVVER}.simg docker://localhost:5000/deepvariant:latest. . # make deepvariant GPU image. sudo nvidia-docker pull gcr.io/deepvariant-docker/deepvar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:35,usability,help,helpful,35,"@williamrowell WOW, this is really helpful! THANK YOU very much!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:210,availability,error,error,210,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1287,deployability,log,login,1287,"mg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1560,deployability,modul,module,1560,"e command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buff",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1608,deployability,modul,module,1608,"ne-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode cal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1682,deployability,fail,failed,1682,"18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-tes",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1730,deployability,fail,failed,1730,"art-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1828,deployability,fail,failed,1828,"awy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2015,deployability,modul,module,2015,"nt_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:13,energy efficiency,CPU,CPU,13,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1273,energy efficiency,Power,Power,1273,"deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1659,energy efficiency,core,core,1659,"e calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1719,energy efficiency,core,core,1719,"dawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1800,energy efficiency,core,core,1800,"ch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:614,integrability,buffer,buffer,614,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1197,integrability,pub,publication,1197,"t this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2311,integrability,sub,subprocess,2311,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2404,integrability,sub,subprocess,2404,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2485,integrability,sub,subprocess,2485,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2559,integrability,buffer,buffer,2559,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1560,modifiability,modul,module,1560,"e command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buff",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1608,modifiability,modul,module,1608,"ne-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode cal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2015,modifiability,modul,module,2015,"nt_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2075,modifiability,pac,packages,2075,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2175,modifiability,pac,packages,2175,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:13,performance,CPU,CPU,13,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:210,performance,error,error,210,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:580,performance,time,time,580,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:595,performance,parallel,parallel,595,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1168,performance,Parallel,Parallel,1168,"ot have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1245,performance,Parallel,Parallel,1245,"b/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1459,performance,Parallel,Parallel,1459,"20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1522,performance,parallel,parallel,1522,"vcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 't",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2525,performance,time,time,2525,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2540,performance,parallel,parallel,2540,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1682,reliability,fail,failed,1682,"18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-tes",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1730,reliability,fail,failed,1730,"art-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1828,reliability,fail,failed,1828,"awy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:210,safety,error,error,210,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:737,safety,test,testdata,737,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:846,safety,test,testdata,846,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1287,safety,log,login,1287,"mg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1560,safety,modul,module,1560,"e command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buff",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1608,safety,modul,module,1608,"ne-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode cal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2015,safety,modul,module,2015,"nt_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2682,safety,test,testdata,2682,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2791,safety,test,testdata,2791,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:185,security,privil,privileges,185,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1260,security,Command-Lin,Command-Line,1260,"b/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1287,security,log,login,1287,"mg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:382,testability,unit,unittest,382,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:737,testability,test,testdata,737,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:762,testability,unit,unittest,762,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:846,testability,test,testdata,846,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1287,testability,log,login,1287,"mg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1917,testability,Trace,Traceback,1917,"tput/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2682,testability,test,testdata,2682,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2707,testability,unit,unittest,2707,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2791,testability,test,testdata,2791,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:210,usability,error,error,210,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:565,usability,command,command,565,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:696,usability,user,users,696,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:805,usability,user,users,805,"We created a CPU image on an Amazon instance as described here and the example code was running fine. Then we tried to use the same image on a super computer (where we do not have root privileges), we get this error: . singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1260,usability,Command,Command-Line,1260,"b/locale/ deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1279,usability,Tool,Tool,1279,"ariant.simg /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1341,usability,help,helps,1341,"GS --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=output.vcf.gz --output_gvcf=output.g.vcf.gz. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:1888,usability,user,user,1888,"xamples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfre",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2333,usability,command,command,2333,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2516,usability,Command,Command,2516,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2641,usability,user,users,2641,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:2750,usability,user,users,2750,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:3031,usability,statu,status,3031,"record@1.gz"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2019-04-14 11:40:35.568961: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real 0m2.359s. user 0m0.767s. sys 0m0.949s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/mnt/gs18/scratch/users/mansourt/Tamer2/kerdawy/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:248,deployability,version,version,248,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:317,deployability,version,version,317,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:341,deployability,version,version,341,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:248,integrability,version,version,248,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:317,integrability,version,version,317,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:341,integrability,version,version,341,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:248,modifiability,version,version,248,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:317,modifiability,version,version,317,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:341,modifiability,version,version,341,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:92,safety,permiss,permission,92,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:136,safety,test,test,136,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:136,testability,test,test,136,"@drtamermansour I have not tried saving an image and running it somewhere I don't have root permission. I'll have to think about how to test that better. But before I do that, can I have you provide a few more information, such as:. What is the OS version of the super computer you're on, and what is the singularity version (`singularity --version`) on your AWS machine and your super computer? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:99,deployability,releas,release,99,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:121,deployability,Version,Version,121,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:178,deployability,version,version,178,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:277,deployability,version,version,277,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:130,energy efficiency,core,core-,130,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:145,energy efficiency,core,core-,145,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:121,integrability,Version,Version,121,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:178,integrability,version,version,178,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:277,integrability,version,version,277,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:121,modifiability,Version,Version,121,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:178,modifiability,version,version,178,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:277,modifiability,version,version,277,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:34,performance,time,time,34,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:42,usability,help,help,42,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:316,usability,help,help,316,@pichuan Thank you for taking the time to help on this . The super computer has an OS CentOS Linux release 7.6.1810 (LSB Version: core-4.1-amd64:core-4.1-noarch) and singularity version 2.5.2. I created the image on Amazon instance with Ubuntu 16.04. I tried using singularity version 2.5.2 & 2.6.0 but both did not help,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/133:335,deployability,configurat,configuration-file-for-each,335,"Hi Masaru,. It looks like you're using DirectRunner, which is fine for smaller datasets, but when we have larger datasets we instead use DataflowRunner (see where we shuffle training set [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each)). In the Case Study, the DirectRunner is used for the small validation set and DataflowRunner is used for the large training set. The fact that it works when you split up the data into smaller pieces suggests this may be the issue. Please try running with DataflowRunner and let me know if that works for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:335,integrability,configur,configuration-file-for-each,335,"Hi Masaru,. It looks like you're using DirectRunner, which is fine for smaller datasets, but when we have larger datasets we instead use DataflowRunner (see where we shuffle training set [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each)). In the Case Study, the DirectRunner is used for the small validation set and DataflowRunner is used for the large training set. The fact that it works when you split up the data into smaller pieces suggests this may be the issue. Please try running with DataflowRunner and let me know if that works for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:335,modifiability,configur,configuration-file-for-each,335,"Hi Masaru,. It looks like you're using DirectRunner, which is fine for smaller datasets, but when we have larger datasets we instead use DataflowRunner (see where we shuffle training set [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each)). In the Case Study, the DirectRunner is used for the small validation set and DataflowRunner is used for the large training set. The fact that it works when you split up the data into smaller pieces suggests this may be the issue. Please try running with DataflowRunner and let me know if that works for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:424,safety,valid,validation,424,"Hi Masaru,. It looks like you're using DirectRunner, which is fine for smaller datasets, but when we have larger datasets we instead use DataflowRunner (see where we shuffle training set [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each)). In the Case Study, the DirectRunner is used for the small validation set and DataflowRunner is used for the large training set. The fact that it works when you split up the data into smaller pieces suggests this may be the issue. Please try running with DataflowRunner and let me know if that works for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:335,security,configur,configuration-file-for-each,335,"Hi Masaru,. It looks like you're using DirectRunner, which is fine for smaller datasets, but when we have larger datasets we instead use DataflowRunner (see where we shuffle training set [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each)). In the Case Study, the DirectRunner is used for the small validation set and DataflowRunner is used for the large training set. The fact that it works when you split up the data into smaller pieces suggests this may be the issue. Please try running with DataflowRunner and let me know if that works for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:424,security,validat,validation,424,"Hi Masaru,. It looks like you're using DirectRunner, which is fine for smaller datasets, but when we have larger datasets we instead use DataflowRunner (see where we shuffle training set [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each)). In the Case Study, the DirectRunner is used for the small validation set and DataflowRunner is used for the large training set. The fact that it works when you split up the data into smaller pieces suggests this may be the issue. Please try running with DataflowRunner and let me know if that works for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:205,availability,servic,service,205,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:293,availability,avail,available,293,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:197,deployability,manag,managed,197,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:205,deployability,servic,service,205,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:173,energy efficiency,Cloud,Cloud,173,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:197,energy efficiency,manag,managed,197,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:227,energy efficiency,Cloud,Cloud,227,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:318,energy efficiency,Cloud,Cloud,318,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:205,integrability,servic,service,205,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:233,interoperability,Platform,Platform,233,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:324,interoperability,Platform,Platform,324,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:205,modifiability,servic,service,205,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:191,reliability,fully manag,fully managed,191,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:293,reliability,availab,available,293,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:197,safety,manag,managed,197,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:293,safety,avail,available,293,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:293,security,availab,available,293,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:117,usability,document,documentation,117,"Hi Sidharth,. Thanks for your kind comments. I understood what is wrong. However, this page (https://beam.apache.org/documentation/) says:. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service within Google Cloud Platform. Then, are your scripts for shuffling training set available only in Google Cloud Platform? Best,. Masaru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:750,availability,servic,service,750,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:843,availability,avail,available,843,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:144,deployability,infrastructur,infrastructures,144,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:742,deployability,manag,managed,742,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:750,deployability,servic,service,750,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:225,energy efficiency,Cloud,Cloud,225,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:272,energy efficiency,Cloud,Cloud,272,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:718,energy efficiency,Cloud,Cloud,718,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:742,energy efficiency,manag,managed,742,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:775,energy efficiency,Cloud,Cloud,775,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:871,energy efficiency,Cloud,Cloud,871,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:750,integrability,servic,service,750,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:961,integrability,sub,subscribed,961,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:781,interoperability,Platform,Platform,781,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:877,interoperability,Platform,Platform,877,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:750,modifiability,servic,service,750,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:736,reliability,fully manag,fully managed,736,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:843,reliability,availab,available,843,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:742,safety,manag,managed,742,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:843,safety,avail,available,843,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:843,security,availab,available,843,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1187,security,auth,auth,1187,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:659,usability,document,documentation,659,"Hi,. On the same page , it also mentioned other runners such as SparkRunner. Our shuffling script uses Apache Beam, which can run on different. infrastructures such as Spark or Dataflow, and is not only restricted to. Google Cloud. However, our example was done on Google Cloud. You can set it. up on different things to run. If you're running on smaller amount of examples where your machine can. handle, it is possible to use DirectRunner. (from my phone). On Sun, Jan 6, 2019, 9:00 PM koido <notifications@github.com wrote:. > Hi Sidharth,. >. > Thanks for your kind comments. > I understood what is wrong. >. > However, this page (https://beam.apache.org/documentation/) says:. >. > DataflowRunner: Runs on Google Cloud Dataflow, a fully managed service. > within Google Cloud Platform. > Then, are your scripts for shuffling training set available only in Google. > Cloud Platform? >. > Best,. >. > Masaru. >. > . > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/133#issuecomment-451807897>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBRjGrR7u5rRQIM66vEHMYO6Wl_nUks5vArhcgaJpZM4Zg_qa>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/134:22,availability,down,down,22,I tracked the problem down to building with bazel 0.19.0 rather that 0.15.0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:30,deployability,build,building,30,I tracked the problem down to building with bazel 0.19.0 rather that 0.15.0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/135:1203,availability,state,states,1203,"y lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biot",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1239,availability,state,state,1239,"lter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recomm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1586,availability,error,error,1586,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1836,availability,sli,slightly,1836,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1949,availability,sli,slightly,1949,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:705,deployability,version,version,705,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1470,deployability,observ,observation,1470,"ity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1703,deployability,observ,observation,1703,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1148,energy efficiency,estimat,estimates,1148,"ion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:240,integrability,filter,filter,240,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:705,integrability,version,version,705,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1203,integrability,state,states,1203,"y lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biot",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1239,integrability,state,state,1239,"lter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recomm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1455,integrability,filter,filtering,1455,"ditional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2077,integrability,filter,filtering,2077,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1777,interoperability,distribut,distributed,1777,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2497,interoperability,share,shared,2497,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:705,modifiability,version,version,705,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:35,performance,time,time,35,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:595,performance,perform,performs,595,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:751,performance,perform,performed,751,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1113,performance,network,network,1113,"e some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1586,performance,error,error,1586,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2053,performance,perform,perform,2053,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1836,reliability,sli,slightly,1836,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1949,reliability,sli,slightly,1949,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:469,safety,compl,complexity,469,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1586,safety,error,error,1586,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:469,security,compl,complexity,469,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1113,security,network,network,1113,"e some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1470,testability,observ,observation,1470,"ity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1703,testability,observ,observation,1703,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:124,usability,minim,minimum,124,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:595,usability,perform,performs,595,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:751,usability,perform,performed,751,"Hello C,. Thank you for taking the time to investigate DeepVariant. . With respect to DP and AD, reads considered have some minimum thresholds for inclusion. You can see these in deepvariant/make_examples.py lines 274-277. The default is a filter at MAPQ 10. You can see this manifest in the calculation of allele depth in deepvariant/allelecounter.cc line 289. . Above these thresholds, DeepVariant will count all of the reads present. However, there is an additional complexity. DeepVariant generates local a local of the ref and alt alleles by constructing a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1586,usability,error,error,1586,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1868,usability,prefer,prefer,1868,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2053,usability,perform,perform,2053,"a De Bruijn graph of each. It then performs a Smith-Waterman re-alignment of reads to the assemblies. You can think of this as a more exhaustive version of the candidate haplotype generation performed in GATK. As a result of this re-assembly, there may be some differences between the alleles that DeepVariant constructs and those constructed in GATK (and this may contribute to differences in AD). See the deepvariant/realigner folder for all of the associated code. With respect to GT and GQ, these are the primary outputs of the convolutional neural network classifier. The classifier estimates the probability of HOM REF, HET, and HOM ALT states. The GT is the most probably state as determined by the classifier. The GQ should correspond to the likelihood calculated for that GT (and as a result, this should correspond to PL). With respect to the calibration of GQ and recommendations for filtering. One observation we have about DeepVariant is that the genotype qualities seem to quite accurately reflect the empirical error probability (see Figure 2 Panel C of - https://www.nature.com/articles/nbt.4235). This fact, combined with the observation that the GQ scores produced by DeepVariant are quite normally distributed, means that you have flexibility to shift them slightly higher or lower if you prefer higher precision or higher recall. . If anything, DeepVariant seems to be slightly on the conservative side outside of the confident regions, so I would likely recommend you not perform additional hard filtering on GQ, and consider REF calls with GQ below 10 or 20 to be more like no-calls. If you have not yet read the Nature Biotechnology manuscript, I would recommend that as another good overview https://www.nature.com/articles/nbt.423. If you are curious to compare calls between DeepVariant and other technologies, I would also recommend that you use metrics like TiTv ratio or dbSNP fraction on the calls that are shared and singletons between the two methods. Thanks,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:907,availability,error,errors,907,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:984,availability,error,error,984,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1041,availability,error,error,1041,"ismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is ther",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:701,deployability,depend,dependent,701,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:701,integrability,depend,dependent,701,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:43,interoperability,mismatch,mismatches,43,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:98,interoperability,mismatch,mismatches,98,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:373,interoperability,distribut,distribution,373,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:512,interoperability,distribut,distribution,512,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:701,modifiability,depend,dependent,701,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:907,performance,error,errors,907,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:984,performance,error,error,984,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1041,performance,error,error,1041,"ismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is ther",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1074,performance,time,times,1074,"hts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is there an argument to use in deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:701,safety,depend,dependent,701,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:907,safety,error,errors,907,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:984,safety,error,error,984,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1041,safety,error,error,1041,"ismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is ther",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2300,safety,compl,completely,2300,"ty of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is there an argument to use in deepvariant to control this feature? At the moment there is a bug in GATK (https://github.com/broadinstitute/gatk/issues/3697) which also could cause some discrepancies  I have noticed several calls where the alternative bases are completely ignored and I may be caused by this bug. . Cheers, C.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2083,security,control,control,2083,"ty of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is there an argument to use in deepvariant to control this feature? At the moment there is a bug in GATK (https://github.com/broadinstitute/gatk/issues/3697) which also could cause some discrepancies  I have noticed several calls where the alternative bases are completely ignored and I may be caused by this bug. . Cheers, C.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2300,security,compl,completely,2300,"ty of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is there an argument to use in deepvariant to control this feature? At the moment there is a bug in GATK (https://github.com/broadinstitute/gatk/issues/3697) which also could cause some discrepancies  I have noticed several calls where the alternative bases are completely ignored and I may be caused by this bug. . Cheers, C.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:701,testability,depend,dependent,701,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:2083,testability,control,control,2083,"ty of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is there an argument to use in deepvariant to control this feature? At the moment there is a bug in GATK (https://github.com/broadinstitute/gatk/issues/3697) which also could cause some discrepancies  I have noticed several calls where the alternative bases are completely ignored and I may be caused by this bug. . Cheers, C.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:274,usability,minim,minimum,274,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:907,usability,error,errors,907,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:984,usability,error,error,984,"Thanks for the reply. I have analyzed some mismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:1041,usability,error,error,1041,"ismatches and here are some thoughts:. Looking at two mismatches, here is the first one:. Chr1:261478C>A :. - GATK (GT:GQ:DP:AD) = 0/1:99:43:31,12. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:33,13:46:25:0,24,38:0.282609. GAKT have a minimum BaseQuality of 10 and MQ of 20, deepvariant 10 and 10. . Calculating the probability of AD distribution 31,12 (GATK) and 33,13 (deepvariant) is approximately 0.24% for deepvariant and 0,26% for GATK  so the probability that this distribution occurs assuming diploid and 50% chance of success the GT is most likely 0/0. GATKs GT is 0/1 with a GQ of 99  it is however flagged a VQSRTrancheSNP99.90to100.00, but this is dependent on the other genomes in the sample( Im not a big fan of VQSR). Manually inspecting the variant using IGV I would annotate this as 0/1, but it is reasonable that it is assigned 0/0 considering the errors introduced by Illumnia sequencing are not random, even though with an error rate of 1:1000 it is highly unlikely that the same error occurs at the same site 13 times. (btw this is PCR-free WGS). The variant chr1:202192T>C:. - GATK (GT:GQ:DP:AD) = 0/1:99:16:10,6. - Deepvariant(GT:AD:DP:GQ:PL:VAF) = 0/0:17,16:23:6:0,5,29:0.26087. The probability is here for deepvariant 1.75% and GATK 22.6% - so the discrepancy of this variant makes sense. Manually inspecting the variant using IGV I would annotate this as 0/1. I guess that by including low quality MQ in this case decreases the GQ for deepvariant and increasing the min_mapping_quality to 20 could be worth trying for comparison. Is there an argument that can be used for this? (im using GCP for this project). I have noticed that deepvariant call variants in soft-clipped regions, but is seems they are assigned 0/0  this is great  is this an intentional feature in deepvariant algorithm? This could be one reason to the discrepancies as GATK by default also call in soft-clipped regions. I will try to excluded these regions from GATK HC and see what the impact is. Is ther",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:298,modifiability,paramet,parameter,298,"Hello C,. I cannot comment much on your examples without seeing IGV. Keep in mind that DeepVariant does a realignment, therefore some reads may align differently from what you see in original BAM. As for the second example min_mapping_quality is set to 20 by default. It is possible to change this parameter in make_examples (make_examples is one of the steps and is called by GCP runner). Regarding soft-clipped regions. As Andrew mentioned earlier, reads are realigned to haplotypes, therefore sometimes new alignment can be done without soft-clips (read can be aligned to haplotype perfectly, although when aligning the same read to reference we get a soft-clip) There is no way to control this behavior. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:99,reliability,doe,does,99,"Hello C,. I cannot comment much on your examples without seeing IGV. Keep in mind that DeepVariant does a realignment, therefore some reads may align differently from what you see in original BAM. As for the second example min_mapping_quality is set to 20 by default. It is possible to change this parameter in make_examples (make_examples is one of the steps and is called by GCP runner). Regarding soft-clipped regions. As Andrew mentioned earlier, reads are realigned to haplotypes, therefore sometimes new alignment can be done without soft-clips (read can be aligned to haplotype perfectly, although when aligning the same read to reference we get a soft-clip) There is no way to control this behavior. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:685,security,control,control,685,"Hello C,. I cannot comment much on your examples without seeing IGV. Keep in mind that DeepVariant does a realignment, therefore some reads may align differently from what you see in original BAM. As for the second example min_mapping_quality is set to 20 by default. It is possible to change this parameter in make_examples (make_examples is one of the steps and is called by GCP runner). Regarding soft-clipped regions. As Andrew mentioned earlier, reads are realigned to haplotypes, therefore sometimes new alignment can be done without soft-clips (read can be aligned to haplotype perfectly, although when aligning the same read to reference we get a soft-clip) There is no way to control this behavior. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:685,testability,control,control,685,"Hello C,. I cannot comment much on your examples without seeing IGV. Keep in mind that DeepVariant does a realignment, therefore some reads may align differently from what you see in original BAM. As for the second example min_mapping_quality is set to 20 by default. It is possible to change this parameter in make_examples (make_examples is one of the steps and is called by GCP runner). Regarding soft-clipped regions. As Andrew mentioned earlier, reads are realigned to haplotypes, therefore sometimes new alignment can be done without soft-clips (read can be aligned to haplotype perfectly, although when aligning the same read to reference we get a soft-clip) There is no way to control this behavior. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:698,usability,behavi,behavior,698,"Hello C,. I cannot comment much on your examples without seeing IGV. Keep in mind that DeepVariant does a realignment, therefore some reads may align differently from what you see in original BAM. As for the second example min_mapping_quality is set to 20 by default. It is possible to change this parameter in make_examples (make_examples is one of the steps and is called by GCP runner). Regarding soft-clipped regions. As Andrew mentioned earlier, reads are realigned to haplotypes, therefore sometimes new alignment can be done without soft-clips (read can be aligned to haplotype perfectly, although when aligning the same read to reference we get a soft-clip) There is no way to control this behavior. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:58,integrability,coupl,couple,58,Unfortunately it is not possible as of today. You may add couple of lines of code to realigner.py to output realigned reads with cigars to console or text file and run make_example on a small window of interest. Also you may run DeepVariant without realigner using --norealign_reads flag.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:58,modifiability,coupl,couple,58,Unfortunately it is not possible as of today. You may add couple of lines of code to realigner.py to output realigned reads with cigars to console or text file and run make_example on a small window of interest. Also you may run DeepVariant without realigner using --norealign_reads flag.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:58,testability,coupl,couple,58,Unfortunately it is not possible as of today. You may add couple of lines of code to realigner.py to output realigned reads with cigars to console or text file and run make_example on a small window of interest. Also you may run DeepVariant without realigner using --norealign_reads flag.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:71,energy efficiency,cloud,cloud,71,"OK, thanks. . This is probably an embarrassing question: Im using GCP cloud shell and I am new to this, so how can I manipulate files in the docker images i.e changing the parameters in make_example.py? Is there a list of arguments/flags somewhere for make_example etc?. . For example from make_examples.py line 274-277:. read_reqs = reads_pb2.ReadRequirements(. min_base_quality=10,. min_mapping_quality=10,. min_base_quality_mode=reads_pb2.ReadRequirements.ENFORCED_BY_CLIENT). Could on change the parameters to --make_examples_min_base_quality = 20? Or maybe copy the image to a local bucket and manipulate them there? . Sorry for taking so much of your time! Cheers,. Christian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:173,modifiability,paramet,parameters,173,"OK, thanks. . This is probably an embarrassing question: Im using GCP cloud shell and I am new to this, so how can I manipulate files in the docker images i.e changing the parameters in make_example.py? Is there a list of arguments/flags somewhere for make_example etc?. . For example from make_examples.py line 274-277:. read_reqs = reads_pb2.ReadRequirements(. min_base_quality=10,. min_mapping_quality=10,. min_base_quality_mode=reads_pb2.ReadRequirements.ENFORCED_BY_CLIENT). Could on change the parameters to --make_examples_min_base_quality = 20? Or maybe copy the image to a local bucket and manipulate them there? . Sorry for taking so much of your time! Cheers,. Christian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:501,modifiability,paramet,parameters,501,"OK, thanks. . This is probably an embarrassing question: Im using GCP cloud shell and I am new to this, so how can I manipulate files in the docker images i.e changing the parameters in make_example.py? Is there a list of arguments/flags somewhere for make_example etc?. . For example from make_examples.py line 274-277:. read_reqs = reads_pb2.ReadRequirements(. min_base_quality=10,. min_mapping_quality=10,. min_base_quality_mode=reads_pb2.ReadRequirements.ENFORCED_BY_CLIENT). Could on change the parameters to --make_examples_min_base_quality = 20? Or maybe copy the image to a local bucket and manipulate them there? . Sorry for taking so much of your time! Cheers,. Christian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:658,performance,time,time,658,"OK, thanks. . This is probably an embarrassing question: Im using GCP cloud shell and I am new to this, so how can I manipulate files in the docker images i.e changing the parameters in make_example.py? Is there a list of arguments/flags somewhere for make_example etc?. . For example from make_examples.py line 274-277:. read_reqs = reads_pb2.ReadRequirements(. min_base_quality=10,. min_mapping_quality=10,. min_base_quality_mode=reads_pb2.ReadRequirements.ENFORCED_BY_CLIENT). Could on change the parameters to --make_examples_min_base_quality = 20? Or maybe copy the image to a local bucket and manipulate them there? . Sorry for taking so much of your time! Cheers,. Christian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:214,energy efficiency,current,currently,214,"@HagenC all flags for `make_example.py` can be found [here](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L87) (lines 87-207). For the `min_base_quality` that you reference, there is currently no flag set up to modify that value. If you want to modify that value, the best way to do so would be to modify the default in the source code or add a flag and then rebuild DeepVariant. I realize that this might be a bit tedious to do, and we will consider including a flag for that parameter later on.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:508,modifiability,paramet,parameter,508,"@HagenC all flags for `make_example.py` can be found [here](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L87) (lines 87-207). For the `min_base_quality` that you reference, there is currently no flag set up to modify that value. If you want to modify that value, the best way to do so would be to modify the default in the source code or add a flag and then rebuild DeepVariant. I realize that this might be a bit tedious to do, and we will consider including a flag for that parameter later on.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:242,security,modif,modify,242,"@HagenC all flags for `make_example.py` can be found [here](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L87) (lines 87-207). For the `min_base_quality` that you reference, there is currently no flag set up to modify that value. If you want to modify that value, the best way to do so would be to modify the default in the source code or add a flag and then rebuild DeepVariant. I realize that this might be a bit tedious to do, and we will consider including a flag for that parameter later on.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:276,security,modif,modify,276,"@HagenC all flags for `make_example.py` can be found [here](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L87) (lines 87-207). For the `min_base_quality` that you reference, there is currently no flag set up to modify that value. If you want to modify that value, the best way to do so would be to modify the default in the source code or add a flag and then rebuild DeepVariant. I realize that this might be a bit tedious to do, and we will consider including a flag for that parameter later on.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:329,security,modif,modify,329,"@HagenC all flags for `make_example.py` can be found [here](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L87) (lines 87-207). For the `min_base_quality` that you reference, there is currently no flag set up to modify that value. If you want to modify that value, the best way to do so would be to modify the default in the source code or add a flag and then rebuild DeepVariant. I realize that this might be a bit tedious to do, and we will consider including a flag for that parameter later on.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:146,deployability,depend,depending,146,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:557,deployability,version,version,557,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:718,deployability,version,version,718,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:61,energy efficiency,current,currently,61,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:233,energy efficiency,cloud,cloud,233,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:323,energy efficiency,cloud,cloud,323,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:710,energy efficiency,current,current,710,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:146,integrability,depend,depending,146,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:557,integrability,version,version,557,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:718,integrability,version,version,718,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:146,modifiability,depend,depending,146,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:557,modifiability,version,version,557,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:718,modifiability,version,version,718,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:855,reliability,doe,does,855,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:146,safety,depend,depending,146,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:71,security,modif,modify,71,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:119,security,modif,modify,119,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:146,testability,depend,depending,146,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:572,usability,document,document,572,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:733,usability,document,document,733,"@HagenC I want to clarify a bit more. Even though you cannot currently modify the value of `min_base_quality`, you CAN modify the existing flags, depending on how you are running DeepVariant. I was not sure what you meant by the GCP cloud shell. Are you running on one machine yourself or following [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant)? . If you are running on one machine, you can take a look at [the WGS case study](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-case-study.md). This is an older version of the document that shows how to pass different flags to each step (`make_examples`, `call_variants`, `postprocess_variants`). You can find the current version of the document [here](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md), but this uses Docker and does not show how to run each step with additional flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:169,deployability,contain,container,169,"@gunjanbaid I am following the tutorial https://cloud.google.com/genomics/docs/tutorials/deepvariant - so GCP WM with Debian 9.6 (4.14.74+ GNU/Linux) running the docker container that you have provided. I have access to a CentOS 7.5.1804 (3.10.0-862.3.3.el7.x86_64 GNU/Linux) system, however, I do not have full admin rights as it a shared system and there are several post about issues with CentOS 7 and not having root permissions. Unfortunately I dont have the time to play around with this at the moment  Im expecting there will be a lot of trouble shooting and work arounds!. Thanks for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:48,energy efficiency,cloud,cloud,48,"@gunjanbaid I am following the tutorial https://cloud.google.com/genomics/docs/tutorials/deepvariant - so GCP WM with Debian 9.6 (4.14.74+ GNU/Linux) running the docker container that you have provided. I have access to a CentOS 7.5.1804 (3.10.0-862.3.3.el7.x86_64 GNU/Linux) system, however, I do not have full admin rights as it a shared system and there are several post about issues with CentOS 7 and not having root permissions. Unfortunately I dont have the time to play around with this at the moment  Im expecting there will be a lot of trouble shooting and work arounds!. Thanks for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:333,interoperability,share,shared,333,"@gunjanbaid I am following the tutorial https://cloud.google.com/genomics/docs/tutorials/deepvariant - so GCP WM with Debian 9.6 (4.14.74+ GNU/Linux) running the docker container that you have provided. I have access to a CentOS 7.5.1804 (3.10.0-862.3.3.el7.x86_64 GNU/Linux) system, however, I do not have full admin rights as it a shared system and there are several post about issues with CentOS 7 and not having root permissions. Unfortunately I dont have the time to play around with this at the moment  Im expecting there will be a lot of trouble shooting and work arounds!. Thanks for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:465,performance,time,time,465,"@gunjanbaid I am following the tutorial https://cloud.google.com/genomics/docs/tutorials/deepvariant - so GCP WM with Debian 9.6 (4.14.74+ GNU/Linux) running the docker container that you have provided. I have access to a CentOS 7.5.1804 (3.10.0-862.3.3.el7.x86_64 GNU/Linux) system, however, I do not have full admin rights as it a shared system and there are several post about issues with CentOS 7 and not having root permissions. Unfortunately I dont have the time to play around with this at the moment  Im expecting there will be a lot of trouble shooting and work arounds!. Thanks for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:421,safety,permiss,permissions,421,"@gunjanbaid I am following the tutorial https://cloud.google.com/genomics/docs/tutorials/deepvariant - so GCP WM with Debian 9.6 (4.14.74+ GNU/Linux) running the docker container that you have provided. I have access to a CentOS 7.5.1804 (3.10.0-862.3.3.el7.x86_64 GNU/Linux) system, however, I do not have full admin rights as it a shared system and there are several post about issues with CentOS 7 and not having root permissions. Unfortunately I dont have the time to play around with this at the moment  Im expecting there will be a lot of trouble shooting and work arounds!. Thanks for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:210,security,access,access,210,"@gunjanbaid I am following the tutorial https://cloud.google.com/genomics/docs/tutorials/deepvariant - so GCP WM with Debian 9.6 (4.14.74+ GNU/Linux) running the docker container that you have provided. I have access to a CentOS 7.5.1804 (3.10.0-862.3.3.el7.x86_64 GNU/Linux) system, however, I do not have full admin rights as it a shared system and there are several post about issues with CentOS 7 and not having root permissions. Unfortunately I dont have the time to play around with this at the moment  Im expecting there will be a lot of trouble shooting and work arounds!. Thanks for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:604,usability,help,help,604,"@gunjanbaid I am following the tutorial https://cloud.google.com/genomics/docs/tutorials/deepvariant - so GCP WM with Debian 9.6 (4.14.74+ GNU/Linux) running the docker container that you have provided. I have access to a CentOS 7.5.1804 (3.10.0-862.3.3.el7.x86_64 GNU/Linux) system, however, I do not have full admin rights as it a shared system and there are several post about issues with CentOS 7 and not having root permissions. Unfortunately I dont have the time to play around with this at the moment  Im expecting there will be a lot of trouble shooting and work arounds!. Thanks for all your help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:64,usability,help,help,64,"@HagenC no problem! Let me know if there is anything else I can help with. Otherwise, I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:93,usability,close,close,93,"@HagenC no problem! Let me know if there is anything else I can help with. Otherwise, I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:159,deployability,releas,release,159,@HagenC We have internally added both `min_base_quality` and `min_mapping_quality` as flags in `make_examples` and these will come out in the next DeepVariant release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/136:100,energy efficiency,cloud,cloud,100,@hguan6 Based on the following page the P100's are limited to a max of 4. Try V100 or K80:. https://cloud.google.com/compute/docs/gpus/#gpus-list,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:130,energy efficiency,gpu,gpus,130,@hguan6 Based on the following page the P100's are limited to a max of 4. Try V100 or K80:. https://cloud.google.com/compute/docs/gpus/#gpus-list,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:136,energy efficiency,gpu,gpus-list,136,@hguan6 Based on the following page the P100's are limited to a max of 4. Try V100 or K80:. https://cloud.google.com/compute/docs/gpus/#gpus-list,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:130,performance,gpu,gpus,130,@hguan6 Based on the following page the P100's are limited to a max of 4. Try V100 or K80:. https://cloud.google.com/compute/docs/gpus/#gpus-list,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:136,performance,gpu,gpus-list,136,@hguan6 Based on the following page the P100's are limited to a max of 4. Try V100 or K80:. https://cloud.google.com/compute/docs/gpus/#gpus-list,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:22,usability,close,close,22,@hguan6 I am going to close this issue as it seems to be resolved. Feel free to reopen if you still have pending questions.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:37,energy efficiency,current,currently,37,"@hguan6 one last thing I'd mention - currently call_variants doesn't utilize more than one GPU. And, empirically, it's not actually faster if you run multiple call_variants on the same machine. If you're running call_variants on one machine, my suggestion is to run just one call_variants. But feel free to experiment with different settings on your side to see what works best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:91,energy efficiency,GPU,GPU,91,"@hguan6 one last thing I'd mention - currently call_variants doesn't utilize more than one GPU. And, empirically, it's not actually faster if you run multiple call_variants on the same machine. If you're running call_variants on one machine, my suggestion is to run just one call_variants. But feel free to experiment with different settings on your side to see what works best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:91,performance,GPU,GPU,91,"@hguan6 one last thing I'd mention - currently call_variants doesn't utilize more than one GPU. And, empirically, it's not actually faster if you run multiple call_variants on the same machine. If you're running call_variants on one machine, my suggestion is to run just one call_variants. But feel free to experiment with different settings on your side to see what works best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:61,reliability,doe,doesn,61,"@hguan6 one last thing I'd mention - currently call_variants doesn't utilize more than one GPU. And, empirically, it's not actually faster if you run multiple call_variants on the same machine. If you're running call_variants on one machine, my suggestion is to run just one call_variants. But feel free to experiment with different settings on your side to see what works best.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:932,availability,Heal,Health,932,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:958,availability,State,State,958,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:171,energy efficiency,current,currently,171,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:225,energy efficiency,GPU,GPU,225,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:958,integrability,State,State,958,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:225,performance,GPU,GPU,225,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:195,reliability,doe,doesn,195,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:785,security,auth,auth,785,"Thank you! Hong. On Thu, Jan 10, 2019 at 11:47 AM Pi-Chuan Chang <notifications@github.com>. wrote:. > @hguan6 <https://github.com/hguan6> one last thing I'd mention -. > currently call_variants doesn't utilize more than one GPU. And,. > empirically, it's not actually faster if you run multiple call_variants on. > the same machine. If you're running call_variants on one machine, my. > suggestion is to run just one call_variants. But feel free to experiment. > with different settings on your side to see what works best. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/136#issuecomment-453208669>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AS_dixdlyMD05-L1pPM529ZDw00t2yOzks5vB4q2gaJpZM4Zsand>. > . >. -- . Hong Guan. Graduate Research Assistant, Biomedical Informatics. College of Health Solutions. Arizona State University.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/137:50,availability,error,error,50,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:71,availability,error,error,71,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:924,availability,error,error,924,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:291,deployability,fail,failed,291,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2472,deployability,modul,module,2472,"rt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6296,deployability,api,apitools,6296,"py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connectio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6305,deployability,api,apitools,6305," 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6502,deployability,api,apitools,6502,"terAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6511,deployability,api,apitools,6511,"expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6945,deployability,api,apitools,6945,"l_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6954,deployability,api,apitools,6954,"\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7169,deployability,api,apitools,7169,"al_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7178,deployability,api,apitools,7178,")\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, cre",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1631,energy efficiency,model,models,1631,"t_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1784,energy efficiency,model,models,1784,"ages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1939,energy efficiency,model,models,1939,"============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2092,energy efficiency,model,models,2092," <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/go",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2239,energy efficiency,model,models,2239,"nit/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2414,energy efficiency,cloud,cloud-sdk-,2414,"pefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_itera",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2563,energy efficiency,cloud,cloud-sdk-,2563,"inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2730,energy efficiency,cloud,cloud-sdk-,2730,"iniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2905,energy efficiency,cloud,cloud-sdk-,2905,"ar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_exp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3100,energy efficiency,cloud,cloud-sdk-,3100,"riant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3297,energy efficiency,cloud,cloud-sdk-,3297,"s_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3488,energy efficiency,cloud,cloud-sdk-,3488,"ain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsut",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3680,energy efficiency,cloud,cloud-sdk-,3680,"ansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platfor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3860,energy efficiency,cloud,cloud-sdk-,3860,"rt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4065,energy efficiency,cloud,cloud-sdk-,4065,"da3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4263,energy efficiency,cloud,cloud-sdk-,4263,"a3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4460,energy efficiency,cloud,cloud-sdk-,4460,"s/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4658,energy efficiency,cloud,cloud-sdk-,4658,"Var/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4855,energy efficiency,cloud,cloud-sdk-,4855,"cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5053,energy efficiency,cloud,cloud-sdk-,5053,"google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5229,energy efficiency,cloud,cloud-sdk-,5229,"a3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5427,energy efficiency,cloud,cloud-sdk-,5427,"3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5631,energy efficiency,cloud,cloud-sdk-,5631,"/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/min",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5843,energy efficiency,cloud,cloud-sdk-,5843,"google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6023,energy efficiency,cloud,cloud-sdk-,6023,"nvs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_respon",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6248,energy efficiency,cloud,cloud-sdk-,6248,"form/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6454,energy efficiency,cloud,cloud-sdk-,6454,"til/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6670,energy efficiency,cloud,cloud-sdk-,6670,"ldcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6897,energy efficiency,cloud,cloud-sdk-,6897," line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7121,energy efficiency,cloud,cloud-sdk-,7121,", in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7372,energy efficiency,cloud,cloud-sdk-,7372,"est, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _upda",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7577,energy efficiency,cloud,cloud-sdk-,7577,"_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7790,energy efficiency,cloud,cloud-sdk-,7790,"AndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8003,energy efficiency,cloud,cloud-sdk-,8003,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8256,energy efficiency,cloud,cloud-sdk-,8256,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8471,energy efficiency,cloud,cloud-sdk-,8471,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8694,energy efficiency,cloud,cloud-sdk-,8694,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:56,integrability,messag,messages,56,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:77,integrability,messag,message,77,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:930,integrability,messag,message,930,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6296,integrability,api,apitools,6296,"py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connectio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6305,integrability,api,apitools,6305," 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6502,integrability,api,apitools,6502,"terAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6511,integrability,api,apitools,6511,"expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6945,integrability,api,apitools,6945,"l_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6954,integrability,api,apitools,6954,"\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7169,integrability,api,apitools,7169,"al_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7178,integrability,api,apitools,7178,")\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, cre",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:56,interoperability,messag,messages,56,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:77,interoperability,messag,message,77,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:930,interoperability,messag,message,930,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1758,interoperability,share,share,1758,"e ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1913,interoperability,share,share,1913,"r:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2213,interoperability,share,share,2213,"ut (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2401,interoperability,share,share,2401,"+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2434,interoperability,platform,platform,2434,"SION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2550,interoperability,share,share,2550,"ME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2583,interoperability,platform,platform,2583,"data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2717,interoperability,share,share,2717,"home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2750,interoperability,platform,platform,2750,"Var/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _Sequ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2892,interoperability,share,share,2892,"nda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2925,interoperability,platform,platform,2925,"t-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 62",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3087,interoperability,share,share,3087,"t/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3120,interoperability,platform,platform,3120,"iant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkab",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3284,interoperability,share,share,3284,"3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/plat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3317,interoperability,platform,platform,3317,"ack (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3475,interoperability,share,share,3475,">\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3508,interoperability,platform,platform,3508,"home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3667,interoperability,share,share,3667,"le ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-16",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3700,interoperability,platform,platform,3700,"envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3847,interoperability,share,share,3847,"mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/go",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3880,interoperability,platform,platform,3880,"deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4052,interoperability,share,share,4052,"ansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4085,interoperability,platform,platform,4085,"are/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4250,interoperability,share,share,4250,"nsourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/plat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4283,interoperability,platform,platform,4283,"re/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checka",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4447,interoperability,share,share,4447,"/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/pla",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4480,interoperability,platform,platform,4480,"gle-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4645,interoperability,share,share,4645,"onda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4678,interoperability,platform,platform,4678,"oud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4842,interoperability,share,share,4842,"r/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4875,interoperability,platform,platform,4875,"/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5040,interoperability,share,share,5040,"/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5073,interoperability,platform,platform,5073,"6.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5216,interoperability,share,share,5216,"nsourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/minicond",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5249,interoperability,platform,platform,5249,"re/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5414,interoperability,share,share,5414,"sourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5447,interoperability,platform,platform,5447,"e/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/goog",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5618,interoperability,share,share,5618,"miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5651,interoperability,platform,platform,5651,"le-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__\n for (names_container, blr) in self.tuple_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5830,interoperability,share,share,5830,"/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:5863,interoperability,platform,platform,5863,"6.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/minicon",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6010,interoperability,share,share,6010,"rt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6043,interoperability,platform,platform,6043,"oogle-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__\n for blr in self.blr_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_respo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6235,interoperability,share,share,6235,"-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6268,interoperability,platform,platform,6268,"lurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirection",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6296,interoperability,api,apitools,6296,"py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connectio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6305,interoperability,api,apitools,6305," 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6441,interoperability,share,share,6441,"-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2clien",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6474,interoperability,platform,platform,6474,"iterator.py"", line 476, in IterAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_req",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6502,interoperability,api,apitools,6502,"terAll\n expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6511,interoperability,api,apitools,6511,"expand_top_level_buckets=expand_top_level_buckets):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6657,interoperability,share,share,6657,"gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6690,interoperability,platform,platform,6690,", line 215, in __iter__\n provider=self.wildcard_url.scheme, fields=listing_fields):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6884,interoperability,share,share,6884,"s_json_api.py"", line 595, in ListObjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6917,interoperability,platform,platform,6917,"bjects\n global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6945,interoperability,api,apitools,6945,"l_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:6954,interoperability,api,apitools,6954,"\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7108,interoperability,share,share,7108,".py"", line 1237, in List\n config, request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7141,interoperability,platform,platform,7141," request, global_params=global_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multist",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7169,interoperability,api,apitools,7169,"al_params)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7178,interoperability,api,apitools,7178,")\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod\n http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, cre",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7359,interoperability,share,share,7359,"http, http_request, **opts)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", lin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7392,interoperability,platform,platform,7392," ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 351, in MakeRequest\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n sel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7564,interoperability,share,share,7564,"est\n max_retry_wait, total_wait_sec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7597,interoperability,platform,platform,7597,"ec))\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/util.py"", line 1719, in WarnAfterManyRetriesHandler\n http_wrapper.HandleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7777,interoperability,share,share,7777,"andleExceptionsAndRebuildHttpConnections(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/mult",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7810,interoperability,platform,platform,7810,"ctions(retry_args)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _loc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:7990,interoperability,share,share,7990,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8023,interoperability,platform,platform,8023,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8243,interoperability,share,share,8243,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8276,interoperability,platform,platform,8276,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8458,interoperability,share,share,8458,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8491,interoperability,platform,platform,8491,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8681,interoperability,share,share,8681,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:8714,interoperability,platform,platform,8714,".0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest\n check_response_func=check_response_func)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry\n redirections=redirections, connection_type=connection_type)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 616, in new_request\n self._refresh(request_orig)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 885, in _refresh\n self._do_refresh_request(http_request)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/client.py"", line 939, in _do_refresh_request\n self.store.locked_put(self)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 271, in locked_put\n self._multistore._update_credential(self._key, credentials)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 475, in _update_credential\n self._write()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 441, in _write\n self._locked_json_write(raw_data)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/oauth2client/oauth2client/contrib/multistore_file.py"", line 367, in _locked_json_write\n self._file.file_handle().truncate()\nIOError: [Errno 9] Bad file descriptor\n'.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:116,modifiability,PAC,PACKAGE,116,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:479,modifiability,pac,packages,479,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:602,modifiability,pac,packages,602,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:709,modifiability,pac,packages,709,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:783,modifiability,pac,packages,783,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2472,modifiability,modul,module,2472,"rt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:50,performance,error,error,50,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:71,performance,error,error,71,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:924,performance,error,error,924,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:291,reliability,fail,failed,291,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:41,safety,except,except,41,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:50,safety,error,error,50,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:71,safety,error,error,71,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:499,safety,test,tests,499,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:622,safety,test,tests,622,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:729,safety,test,tests,729,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:803,safety,test,tests,803,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:924,safety,error,error,924,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2472,safety,modul,module,2472,"rt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1631,security,model,models,1631,"t_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1784,security,model,models,1784,"ages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1939,security,model,models,1939,"============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2092,security,model,models,2092," <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/go",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2239,security,model,models,2239,"nit/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ /mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil cp \'gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/*\' /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard/\nTraceback (most recent call last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:499,testability,test,tests,499,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:622,testability,test,tests,622,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:729,testability,test,tests,729,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:803,testability,test,tests,803,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:50,usability,error,error,50,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:71,usability,error,error,71,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:924,usability,error,error,924,"Running with -v, everything looks normal except 2 error messages:. 1st error message:. ==============. ===> LINKING PACKAGE: conda-forge::linecache2-1.0.0-py_1 <===. prefix=/mnt/home/mansourt/miniconda3/envs/deepVar. source=/mnt/home/mansourt/miniconda3/pkgs/linecache2-1.0.0-py_1. pyc file failed to compile successfully. python_exe_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/bin/python2.7. py_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py. pyc_full_path: /mnt/home/mansourt/miniconda3/envs/deepVar/lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.pyc. compile rc: 1. compile stdout: Compiling lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py ... File ""lib/python2.7/site-packages/linecache2/tests/inspect_fodder2.py"", line 102. def keyworded(*arg1, arg2=1):. ^. SyntaxError: invalid syntax. compile stderr:. 2nd error message:. ==============. $ bash -x /mnt/home/mansourt/miniconda3/envs/deepVar/bin/.deepvariant-post-link.sh. ==> cwd: /mnt/home/mansourt/miniconda3/envs/deepVar/bin <==. ==> exit code: 1 <==. ==> stdout <==. b'Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/local/lmod/lmod/init/bash)\nShell debugging restarted\n'. ==> stderr <==. b'+ \'[\' -z \'\' \']\'\n+ case ""$-"" in\n+ __lmod_vx=x\n+ \'[\' -n x \']\'\n+ set +x\n+ unset __lmod_vx\n+ set -eu -o pipefail\n+ MODEL_VERSION=0.7.2\n+ GSUTIL=/mnt/home/mansourt/miniconda3/envs/deepVar/bin/gsutil\n+ for MODEL_TYPE in wgs wes\n+ MODEL_NAME=DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ GSREF=gs://deepvariant/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ OUTDIR=/mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-wgs_standard\n+ mkdir -p /mnt/home/mansourt/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/models/DeepVariant/0.7.2/DeepVariant-inception_v3-0.7.2+data-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3339,usability,command,commands,3339,"last):\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>\n gsutil.RunMain()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __ite",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3530,usability,command,command,3530,"a3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain\n sys.exit(gslib.__main__.main())\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3722,usability,command,command,3722,"gle-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main\n perf_trace_token=perf_trace_token)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions\n collect_analytics=True)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand\n return_code = command_inst.RunCommand()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand\n seek_ahead_iterator=seek_ahead_iterator)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply\n arg_checker, should_return_results, fail_on_error)\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply\n args = args_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next\n name_expansion_result = self.current_expansion_iter.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__\n for (names_container, blr) in post_step3_iter:\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead\n e = self.base_iterator.next()\n File ""/mnt/home/mansourt/miniconda3/envs/deepVar/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:54,deployability,instal,install,54,"Tamer;. Thanks for the report and apologies about the install issue. This looks like you might be trying to install inside an miniconda environment running python 3. Is that a possibility? Right now, gsutil and deepvariant are only compatible with python 2.7 so using miniconda 2 (https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh) or a python=2 environment inside your existing conda install will hopefully resolve the problem.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:108,deployability,instal,install,108,"Tamer;. Thanks for the report and apologies about the install issue. This looks like you might be trying to install inside an miniconda environment running python 3. Is that a possibility? Right now, gsutil and deepvariant are only compatible with python 2.7 so using miniconda 2 (https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh) or a python=2 environment inside your existing conda install will hopefully resolve the problem.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:405,deployability,instal,install,405,"Tamer;. Thanks for the report and apologies about the install issue. This looks like you might be trying to install inside an miniconda environment running python 3. Is that a possibility? Right now, gsutil and deepvariant are only compatible with python 2.7 so using miniconda 2 (https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh) or a python=2 environment inside your existing conda install will hopefully resolve the problem.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:232,interoperability,compatib,compatible,232,"Tamer;. Thanks for the report and apologies about the install issue. This looks like you might be trying to install inside an miniconda environment running python 3. Is that a possibility? Right now, gsutil and deepvariant are only compatible with python 2.7 so using miniconda 2 (https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh) or a python=2 environment inside your existing conda install will hopefully resolve the problem.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:69,deployability,version,version,69,Thanks for the response but actually no. I am using py2.7. >python --version. Python 2.7.15.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:69,integrability,version,version,69,Thanks for the response but actually no. I am using py2.7. >python --version. Python 2.7.15.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:69,modifiability,version,version,69,Thanks for the response but actually no. I am using py2.7. >python --version. Python 2.7.15.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:21,availability,replic,replicate,21,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:424,availability,error,error,424,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:488,availability,error,error,488,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1053,availability,down,download,1053,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1690,availability,error,error,1690,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1762,availability,replic,replicate,1762,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1783,availability,error,error,1783,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:228,deployability,instal,installations,228,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:269,deployability,updat,update,269,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:291,deployability,instal,installations,291,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:338,deployability,instal,install,338,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:551,deployability,instal,installation,551,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:573,deployability,fail,failed,573,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:639,deployability,stack,stackoverflow,639,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:691,deployability,modul,module-named-google-compute-engine,691,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:773,deployability,instal,installing,773,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:861,deployability,instal,install,861,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:887,deployability,instal,install,887,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1004,deployability,instal,install,1004,", I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melke",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1082,deployability,instal,install,1082,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1249,deployability,fail,failing,1249,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1380,deployability,instal,install,1380,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1574,deployability,instal,install,1574,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1643,deployability,instal,install,1643,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1730,deployability,instal,installation,1730,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1974,deployability,instal,install,1974,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:130,energy efficiency,cloud,cloud,130,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:174,energy efficiency,cloud,cloud,174,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:920,energy efficiency,cloud,cloud,920,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:691,modifiability,modul,module-named-google-compute-engine,691,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:424,performance,error,error,424,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:488,performance,error,error,488,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1690,performance,error,error,1690,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1783,performance,error,error,1783,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:573,reliability,fail,failed,573,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1249,reliability,fail,failing,1249,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:269,safety,updat,update,269,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:424,safety,error,error,424,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:488,safety,error,error,488,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:691,safety,modul,module-named-google-compute-engine,691,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1690,safety,error,error,1690,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1783,safety,error,error,1783,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1795,safety,sanit,sanity,1795,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:269,security,updat,update,269,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1795,security,sanit,sanity,1795,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:963,testability,verif,verify,963,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:424,usability,error,error,424,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:488,usability,error,error,488,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:817,usability,command,commands,817,"Hi Tamer, I tried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1690,usability,error,error,1690,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1783,usability,error,error,1783,"ried to replicate this issue, and here is what I found. I created an instance from [this CentOS7 VM](https://console.cloud.google.com/marketplace/details/centos-cloud/centos-7). I chose the default location for all installations. When asked if I wanted to update my PATH during installations, I chose to do so. I was able to install DeepVariant through Bioconda using the below steps. . I ran into a particular error with `gsutil`. After running `source ~/.bashrc`, I saw an error when I ran `gsutil`. `gsutil` is used by the DeepVariant installation, so that failed as well. To address this, I referenced [this post](https://stackoverflow.com/questions/38783140/importerror-no-module-named-google-compute-engine) and ran `export BOTO_CONFIG=/dev/null` before installing DeepVariant again. Running these commands in order allows me to successfully install on the VM. ```. # install gsutil. curl https://sdk.cloud.google.com | bash. exec -l $SHELL. # verify that gsutil is working. gsutil. # install wget and bzip2, which are both needed to download miniconda. sudo yum install bzip2 wget. wget https://repo.anaconda.com/miniconda/Miniconda2-latest-Linux-x86_64.sh. bash Miniconda2-latest-Linux-x86_64.sh . source ~/.bashrc. # gsutil is failing now. gsutil. export BOTO_CONFIG=/dev/null. # gsutil should be working again. gsutil. # create new conda env, add channels, install deepvaraint. conda create -n dv python=2.7. conda activate dv. conda config --add channels defaults. conda config --add channels bioconda. conda config --add channels conda-forge. conda install -n dv deepvariant -v. ```. In the output from running `conda install -n dv deepvariant -v`, I see the first error you posted even with a successful installation. I was not able to replicate the second error. Some sanity checks for you:. * Are you able to successfully run `gsutil`? * Did you add all conda channels in the correct order? * Could you post the entire output from running `conda install -v deepvariant`? CC @melkerdawy",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:430,availability,error,error,430,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:506,availability,error,error,506,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2637,availability,error,error,2637,"aceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:79,deployability,instal,installed,79,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:271,deployability,instal,install,271,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:318,deployability,instal,install,318,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:367,deployability,log,log,367,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:396,deployability,instal,installation,396,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1030,deployability,modul,module,1030,"ordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1183,deployability,modul,module,1183,"ed:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1399,deployability,modul,module,1399,"lation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CX",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1592,deployability,modul,module,1592,"Variant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1809,deployability,modul,module,1809,""" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2022,deployability,modul,module,2022," in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2391,deployability,version,version,2391,"in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import range",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2571,deployability,upgrad,upgraded,2571,"y"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Ba",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2592,deployability,version,version,2592,"le>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2650,deployability,modul,module,2650," recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3189,deployability,modul,module,3189,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3344,deployability,modul,module,3344,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3513,deployability,modul,module,3513,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3672,deployability,modul,module,3672,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3766,deployability,version,version,3766,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3973,deployability,instal,install,3973,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4038,deployability,instal,installation,4038,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4051,deployability,fail,failed,4051,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:301,energy efficiency,cloud,cloud-sdk,301,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2657,energy efficiency,load,load,2657,"t call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:436,integrability,messag,message,436,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2391,integrability,version,version,2391,"in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import range",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2592,integrability,version,version,2592,"le>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3766,integrability,version,version,3766,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:436,interoperability,messag,message,436,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:556,interoperability,share,share,556,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2715,interoperability,share,share,2715,"pvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python im",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1030,modifiability,modul,module,1030,"ordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1136,modifiability,pac,packages,1136,"dit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1183,modifiability,modul,module,1183,"ed:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1345,modifiability,pac,packages,1345,"epvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/sof",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1399,modifiability,modul,module,1399,"lation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CX",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1529,modifiability,pac,packages,1529,"iniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1592,modifiability,modul,module,1592,"Variant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1746,modifiability,pac,packages,1746,"ruth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1809,modifiability,modul,module,1809,""" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1950,modifiability,pac,packages,1950,"runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2022,modifiability,modul,module,2022," in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2155,modifiability,pac,packages,2155,"nit__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/ma",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2391,modifiability,version,version,2391,"in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import range",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2504,modifiability,pac,packages,2504,"t/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2571,modifiability,upgrad,upgraded,2571,"y"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Ba",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2592,modifiability,version,version,2592,"le>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2650,modifiability,modul,module,2650," recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3189,modifiability,modul,module,3189,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3344,modifiability,modul,module,3344,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3513,modifiability,modul,module,3513,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3672,modifiability,modul,module,3672,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3766,modifiability,version,version,3766,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:430,performance,error,error,430,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:506,performance,error,error,506,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2637,performance,error,error,2637,"aceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2657,performance,load,load,2657,"t call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4051,reliability,fail,failed,4051,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:367,safety,log,log,367,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:430,safety,error,error,430,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:506,safety,error,error,506,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1030,safety,modul,module,1030,"ordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1183,safety,modul,module,1183,"ed:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1399,safety,modul,module,1399,"lation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CX",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1592,safety,modul,module,1592,"Variant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1809,safety,modul,module,1809,""" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2022,safety,modul,module,2022," in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2637,safety,error,error,2637,"aceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2650,safety,modul,module,2650," recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3189,safety,modul,module,3189,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3344,safety,modul,module,3344,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3513,safety,modul,module,3513,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3672,safety,modul,module,3672,"ome/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installation failed. Any suggestions to move forward? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:367,security,log,log,367,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:367,testability,log,log,367,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:885,testability,Trace,Traceback,885,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1638,testability,Trace,Traceback,1638,"e_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:3044,testability,Trace,Traceback,3044,"_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/io/python/../../../../_solib_k8/libexternal_Shtslib_Slibhtslib.so). ```. I tried to install local GLIBC. I tried v2.25 ans v2.28 using conda but the installatio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:173,usability,command,commands,173,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:430,usability,error,error,430,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:506,usability,error,error,506,"Thank you for the response . I reordered the conda channels to match yours and installed gsutil but using conda and thus I did not need to edit the path. This is the set of commands I used:. ```. conda create -n deepvariant python=2.7. source activate deepvariant. conda install -c conda-forge google-cloud-sdk. conda install -v -y deepvariant &> deepvariant_insatll.log. ```. I got a successful installation inspite of the first error message just like you. However, running the code is producing another error:. ```. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_4i44qy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/__init__.py"", line 30, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>. from tensorflow.python import pywrap_tensorflow. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>. raise ImportError(msg). ImportError: Traceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_inter",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:2637,usability,error,error,2637,"aceback (most recent call last):. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>. from tensorflow.python.pywrap_tensorflow_internal import *. File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>. _pywrap_tensorflow_internal = swig_import_helper(). File ""/mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper. _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description). ImportError: /opt/software/GCCcore/6.4.0/lib64/libstdc++.so.6: version `CXXABI_1.3.11' not found (required by /mnt/home/mansourt/miniconda3/envs/deepvariant/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so). ```. I upgraded to a higher version of GNU and re-ran but I got a nother error . ```. module load GNU/7.3.0-2.30. python $HOME/miniconda3/envs/deepVar/share/deepvariant-0.7.2-1/binaries/DeepVariant/0.7.2/DeepVariant-0.7.2+cl-225213413/make_examples.zip \. --mode training --reads ""${BAM}"" --ref ""${REF}"" --examples ""$training.tfrecord.gz"" \. --truth_variants ""${TRUTH_VCF}"" --confident_regions ""${TRUTH_BED}"" \. --exclude_regions ""chr20:14000000-15000000"" --sample_name ""train"" . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_FlJ2h7/runfiles/com_google_deepvariant/third_party/n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:30,availability,down,download,30,"@drtamermansour Why don't you download glibc 2.23 from here:. https://ftp.gnu.org/gnu/glibc/. Then either inline LD_LIBRARY_PATH or export it with the location of glibc 2.23 being one of the first libraries locations it searches for. Then try rerunning the program. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:274,usability,help,helps,274,"@drtamermansour Why don't you download glibc 2.23 from here:. https://ftp.gnu.org/gnu/glibc/. Then either inline LD_LIBRARY_PATH or export it with the location of glibc 2.23 being one of the first libraries locations it searches for. Then try rerunning the program. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:245,availability,error,error,245,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:96,deployability,stack,stackoverflow,96,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:278,deployability,fail,fails,278,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:420,deployability,build,build,420,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:438,deployability,build,build,438,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:454,deployability,instal,install,454,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:521,deployability,instal,install,521,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:224,energy efficiency,optim,optimization,224,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:477,integrability,configur,configure,477,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:477,modifiability,configur,configure,477,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:224,performance,optimiz,optimization,224,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:245,performance,error,error,245,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:278,reliability,fail,fails,278,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:245,safety,error,error,245,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:477,security,configur,configure,477,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:245,usability,error,error,245,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:270,usability,command,command,270,"@pgrosu I could not compile the library on my server . I followed the suggestion [here](https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/851229#851229). I added CFLAGS=""-O2"" to address an optimization request error but still the make command fails to compile. ```. mkdir glibc && cd glibc. wget https://ftp.gnu.org/gnu/glibc/glibc-2.23.tar.gz. tar xvzf glibc-2.23.tar.gz. mkdir glibc-build && cd glibc-build. mkdir ../install. ../glibc-2.23/configure CFLAGS=""-O2"" --prefix $HOME/glibc/install. make -j `nproc`. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:105,availability,echo,echo,105,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:148,availability,echo,echo,148,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:14,deployability,updat,update,14,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:52,deployability,version,version,52,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:52,integrability,version,version,52,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:313,interoperability,share,shared-libraries-in-linux,313,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:52,modifiability,version,version,52,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:14,safety,updat,update,14,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:594,safety,test,test,594,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:14,security,updat,update,14,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:299,testability,understand,understanding-shared-libraries-in-linux,299,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:594,testability,test,test,594,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:60,usability,close,closer,60,"Right, so now update your LD_LIBRARY_PATH with this version closer to the beginning of it. Make sure you echo it first to see what it's set to via `echo $LD_LIBRARY_PATH` as you might want to include those things as well. Study the following two links for more information:. https://www.tecmint.com/understanding-shared-libraries-in-linux/. https://docs.oracle.com/cd/E19455-01/816-0559/chapter2-48927/index.html. LD_LIBRARY_PATH is a string of colon-separated paths that a program will search (from left-to-right) through for the libraries it needs. You don't have to export it if you want to test things like this:. LD_LIBRARY_PATH=....(your paths)... python $HOME/miniconda3/envs/deepVar...",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:80,deployability,instal,install,80,@pgrosu . I am sorry if I was not clear enough. I tried to say that I could not install glibc locally on my system. . I started the contact with the system administrator to see what they can do.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:34,usability,clear,clear,34,@pgrosu . I am sorry if I was not clear enough. I tried to say that I could not install glibc locally on my system. . I started the contact with the system administrator to see what they can do.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:34,deployability,instal,install,34,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:177,deployability,instal,install,177,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:197,deployability,updat,update,197,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:133,integrability,configur,configure,133,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:133,modifiability,configur,configure,133,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:197,safety,updat,update,197,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:133,security,configur,configure,133,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:197,security,updat,update,197,"@drtamermansour You don't have to install glibc, you just need to compile it in a local directory. Basically you just need to run `./configure` and `make` without running `make install`. Then just update `LD_LIBRARY_PATH` to include the local directory of the compiled glibc .so file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:59,usability,close,close,59,"@drtamermansour Were you able to resolve the problem? I'll close this issue for now, but feel free to reopen if you have any other questions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:579,availability,down,down,579,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:766,availability,error,error,766,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1020,availability,fault,fault,1020,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:30,deployability,instal,install,30,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:405,deployability,instal,installs,405,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1020,energy efficiency,fault,fault,1020,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1026,energy efficiency,core,core,1026,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:649,integrability,configur,configured,649,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:649,modifiability,configur,configured,649,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:766,performance,error,error,766,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1020,performance,fault,fault,1020,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1020,reliability,fault,fault,1020,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:766,safety,error,error,766,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:834,safety,test,test-math-isinff,834,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1020,safety,fault,fault,1020,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:258,security,privil,privileges,258,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:649,security,configur,configured,649,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:834,testability,test,test-math-isinff,834,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:291,usability,help,helped,291,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:745,usability,command,command,745,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:766,usability,error,error,766,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:855,usability,Command,Command,855,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:991,usability,command,command,991,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:1134,usability,help,help,1134,"Hi everyone, . I am trying to install the DeepVariant bioconda on RedHat Entreprise Server 7.2. I am really not familiar with conda but this looks like the most straightforward way to run deepvariant on a machine for which I do not (and will never get) sudo privileges. The above discussion helped to pass a lot of kinks but I am still struggling. . I am having the two following problems : . - conda now installs libcrypto.so.1.1 instead of libcrypto.so.1.0.0 . I solved it by adding a hard link from libcrypto.so.1.1 to a libcrypto.so.1.0.0 which is dirty and may break things down the line. - I am really struggling with compiling GLIBC-2.23 . I configured it with ""-O2 -g -Wall"" which are the gcc flags recommended in the RHES doc. The make command ran well (no error of what I can see) but when I do make check it crashes with . test-math-isinff.cc: Command not found. If I add the GLIBC path to my LD_LIBRARY_PATH as suggested by @pgrosu , it then corrupts the environment (i.e. every command goes to segmentation fault core dump) so I assume the GLIBC is not built properly . Do you have any idea about how to solve this ? Any help would be greatly appreciated. Thanks !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:332,deployability,instal,install,332,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:416,deployability,instal,install,416,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:307,energy efficiency,current,currently,307,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:568,energy efficiency,Current,Currently,568,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:99,safety,permiss,permission,99,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:164,safety,permiss,permission,164,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:757,safety,permiss,permission,757,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:34,testability,understand,understand,34,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:675,testability,understand,understanding,675,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:63,usability,help,help,63,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:72,usability,user,users,72,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:489,usability,user,users,489,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:582,usability,person,personally,582,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:731,usability,user,users,731,"Hi @frapaport , . I would like to understand better how we can help the users that don't have root permission. One question for you. Given that you don't have root permission on your machine, I assume that using our pre-built binaries is also not possible. (Because it requires running run-prereq.sh, which currently uses `sudo` to install a bunch of stuff.). Other than bioconda, are there other common ways to run/install softwares that you think works well? For example, several of our users mentioned Singularity. Have you used that, and would you consider that? (Currently I'm personally not very familiar with either bioconda or singularity. I'm trying to get a better understanding of what will be more generally useful for users who don't have root permission.) If you have any suggestions, please let me know! I'll come back to your questions later as well. Might take me a while to try this again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:279,availability,avail,available,279,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:113,deployability,instal,installation,113,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:259,deployability,instal,installed,259,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:440,deployability,instal,installation,440,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:300,interoperability,distribut,distributed,300,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:332,interoperability,distribut,distributed,332,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:518,performance,time,time,518,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:279,reliability,availab,available,279,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:279,safety,avail,available,279,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:432,safety,compl,complex,432,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:140,security,privil,privileges,140,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:279,security,availab,available,279,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:432,security,compl,complex,432,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:87,testability,understand,understanding,87,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:488,usability,help,help,488,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:540,usability,help,help,540,"Hi @pichuan , . I am actually not familiar with singularity. I checked the docs and my understanding is that the installation requires root privileges but, according to a quick forum searches, there are some ways to get around it. Most of the software I have installed is either available through R (distributed in bioconductor) or distributed as a JAR archive. I have had to run a few makefiles but I think deepvariant is the most complex installation I took care of myself (without the help of a sysadmin) in a long time. Thanks for your help !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:16,deployability,updat,update,16,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:104,deployability,releas,release,104,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:215,deployability,instal,install,215,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:285,deployability,releas,release,285,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:364,deployability,instal,installation,364,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:16,safety,updat,update,16,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:45,safety,test,tested,45,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:16,security,updat,update,16,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:45,testability,test,tested,45,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:338,usability,usab,usability,338,"@frapaport . an update on Singularity - I've tested our latest setting (which will come out in the next release) by converting it in to a Singularity image. It seems to work fine for me. So, if you would be able to install singularity, that will be an easier way forward once our next release is out. I'll still come back and revisit the usability of our bioconda installation. But might take a while.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:28,energy efficiency,GPU,GPUs-enabled,28,Please make sure you have a GPUs-enabled singularity image! :),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:28,performance,GPU,GPUs-enabled,28,Please make sure you have a GPUs-enabled singularity image! :),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:129,deployability,instal,install,129,"Thanks @pichuan , I will wait for the Singularity image then. If Singularity works then I will most likely not need the bioconda install.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4,availability,slo,slow,4,too slow to download the main soft,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:12,availability,down,download,12,too slow to download the main soft,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:4,reliability,slo,slow,4,too slow to download the main soft,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:454,deployability,updat,update,454,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:465,deployability,version,version,465,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:323,energy efficiency,GPU,GPU,323,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:385,integrability,topic,topic,385,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:465,integrability,version,version,465,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:174,interoperability,distribut,distribute,174,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:251,interoperability,share,share,251,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:465,modifiability,version,version,465,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:323,performance,GPU,GPU,323,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:454,safety,updat,update,454,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:454,security,updat,update,454,"Hi @frapaport , I added some notes about Singularity in https://github.com/google/deepvariant/issues/132#issuecomment-482430728 . I'm still figuring out what's a best way to distribute images. I do have the image files that I built. If it's useful to share those files, let me know. . @kokyriakidis I have an example for a GPU run in that comment as well. And, addressing the original topic about bioconda, I'll get in touch with @chapmanb to see how to update the version to 0.8.0 and I'll also see if I can try it out more myself as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/137:102,usability,close,close,102,This one seems a bit outdated. It seems like 0.8.0 is out and some issues were resolved already. I'll close this again...,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/137
https://github.com/google/deepvariant/issues/138:61,usability,command,command,61,@mosh305 could you post the full output of running the above command?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:184,availability,error,error,184,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:333,availability,error,error,333,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:763,deployability,contain,contains,763,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1095,deployability,contain,containing,1095,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:714,integrability,FILTER,FILTER,714,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:234,interoperability,format,formatted,234,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:726,interoperability,FORMAT,FORMAT,726,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:850,interoperability,specif,specification,850,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:184,performance,error,error,184,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:333,performance,error,error,333,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:184,safety,error,error,184,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:333,safety,error,error,333,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:184,usability,error,error,184,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:333,usability,error,error,333,"@mosh305 To add on, I tried running DeepVariant with these files and I ran into the following two issues. I am still curious to see the output from your run so that we can improve the error reporting. 1. The VCF file is not correctly formatted. If you try running `bcftools view data/NA12878.sorted.vcf.gz`, you will probably see an error regarding the header. I was able to fix this by correcting two lines in the VCF. The corrections are shown below. * Add a `#` to the beginning of line 4. ```. ##contig=<ID=chr1,length=249250621,assembly=hg19,md5=65f842b98f4298437d3e80f5979dc53b,species=""Homo sapiens"",taxonomy=x>. ```. * Reformat line 109 so that each field is tab-separated. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. ```. 2. The BAM file contains no information in the `QUAL` field (column 11), which is required as per the [specification](https://samtools.github.io/hts-specs/SAMv1.pdf) (see section 1.4). DeepVariant requires this field and cannot be run on the existing BAM file. One possible solution is to remap the corresponding FATSA file and generate a BAM file containing the `QUAL` string.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:79,availability,error,errors,79,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:556,deployability,log,log,556,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:582,deployability,log,log,582,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:653,deployability,log,log,653,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:79,performance,error,errors,79,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:300,performance,time,time,300,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:79,safety,error,errors,79,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:556,safety,log,log,556,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:582,safety,log,log,582,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:653,safety,log,log,653,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:556,security,log,log,556,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:582,security,log,log,582,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:653,security,log,log,653,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:556,testability,log,log,556,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:582,testability,log,log,582,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:653,testability,log,log,653,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:79,usability,error,errors,79,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:397,usability,help,help,397,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:520,usability,command,command,520,"@gunjanbaid Thanks for your response! I should have said that I had to fix the errors you listed in the first issue in order to run the script successfully, sorry about that. But thanks for pointing that out! About the second issue, as you can see the BAM file is very big therefore it may take some time to generate a corrected file. Yet if this is what needs to be done I would love to get some help on how to remap the reference and generate the BAM with the `QUAL` string :). I also attach the output of running the command above in the `make_examples.log` file. [make_examples.log](https://github.com/google/deepvariant/files/2752900/make_examples.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:964,availability,error,error,964,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1074,availability,error,error,1074,"ace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1403,deployability,log,log,1403,"mmend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunj",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1653,deployability,Log,Logging,1653,"0.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-01-15 00:54:34.238521: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM hea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:9974,deployability,fail,failed,9974,:34.243179 140481635538688 make_examples.py:782] Found 0 candidates in chr20:44001-45000 [0.00s elapsed]. I0115 00:55:34.244561 140481635538688 make_examples.py:782] Found 0 candidates in chr20:45001-46000 [0.00s elapsed]. I0115 00:55:34.245920 140481635538688 make_examples.py:782] Found 0 candidates in chr20:46001-47000 [0.00s elapsed]. I0115 00:55:34.247314 140481635538688 make_examples.py:782] Found 0 candidates in chr20:47001-48000 [0.00s elapsed]. I0115 00:55:34.248697 140481635538688 make_examples.py:782] Found 0 candidates in chr20:48001-49000 [0.00s elapsed]. I0115 00:55:34.250396 140481635538688 make_examples.py:782] Found 0 candidates in chr20:49001-50000 [0.00s elapsed]. I0115 00:55:34.252091 140481635538688 make_examples.py:782] Found 0 candidates in chr20:50001-51000 [0.00s elapsed]. I0115 00:55:34.253967 140481635538688 make_examples.py:782] Found 0 candidates in chr20:51001-52000 [0.00s elapsed]. I0115 00:55:34.255644 140481635538688 make_examples.py:782] Found 0 candidates in chr20:52001-53000 [0.00s elapsed]. I0115 00:55:34.257420 140481635538688 make_examples.py:782] Found 0 candidates in chr20:53001-54000 [0.00s elapsed]. I0115 00:55:34.259084 140481635538688 make_examples.py:782] Found 0 candidates in chr20:54001-55000 [0.00s elapsed]. I0115 00:55:34.260750 140481635538688 make_examples.py:782] Found 0 candidates in chr20:55001-56000 [0.00s elapsed]. I0115 00:55:34.262422 140481635538688 make_examples.py:782] Found 0 candidates in chr20:56001-57000 [0.00s elapsed]. I0115 00:55:34.264111 140481635538688 make_examples.py:782] Found 0 candidates in chr20:57001-58000 [0.00s elapsed]. I0115 00:55:34.265748 140481635538688 make_examples.py:782] Found 0 candidates in chr20:58001-59000 [0.00s elapsed]. I0115 00:55:34.267412 140481635538688 make_examples.py:782] Found 0 candidates in chr20:59001-60000 [0.00s elapsed]. 2019-01-15 00:55:34.300165: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (619 vs. 0). ```.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:323,modifiability,Pac,PacificBiosciences,323,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:451,modifiability,Pac,PacBio,451,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:964,performance,error,error,964,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1074,performance,error,error,1074,"ace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1349,performance,content,contents,1349,"ry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:9974,reliability,fail,failed,9974,:34.243179 140481635538688 make_examples.py:782] Found 0 candidates in chr20:44001-45000 [0.00s elapsed]. I0115 00:55:34.244561 140481635538688 make_examples.py:782] Found 0 candidates in chr20:45001-46000 [0.00s elapsed]. I0115 00:55:34.245920 140481635538688 make_examples.py:782] Found 0 candidates in chr20:46001-47000 [0.00s elapsed]. I0115 00:55:34.247314 140481635538688 make_examples.py:782] Found 0 candidates in chr20:47001-48000 [0.00s elapsed]. I0115 00:55:34.248697 140481635538688 make_examples.py:782] Found 0 candidates in chr20:48001-49000 [0.00s elapsed]. I0115 00:55:34.250396 140481635538688 make_examples.py:782] Found 0 candidates in chr20:49001-50000 [0.00s elapsed]. I0115 00:55:34.252091 140481635538688 make_examples.py:782] Found 0 candidates in chr20:50001-51000 [0.00s elapsed]. I0115 00:55:34.253967 140481635538688 make_examples.py:782] Found 0 candidates in chr20:51001-52000 [0.00s elapsed]. I0115 00:55:34.255644 140481635538688 make_examples.py:782] Found 0 candidates in chr20:52001-53000 [0.00s elapsed]. I0115 00:55:34.257420 140481635538688 make_examples.py:782] Found 0 candidates in chr20:53001-54000 [0.00s elapsed]. I0115 00:55:34.259084 140481635538688 make_examples.py:782] Found 0 candidates in chr20:54001-55000 [0.00s elapsed]. I0115 00:55:34.260750 140481635538688 make_examples.py:782] Found 0 candidates in chr20:55001-56000 [0.00s elapsed]. I0115 00:55:34.262422 140481635538688 make_examples.py:782] Found 0 candidates in chr20:56001-57000 [0.00s elapsed]. I0115 00:55:34.264111 140481635538688 make_examples.py:782] Found 0 candidates in chr20:57001-58000 [0.00s elapsed]. I0115 00:55:34.265748 140481635538688 make_examples.py:782] Found 0 candidates in chr20:58001-59000 [0.00s elapsed]. I0115 00:55:34.267412 140481635538688 make_examples.py:782] Found 0 candidates in chr20:59001-60000 [0.00s elapsed]. 2019-01-15 00:55:34.300165: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (619 vs. 0). ```.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:964,safety,error,error,964,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1074,safety,error,error,1074,"ace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1403,safety,log,log,1403,"mmend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunj",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1478,safety,input,input,1478,"take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1653,safety,Log,Logging,1653,"0.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-01-15 00:54:34.238521: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM hea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1875,safety,input,inputs,1875,".sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-01-15 00:54:34.238521: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:34.241249 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:34.262670 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:563,security,modif,modified,563,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1403,security,log,log,1403,"mmend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunj",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1653,security,Log,Logging,1653,"0.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-01-15 00:54:34.238521: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM hea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:75,testability,trace,trace,75,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1403,testability,log,log,1403,"mmend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunj",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1653,testability,Log,Logging,1653,"0.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-01-15 00:54:34.238521: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM hea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:23,usability,experien,experience,23,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:168,usability,indicat,indicates,168,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:278,usability,document,documentation,278,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:381,usability,help,help,381,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:534,usability,command,command,534,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:964,usability,error,error,964,"@mosh305 I do not have experience with mapping, but the [README](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I01",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1074,usability,error,error,1074,"ace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/README.txt) for the data indicates that it was mapped using `blasr v1.3.2 to the hg19 human reference genome`. You could check out the documentation for [blasr](https://github.com/PacificBiosciences/blasr). Sorry that I cannot be of more help here. Note: we recommend using the `--norealign_reads` flag with PacBio reads. Realigning will take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1478,usability,input,input,1478,"take way too long as the reads are very long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1518,usability,help,helps,1518,"long. So the command you posted should be modified as follows:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr20.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --regions ""chr20"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I third_party/nucleus/io/sam_reader.cc:56",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1875,usability,input,inputs,1875,".sorted.vcf.gz"" \. --norealign_reads. ```. When running with this flag, I run into an error that is due to the `QUAL` field missing (output shown below). I am not sure why you are not seeing this error, but you may want to check your data files. You could try the following:. * Regenerate `data/sorted_final_merged.bam.bai` and `data/NA12878.sorted.vcf.gz.tbi` as these seem to be older than the corresponding data files. . * Check the BAM file. Are you able to view the contents using `samtools`? I mention this because the log shows the following line: `[W::bam_hdr_read] EOF marker is absent. The input is probably truncated`. Hope this helps! ```. 2019-01-15 00:54:33.940093: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0115 00:54:33.942667 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.945646 140481635538688 make_examples.py:1024] Preparing inputs. 2019-01-15 00:54:33.956298: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:33.958478 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:33.978430 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0115 00:54:33.980473 140481635538688 make_examples.py:946] Common contigs are [u'chr20']. I0115 00:54:34.150244 140481635538688 make_examples.py:1030] Writing examples to /home/gunjanbaid/examples/training.examples.tfrecord.gz. 2019-01-15 00:54:34.151400: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-01-15 00:54:34.238521: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0115 00:54:34.241249 140481635538688 genomics_reader.py:174] Reading data/chr20.bam with NativeSamReader. I0115 00:54:34.262670 140481635538688 genomics_reader.py:174] Reading data/NA12878.sorted.vc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:662,availability,error,error,662,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:805,availability,error,error,805,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:4151,availability,error,error,4151,"134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py:782] Found 0 candidates in chr5:5001-6000 [0.00s elapsed]. I0120 14:08:30.692424 140531010582272 make_examples.py:782] Found 0 candidates in chr5:6001-7000 [0.00s elapsed]. I0120 14:08:30.693455 140531010582272 make_examples.py:782] Found 0 candidates in chr5:7001-8000 [0.00s elapsed]. I0120 14:08:30.694483 140531010582272 make_examples.py:782] Found 0 candidates in chr5:8001-9000 [0.00s elapsed]. I0120 14:08:30.695507 140531010582272 make_examples.py:782] Found 0 candidates in chr5:9001-10000 [0.00s elapsed]. 2019-01-20 14:08:30.703660: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (5 vs. 0). ```. So it seems there is a problem with the BAM file but only in some regions. Do you think this error will be resolved if I generate the BAM file again using blasr? [sorted_final_merged.header.sam.txt](https://github.com/google/deepvariant/files/2776530/sorted_final_merged.header.sam.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:682,deployability,log,log,682,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:3990,deployability,fail,failed,3990,"134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py:782] Found 0 candidates in chr5:5001-6000 [0.00s elapsed]. I0120 14:08:30.692424 140531010582272 make_examples.py:782] Found 0 candidates in chr5:6001-7000 [0.00s elapsed]. I0120 14:08:30.693455 140531010582272 make_examples.py:782] Found 0 candidates in chr5:7001-8000 [0.00s elapsed]. I0120 14:08:30.694483 140531010582272 make_examples.py:782] Found 0 candidates in chr5:8001-9000 [0.00s elapsed]. I0120 14:08:30.695507 140531010582272 make_examples.py:782] Found 0 candidates in chr5:9001-10000 [0.00s elapsed]. 2019-01-20 14:08:30.703660: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (5 vs. 0). ```. So it seems there is a problem with the BAM file but only in some regions. Do you think this error will be resolved if I generate the BAM file again using blasr? [sorted_final_merged.header.sam.txt](https://github.com/google/deepvariant/files/2776530/sorted_final_merged.header.sam.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:568,interoperability,format,format,568,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:494,performance,content,contents,494,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:662,performance,error,error,662,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:805,performance,error,error,805,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:4151,performance,error,error,4151,"134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py:782] Found 0 candidates in chr5:5001-6000 [0.00s elapsed]. I0120 14:08:30.692424 140531010582272 make_examples.py:782] Found 0 candidates in chr5:6001-7000 [0.00s elapsed]. I0120 14:08:30.693455 140531010582272 make_examples.py:782] Found 0 candidates in chr5:7001-8000 [0.00s elapsed]. I0120 14:08:30.694483 140531010582272 make_examples.py:782] Found 0 candidates in chr5:8001-9000 [0.00s elapsed]. I0120 14:08:30.695507 140531010582272 make_examples.py:782] Found 0 candidates in chr5:9001-10000 [0.00s elapsed]. 2019-01-20 14:08:30.703660: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (5 vs. 0). ```. So it seems there is a problem with the BAM file but only in some regions. Do you think this error will be resolved if I generate the BAM file again using blasr? [sorted_final_merged.header.sam.txt](https://github.com/google/deepvariant/files/2776530/sorted_final_merged.header.sam.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:3990,reliability,fail,failed,3990,"134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py:782] Found 0 candidates in chr5:5001-6000 [0.00s elapsed]. I0120 14:08:30.692424 140531010582272 make_examples.py:782] Found 0 candidates in chr5:6001-7000 [0.00s elapsed]. I0120 14:08:30.693455 140531010582272 make_examples.py:782] Found 0 candidates in chr5:7001-8000 [0.00s elapsed]. I0120 14:08:30.694483 140531010582272 make_examples.py:782] Found 0 candidates in chr5:8001-9000 [0.00s elapsed]. I0120 14:08:30.695507 140531010582272 make_examples.py:782] Found 0 candidates in chr5:9001-10000 [0.00s elapsed]. 2019-01-20 14:08:30.703660: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (5 vs. 0). ```. So it seems there is a problem with the BAM file but only in some regions. Do you think this error will be resolved if I generate the BAM file again using blasr? [sorted_final_merged.header.sam.txt](https://github.com/google/deepvariant/files/2776530/sorted_final_merged.header.sam.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:662,safety,error,error,662,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:682,safety,log,log,682,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:805,safety,error,error,805,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1249,safety,input,input,1249," index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1583,safety,input,inputs,1583,"ied running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-20 14:08:27.111294: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1635,safety,input,input,1635,"'t get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-20 14:08:27.111294: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:2400,safety,input,input,2400,"26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-20 14:08:27.111294: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:4151,safety,error,error,4151,"134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py:782] Found 0 candidates in chr5:5001-6000 [0.00s elapsed]. I0120 14:08:30.692424 140531010582272 make_examples.py:782] Found 0 candidates in chr5:6001-7000 [0.00s elapsed]. I0120 14:08:30.693455 140531010582272 make_examples.py:782] Found 0 candidates in chr5:7001-8000 [0.00s elapsed]. I0120 14:08:30.694483 140531010582272 make_examples.py:782] Found 0 candidates in chr5:8001-9000 [0.00s elapsed]. I0120 14:08:30.695507 140531010582272 make_examples.py:782] Found 0 candidates in chr5:9001-10000 [0.00s elapsed]. 2019-01-20 14:08:30.703660: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (5 vs. 0). ```. So it seems there is a problem with the BAM file but only in some regions. Do you think this error will be resolved if I generate the BAM file again using blasr? [sorted_final_merged.header.sam.txt](https://github.com/google/deepvariant/files/2776530/sorted_final_merged.header.sam.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:682,security,log,log,682,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:682,testability,log,log,682,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:74,usability,help,help,74,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:326,usability,command,command,326,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:602,usability,command,command,602,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:662,usability,error,error,662,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:735,usability,command,command,735,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:805,usability,error,error,805,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:824,usability,command,command,824,"Hello @gunjanbaid , sorry for not replying sooner, and thank you for your help so far! I am going to try generating the BAM file with blasr soon, hope it will work. Meanwhile I generated the `sorted_final_merged.bam.bai` and `NA12878.sorted.vcf.gz.tbi` index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1249,usability,input,input,1249," index files like you said so they won't be outdated. I'm able to run the command successfully with and without the flag `--norealign_reads` , although I still get the same warning about EOF marker being absent, and I'm also able to view the contents of the BAM file using samtools, I'm attaching it's header in SAM format below. I tried running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1583,usability,input,inputs,1583,"ied running the command again with `chr20` but I don't get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-20 14:08:27.111294: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1635,usability,input,input,1635,"'t get the missing QUAL error shown in your log. But the interesting part is I tried running the command with a different reference, for example `chr5`, and I got the error. This is the command I used:. ```. python bin/make_examples.zip \. --mode training \. --ref ""data/chr5.fa"" \. --reads ""data/sorted_final_merged.bam"" \. --examples ""training-examples/training_set.with_label.tfrecord.gz"" \. --confident_regions ""data/NA12878.sorted.bed"" \. --truth_variants ""data/NA12878.sorted.vcf.gz"" \. --regions ""chr5"" \. --norealign_reads. ```. and this is the output:. ```. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.680665: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-20 14:08:27.111294: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:2400,usability,input,input,2400,"26.682436 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.688049 140531010582272 make_examples.py:1024] Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:26.706452: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:26.708137 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:26.726283 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:26.727826 140531010582272 make_examples.py:946] Common contigs are [u'chr5']. I0120 14:08:27.110543 140531010582272 make_examples.py:1030] Writing examples to training-examples/training_set.with_label.tfrecord.gz. 2019-01-20 14:08:27.111294: I third_party/nucleus/io/sam_reader.cc:565] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:4151,usability,error,error,4151,"134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. 2019-01-20 14:08:27.176804: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring:. I0120 14:08:27.178606 140531010582272 genomics_reader.py:174] Reading data/sorted_final_merged.bam with NativeSamReader. I0120 14:08:27.193892 140531010582272 genomics_reader.py:174] Reading data/NA12878.sorted.vcf.gz with NativeVcfReader. I0120 14:08:30.685934 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1-1000 [3.57s elapsed]. I0120 14:08:30.687139 140531010582272 make_examples.py:782] Found 0 candidates in chr5:1001-2000 [0.00s elapsed]. I0120 14:08:30.688232 140531010582272 make_examples.py:782] Found 0 candidates in chr5:2001-3000 [0.00s elapsed]. I0120 14:08:30.689320 140531010582272 make_examples.py:782] Found 0 candidates in chr5:3001-4000 [0.00s elapsed]. I0120 14:08:30.690371 140531010582272 make_examples.py:782] Found 0 candidates in chr5:4001-5000 [0.00s elapsed]. I0120 14:08:30.691399 140531010582272 make_examples.py:782] Found 0 candidates in chr5:5001-6000 [0.00s elapsed]. I0120 14:08:30.692424 140531010582272 make_examples.py:782] Found 0 candidates in chr5:6001-7000 [0.00s elapsed]. I0120 14:08:30.693455 140531010582272 make_examples.py:782] Found 0 candidates in chr5:7001-8000 [0.00s elapsed]. I0120 14:08:30.694483 140531010582272 make_examples.py:782] Found 0 candidates in chr5:8001-9000 [0.00s elapsed]. I0120 14:08:30.695507 140531010582272 make_examples.py:782] Found 0 candidates in chr5:9001-10000 [0.00s elapsed]. 2019-01-20 14:08:30.703660: F deepvariant/allelecounter.cc:122] Check failed: offset + len <= read.aligned_quality_size() (5 vs. 0). ```. So it seems there is a problem with the BAM file but only in some regions. Do you think this error will be resolved if I generate the BAM file again using blasr? [sorted_final_merged.header.sam.txt](https://github.com/google/deepvariant/files/2776530/sorted_final_merged.header.sam.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:14,deployability,version,version,14,@mosh305 What version of samtools are you using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:14,integrability,version,version,14,@mosh305 What version of samtools are you using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:14,modifiability,version,version,14,@mosh305 What version of samtools are you using?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:242,availability,error,error,242,"@mosh305 I ran the below command and killed it before it had completed. Then, I tried to view the resulting BAM file using samtools and saw the EOF marking warning. Do you see this warning when viewing the file with samtools? To resolve this error, I would recommend downloading the BAM file again and maybe just pulling chromosome 20, as I did in the below command. It's possible that the earlier error was caused by an incomplete download. I am using verison 1.9 of samtools and htslib. I would recommend upgrading if you are using much older versions. ```. $ samtools --version. samtools 1.9. Using htslib 1.9. Copyright (C) 2018 Genome Research Ltd. $ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. $ samtools view -h chr20.bam | head. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. @HD	VN:1.4	GO:none	SO:coordinate. @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0. @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7. @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693. @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b. @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648. @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470. @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7. @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459. @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b. ```. Hopefully downloading the file again/remapping the reads will produce a clean BAM file. I am still not sure as to why you are not seeing the error with chromosome 20, but I'll let you know if anything else comes to mind.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:267,availability,down,downloading,267,"@mosh305 I ran the below command and killed it before it had completed. Then, I tried to view the resulting BAM file using samtools and saw the EOF marking warning. Do you see this warning when viewing the file with samtools? To resolve this error, I would recommend downloading the BAM file again and maybe just pulling chromosome 20, as I did in the below command. It's possible that the earlier error was caused by an incomplete download. I am using verison 1.9 of samtools and htslib. I would recommend upgrading if you are using much older versions. ```. $ samtools --version. samtools 1.9. Using htslib 1.9. Copyright (C) 2018 Genome Research Ltd. $ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. $ samtools view -h chr20.bam | head. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. @HD	VN:1.4	GO:none	SO:coordinate. @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0. @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7. @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693. @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b. @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648. @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470. @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7. @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459. @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b. ```. Hopefully downloading the file again/remapping the reads will produce a clean BAM file. I am still not sure as to why you are not seeing the error with chromosome 20, but I'll let you know if anything else comes to mind.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:398,availability,error,error,398,"@mosh305 I ran the below command and killed it before it had completed. Then, I tried to view the resulting BAM file using samtools and saw the EOF marking warning. Do you see this warning when viewing the file with samtools? To resolve this error, I would recommend downloading the BAM file again and maybe just pulling chromosome 20, as I did in the below command. It's possible that the earlier error was caused by an incomplete download. I am using verison 1.9 of samtools and htslib. I would recommend upgrading if you are using much older versions. ```. $ samtools --version. samtools 1.9. Using htslib 1.9. Copyright (C) 2018 Genome Research Ltd. $ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. $ samtools view -h chr20.bam | head. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. @HD	VN:1.4	GO:none	SO:coordinate. @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0. @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7. @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693. @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b. @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648. @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470. @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7. @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459. @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b. ```. Hopefully downloading the file again/remapping the reads will produce a clean BAM file. I am still not sure as to why you are not seeing the error with chromosome 20, but I'll let you know if anything else comes to mind.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:432,availability,down,download,432,"@mosh305 I ran the below command and killed it before it had completed. Then, I tried to view the resulting BAM file using samtools and saw the EOF marking warning. Do you see this warning when viewing the file with samtools? To resolve this error, I would recommend downloading the BAM file again and maybe just pulling chromosome 20, as I did in the below command. It's possible that the earlier error was caused by an incomplete download. I am using verison 1.9 of samtools and htslib. I would recommend upgrading if you are using much older versions. ```. $ samtools --version. samtools 1.9. Using htslib 1.9. Copyright (C) 2018 Genome Research Ltd. $ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. $ samtools view -h chr20.bam | head. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. @HD	VN:1.4	GO:none	SO:coordinate. @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0. @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7. @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693. @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b. @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648. @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470. @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7. @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459. @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b. ```. Hopefully downloading the file again/remapping the reads will produce a clean BAM file. I am still not sure as to why you are not seeing the error with chromosome 20, but I'll let you know if anything else comes to mind.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
https://github.com/google/deepvariant/issues/138:1508,availability,down,downloading,1508,"@mosh305 I ran the below command and killed it before it had completed. Then, I tried to view the resulting BAM file using samtools and saw the EOF marking warning. Do you see this warning when viewing the file with samtools? To resolve this error, I would recommend downloading the BAM file again and maybe just pulling chromosome 20, as I did in the below command. It's possible that the earlier error was caused by an incomplete download. I am using verison 1.9 of samtools and htslib. I would recommend upgrading if you are using much older versions. ```. $ samtools --version. samtools 1.9. Using htslib 1.9. Copyright (C) 2018 Genome Research Ltd. $ samtools view -h ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/sorted_final_merged.bam chr20 -o chr20.bam. $ samtools view -h chr20.bam | head. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. @HD	VN:1.4	GO:none	SO:coordinate. @SQ	SN:chrM	LN:16571	M5:6b9e15a5937653b0006de435f91578c0. @SQ	SN:chr1	LN:249250621	M5:94f0d1b1622299238a1d8a0711dd06c7. @SQ	SN:chr2	LN:243199373	M5:854e985b2e19c122b9f67f6453965693. @SQ	SN:chr3	LN:198022430	M5:8abc85e73b1c75518a03743de2c2b14b. @SQ	SN:chr4	LN:191154276	M5:2d37b4e662928cc6c58b84b2a4cc8648. @SQ	SN:chr5	LN:180915260	M5:250f4e82a213269b0a0e4aebb0468470. @SQ	SN:chr6	LN:171115067	M5:409088215d77f0bc72364b390430a5a7. @SQ	SN:chr7	LN:159138663	M5:ef15cde5c82fb860694bf8f611807459. @SQ	SN:chr8	LN:146364022	M5:8fbef8c3eaaac674cc6e690d1641464b. ```. Hopefully downloading the file again/remapping the reads will produce a clean BAM file. I am still not sure as to why you are not seeing the error with chromosome 20, but I'll let you know if anything else comes to mind.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/138
