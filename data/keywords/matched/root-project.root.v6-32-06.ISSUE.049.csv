id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/issues/8642:9175,availability,operat,operator,9175,"7:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9826,availability,Error,Error,9826,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9886,availability,failur,failure,9886,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:36,deployability,build,build,36,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:69,deployability,build,build,69,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:227,deployability,FAIL,FAILED,227,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:299,deployability,modul,module,299,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:3213,deployability,build,build,3213,"_insert_unique_node' requested here. return __h->_M_insert_unique_node(__n, __code, __p)->second;. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/unordered_map.h:978:16: note: in instantiation of member function 'std::__detail::_Map_base<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4378,deployability,build,build,4378,"edBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4411,deployability,fail,failure,4411,"<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4440,deployability,build,build,4440,"hProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4506,deployability,FAIL,FAILED,4506,"xx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4579,deployability,modul,module,4579,"basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'inte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9853,deployability,build,build,9853,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9886,deployability,fail,failure,9886,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9915,deployability,build,build,9915,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9997,deployability,build,build,9997,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:891,energy efficiency,alloc,allocator,891,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:1767,energy efficiency,alloc,allocator,1767,">, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node' requested here. return __h->_M_insert_unique_node(__n, __code, __p)->second;. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/unordered_map.h:978:16: note: in instantiation of member function 'std::__detail::_Map_base<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNam",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:2676,energy efficiency,alloc,allocator,2676,"::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node' requested here. return __h->_M_insert_unique_node(__n, __code, __p)->second;. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/unordered_map.h:978:16: note: in instantiation of member function 'std::__detail::_Map_base<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::In",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:3542,energy efficiency,alloc,allocator,3542,"tring<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4974,energy efficiency,alloc,allocator,4974,"r 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:6018,energy efficiency,alloc,allocator,6018,"ted here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:6996,energy efficiency,alloc,allocator,6996,"vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:8005,energy efficiency,alloc,allocator,8005,"le> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9045,energy efficiency,alloc,allocator,9045,">::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure cur",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9086,energy efficiency,alloc,allocator,9086,"{. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STA",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9135,energy efficiency,alloc,allocator,9135,"/../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detecte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:10047,energy efficiency,current,current,10047,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:10037,integrability,Configur,Configure,10037,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:3908,interoperability,convers,conversion,3908,"ing<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantia",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4182,interoperability,convers,conversion,4182,"}. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:167",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4959,interoperability,XML,XMLTag,4959,"constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4993,interoperability,XML,XMLTag,4993,"oid _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function '",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:5238,interoperability,convers,conversion,5238,"'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_cons",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:5516,interoperability,convers,conversion,5516,"rlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_cons",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:6213,interoperability,convers,conversion,6213,"ot viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integra",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:6491,interoperability,convers,conversion,6491,"ot viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integra",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:7194,interoperability,convers,conversion,7194,"ble: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:7472,interoperability,convers,conversion,7472,"ble: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:8230,interoperability,convers,conversion,8230,"to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:8508,interoperability,convers,conversion,8508," true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_ty",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9385,interoperability,convers,conversion,9385,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9663,interoperability,convers,conversion,9663,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:10110,interoperability,platform,platform,10110,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:299,modifiability,modul,module,299,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4579,modifiability,modul,module,4579,"basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'inte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:10037,modifiability,Configur,Configure,10037,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:75,performance,error,errors,75,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:429,performance,error,error,429,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4351,performance,Error,Error,4351,"ue_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4411,performance,failur,failure,4411,"<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4709,performance,error,error,4709,"> >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:5078,performance,content,contents,5078,"/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:5765,performance,error,error,5765,"ign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:6740,performance,error,error,6740,"s/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching m",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:7723,performance,error,error,7723,"ctor.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:8757,performance,error,error,8757,"r call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' fo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9826,performance,Error,Error,9826,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9886,performance,failur,failure,9886,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:227,reliability,FAIL,FAILED,227,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4411,reliability,fail,failure,4411,"<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4506,reliability,FAIL,FAILED,4506,"xx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9886,reliability,fail,failure,9886,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:75,safety,error,errors,75,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:299,safety,modul,module,299,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:429,safety,error,error,429,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4351,safety,Error,Error,4351,"ue_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4579,safety,modul,module,4579,"basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'inte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4709,safety,error,error,4709,"> >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:5765,safety,error,error,5765,"ign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:6740,safety,error,error,6740,"s/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching m",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:7723,safety,error,error,7723,"ctor.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:8757,safety,error,error,8757,"r call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' fo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9023,safety,compl,complex,9023,"::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9060,safety,compl,complex,9060,"requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9113,safety,compl,complex,9113,"redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platfor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9150,safety,compl,complex,9150,"+/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the defau",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9223,safety,compl,complex,9223,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9826,safety,Error,Error,9826,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:10133,safety,detect,detected,10133,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:409,security,hash,hashtable,409,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:612,security,hash,hashtable,612,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:1146,security,hash,hash,1146,"8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_reha",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:2022,security,hash,hash,2022,"OT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node' requested here. return __h->_M_insert_unique_node(__n, __code, __p)->second;. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/unordered_map.h:978:16: note: in instantiation of member function 'std::__detail::_Map_base<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:2931,security,hash,hash,2931,"> > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_insert_unique_node' requested here. return __h->_M_insert_unique_node(__n, __code, __p)->second;. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/unordered_map.h:978:16: note: in instantiation of member function 'std::__detail::_Map_base<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:3459,security,hash,hash,3459,"ail::_Map_base<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlay",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:3842,security,hash,hashtable,3842,", std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4116,security,hash,hashtable,4116,"true>::operator[]' requested here. { return _M_h[std::move(__k)]; }. ^. /home/jhahnfel/ROOT/build/include/TTreeReader.h:264:15: note: in instantiation of member function 'std::unordered_map<std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9023,security,compl,complex,9023,"::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9060,security,compl,complex,9060,"requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9113,security,compl,complex,9113,"redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platfor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9150,security,compl,complex,9150,"+/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the defau",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9223,security,compl,complex,9223,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:10037,security,Configur,Configure,10037,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:10133,security,detect,detected,10133,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:75,usability,error,errors,75,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:429,usability,error,error,429,"Switching CMAKE_CXX_STANDARD breaks build; ### Describe the bug. The build errors when switching from `CMAKE_CXX_STANDARD=14` (the default with GCC 8.4.1 on CentOS 8) to `CMAKE_CXX_STANDARD=17` (for example to get ROOT7). ```. FAILED: tree/treeplayer/G__TreePlayer.cxx lib/TreePlayer.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:2084:4: error: no matching member function for call to '_M_rehash_aux'. _M_rehash_aux(__n, __unique_keys());. ^~~~~~~~~~~~~. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:1730:8: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char> >, std::hash<std::__cxx11::string>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_rehash' requested here. _M_rehash(__do_rehash.second, __saved_state);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable_policy.h:739:16: note: in instantiation of member function 'std::_Hashtable<std::__cxx11::basic_string<char>, std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4351,usability,Error,Error,4351,"ue_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> >, std::hash<std::__cxx11::string>, std::equal_to<std::__cxx11::basic_string<char> >, std::allocator<std::pair<const std::__cxx11::basic_string<char>, std::unique_ptr<ROOT::Internal::TNamedBranchProxy, std::default_delete<ROOT::Internal::TNamedBranchProxy> > > > >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:4709,usability,error,error,4709,"> >::operator[]' requested here. fProxies[bpName].reset(p);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:915:12: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. void _M_rehash_aux(size_type __n, std::true_type);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/hashtable.h:918:12: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. void _M_rehash_aux(size_type __n, std::false_type);. ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libTreePlayer8033212c3f_dictUmbrella.h). ```. and. ```. FAILED: montecarlo/pythia8/G__EGPythia8.cxx lib/EGPythia8.pcm. [...]. In module 'std' imported from input_line_1:1:. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:5765,usability,error,error,5765,"ign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/LHEF3.h:212:25: note: in instantiation of member function 'std::vector<Pythia8::XMLTag *, std::allocator<Pythia8::XMLTag *> >::operator=' requested here. tags.back()->tags = findXMLTags(tags.back()->contents, &leftovers);. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:6740,usability,error,error,6740,"s/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:129:7: note: in instantiation of member function 'std::vector<int, std::allocator<int> >::operator=' requested here. class MVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching m",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:7723,usability,error,error,7723,"ctor.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:152:7: note: in instantiation of member function 'std::vector<double, std::allocator<double> >::operator=' requested here. class PVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd ar. gument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:8757,usability,error,error,8757,"r call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/Settings.h:175:7: note: in instantiation of member function 'std::vector<std::__cxx11::basic_string<char>, std::allocator<std::__cxx11::basic_string<char> > >::operator=' requested here. class WVec {. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' fo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9826,usability,Error,Error,9826,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8642:9983,usability,behavi,behavior,9983,"unction not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:601:2: error: no matching member function for call to '_M_move_assign'. _M_move_assign(std::move(__x), __bool_constant<__move_storage>());. ^~~~~~~~~~~~~~. /usr/include/Pythia8/HelicityBasics.h:240:9: note: in instantiation of member function 'std::vector<std::vector<std::complex<double>, std::allocator<std::complex<double> > >, std::allocator<std::vector<std::complex<double>, std::allocator<std::complex<double> > > > >::operator=' requested here. rho = vector< vector<complex> >(spinStates(),. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1677:7: note: candidate function not viable: no known conversion from 'integral_constant<...>' to 'integral_constant<...>' for 2nd argument. _M_move_assign(vector&& __x, std::true_type) noexcept. ^. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/bits/stl_vector.h:1688:7: note: candidate function not viable: no known conversion from 'integral_constant<[...], true aka true>' to 'integral_constant<[...], false>' for 2nd argument. _M_move_assign(vector&& __x, std::false_type). ^. Error: /home/jhahnfel/ROOT/build/bin/rootcling: compilation failure (/home/jhahnfel/ROOT/build/lib/libEGPythia898309100d9_dictUmbrella.h). ```. ### Expected behavior. The build should succeed. ### To Reproduce. Configure current `master` with `cmake -DCMAKE_CXX_STANDARD=14` (or on a platform where this is detected as the default) and then switch to `CMAKE_CXX_STANDARD=17`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8642
https://github.com/root-project/root/issues/8643:52,deployability,version,version,52,Some parts of ROOT still mention C++11; The minimum version is C++14 since #8583. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/core/foundation/inc/ROOT/RConfig.hxx#L47-L52. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/documentation/doxygen/Makefile#L27-L28. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/config/root-config.in#L348-L350. Possibly more in `pyroot` / `cppyy`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8643
https://github.com/root-project/root/issues/8643:165,energy efficiency,core,core,165,Some parts of ROOT still mention C++11; The minimum version is C++14 since #8583. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/core/foundation/inc/ROOT/RConfig.hxx#L47-L52. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/documentation/doxygen/Makefile#L27-L28. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/config/root-config.in#L348-L350. Possibly more in `pyroot` / `cppyy`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8643
https://github.com/root-project/root/issues/8643:52,integrability,version,version,52,Some parts of ROOT still mention C++11; The minimum version is C++14 since #8583. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/core/foundation/inc/ROOT/RConfig.hxx#L47-L52. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/documentation/doxygen/Makefile#L27-L28. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/config/root-config.in#L348-L350. Possibly more in `pyroot` / `cppyy`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8643
https://github.com/root-project/root/issues/8643:52,modifiability,version,version,52,Some parts of ROOT still mention C++11; The minimum version is C++14 since #8583. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/core/foundation/inc/ROOT/RConfig.hxx#L47-L52. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/documentation/doxygen/Makefile#L27-L28. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/config/root-config.in#L348-L350. Possibly more in `pyroot` / `cppyy`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8643
https://github.com/root-project/root/issues/8643:44,usability,minim,minimum,44,Some parts of ROOT still mention C++11; The minimum version is C++14 since #8583. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/core/foundation/inc/ROOT/RConfig.hxx#L47-L52. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/documentation/doxygen/Makefile#L27-L28. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/config/root-config.in#L348-L350. Possibly more in `pyroot` / `cppyy`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8643
https://github.com/root-project/root/issues/8643:294,usability,document,documentation,294,Some parts of ROOT still mention C++11; The minimum version is C++14 since #8583. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/core/foundation/inc/ROOT/RConfig.hxx#L47-L52. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/documentation/doxygen/Makefile#L27-L28. https://github.com/root-project/root/blob/8341e59956b08e78aea43bdcdb0ada478be7018b/config/root-config.in#L348-L350. Possibly more in `pyroot` / `cppyy`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8643
https://github.com/root-project/root/issues/8644:1010,availability,state,statement,1010,"rsion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_ca",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:0,deployability,Automat,Automatic,0,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:322,deployability,contain,container,322,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:591,deployability,automat,automatic,591,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1258,deployability,integr,integration,1258,"oncrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""le",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1311,deployability,contain,container,1311,"aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2130,deployability,contain,containers,2130,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2419,deployability,upgrad,upgrade,2419,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:688,energy efficiency,Load,Load,688,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:723,integrability,pub,public,723,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:837,integrability,pub,public,837,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1010,integrability,state,statement,1010,"rsion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_ca",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1258,integrability,integr,integration,1258,"oncrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""le",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:10,interoperability,convers,conversion,10,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:521,interoperability,share,share,521,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:601,interoperability,convers,conversion,601,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1258,interoperability,integr,integration,1258,"oncrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""le",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1258,modifiability,integr,integration,1258,"oncrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""le",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2419,modifiability,upgrad,upgrade,2419,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2471,modifiability,maintain,maintainers,2471,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:688,performance,Load,Load,688,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2427,performance,perform,performance,2427,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1258,reliability,integr,integration,1258,"oncrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""le",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:197,safety,compl,complicated,197,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2471,safety,maintain,maintainers,2471,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:197,security,compl,complicated,197,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1258,security,integr,integration,1258,"oncrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""le",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:0,testability,Automat,Automatic,0,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:591,testability,automat,automatic,591,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:1258,testability,integr,integration,1258,"oncrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""le",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:707,usability,user,user,707,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:821,usability,user,user,821,"Automatic conversion of TClonesArray in RDF; ### Explain what you would like to see improved. Reading [Delphes](https://github.com/delphes/delphes) trees (which use TClonesArray) with RDF is a bit complicated (see below) due to the need to cast elements to their concrete type, or convert the TClonesArray to a type-aware container (for reference: first brought up in https://root-forum.cern.ch/t/reading-tclonesarray-in-jitted-rdf/45784, thanks to @eguiraud for explaining why my naive code did not work). ### Optional: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2427,usability,perform,performance,2427,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/issues/8644:2445,usability,tool,tools,2445,"onal: share how it could be improved. The type information is stored, so an automatic conversion could be done. ### To Reproduce. ```python. import ROOT as gbl. gbl.gSystem.Load(""/afs/cern.ch/user/p/piedavid/public/delphes_bamboo/DelphesIO/libDelphesIO.so""). gbl.Electron. f = gbl.TFile.Open(""/afs/cern.ch/user/a/atalierc/public/snowmass/delphes_lhe_file_47_14TeV.lhe.root""). tree = f.Get(""Delphes""). df = gbl.ROOT.RDataFrame(tree). df.Define(""leadElPT"", ""Electron[0]->PT""). ```. where the last statement needs this to work (the typedef to distinguish the column and type name):. ```python. gbl.gInterpreter.Declare(""using delphes_electron = Electron;""). df.Define(""leadElPT1"", ""static_cast<delphes_electron*>(Electron[0])->PT""). ```. but for integration in an analysis framework, converting the container is more convenient. What I came up with is this:. ```C++. #include <TObjArray.h>. #include <ROOT/RVec.hxx>. namespace rdfhelpers {. template<typename OBJ>. ROOT::VecOps::RVec<OBJ*> objArrayToRVec(const TObjArray& arr) {. ROOT::VecOps::RVec<OBJ*> out{reinterpret_cast<OBJ**>(arr.GetObjectRef()), static_cast<std::size_t>(arr.GetEntries())};. auto it = *dynamic_cast<TObjArrayIter*>(arr.MakeIterator());. std::size_t i = 0;. while ( ( i != out.size() ) && ( out[i] == *it ) ) {. it.Next();. ++i;. }. if ( i != out.size() ) { // not equal to contiguous array, copy pointers. it.Reset();. const auto n = out.size();. out = ROOT::VecOps::RVec<OBJ*>();. out.reserve(n);. do {. out.push_back(static_cast<OBJ*>(*it));. } while ( it.Next() );. }. return out;. }. };. ```. then I can add a set of defines and use those containers instead:. ```python. df = df.Define(""myElectrons"", ""rdfhelpers::objArrayToRVec<delphes_electron>(Electron)""). df.Define(""leadElPT"", ""myElectrons[0]->PT""). ```. ### Setup. ROOT 6.24/00 from LCG_100 (x86_64-centos7-gcc10-opt) on lxplus. CC: @jnsandhya @selvaggi @pavel-demin (CMS upgrade performance study tools experts and Delphes maintainers, they may be interested as well)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8644
https://github.com/root-project/root/pull/8645:14,availability,state,statement,14,"[RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8645
https://github.com/root-project/root/pull/8645:73,availability,state,statement,73,"[RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8645
https://github.com/root-project/root/pull/8645:14,integrability,state,statement,14,"[RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8645
https://github.com/root-project/root/pull/8645:73,integrability,state,statement,73,"[RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8645
https://github.com/root-project/root/pull/8646:756,availability,operat,operation,756,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:133,deployability,log,logical,133,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:382,deployability,contain,contains,382,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1743,deployability,log,logic,1743,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1828,deployability,depend,depending,1828,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:822,energy efficiency,current,current,822,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1095,energy efficiency,current,current,1095,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1728,energy efficiency,adapt,adapted,1728,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:180,integrability,sub,subsequent,180,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:346,integrability,sub,subset,346,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1160,integrability,sub,sub-TEntryList,1160,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1728,integrability,adapt,adapted,1728,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1828,integrability,depend,depending,1828,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:49,interoperability,distribut,distributed,49,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:235,interoperability,distribut,distributed,235,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:546,interoperability,distribut,distributed,546,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1728,interoperability,adapt,adapted,1728,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1728,modifiability,adapt,adapted,1728,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1828,modifiability,depend,depending,1828,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1587,performance,time,times,1587,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1910,performance,time,times,1910,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:107,safety,input,input,107,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:133,safety,log,logical,133,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:855,safety,input,input,855,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:924,safety,input,input,924,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1615,safety,prevent,prevent,1615,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1722,safety,test,tests,1722,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1743,safety,log,logic,1743,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1770,safety,test,test,1770,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1828,safety,depend,depending,1828,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:133,security,log,logical,133,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1615,security,preven,prevent,1615,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1743,security,log,logic,1743,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:133,testability,log,logical,133,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1722,testability,test,tests,1722,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1743,testability,log,logic,1743,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1770,testability,test,test,1770,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:1828,testability,depend,depending,1828,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:107,usability,input,input,107,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:855,usability,input,input,855,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/pull/8646:924,usability,input,input,924,"[DF] TEntryList instead of Range for TTree based distributed RDF; This commit changes the way in which the input dataset is split in logical ranges of entries. It also changes the subsequent creation of an RDataFrame instance inside a distributed task. For a TTree based dataset, this happens through the creation of a TChain that represents the subset of the original dataset that contains the entries in the range. Before this commit:. For the TTree based case, the entries of the range are global with respect to the TChain created inside the distributed task. `TChain.SetCacheEntryRange` is called with the start and end entries of the range to make sure we don't read more than needed. An RDataFrame is created with the chain as argument. The `Range` operation is used to select only the entries of the TChain in the current task that are inside the input entry range. After this commit:. For the TTree based case, the input range will report global entries with respect to the TChain of the task. But it will also report local entries with respect to each single file of the TChain in the current task. A global TEntryList is created and filled with one sub-TEntryList per file in the chain. This allows to do a preselection directly in the TChain of the entries that should be processed or not. `SetCacheEntryRange` is still called to ensure we don't read more than needed (hence the need to still keep global entries in the range object). The TChain (with the TEntryList) is passed as argument to an RDataFrame constructor. ## TODOs. - [x] ~add some check against using multiple times the same filename, to prevent hitting https://github.com/root-project/root/issues/8505~ No longer needed after #8660 . - [x] Old tests adapted to new logic. - [x] Added one new test to check against reading the wrong number of entries depending on the number of partitions (a result of using TEntryList with multiple times the same treename and filename)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8646
https://github.com/root-project/root/issues/8647:7,availability,restor,restore,7,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:206,availability,Error,Error,206,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:269,availability,Error,Error,269,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:415,interoperability,share,share,415,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:206,performance,Error,Error,206,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:269,performance,Error,Error,269,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:7,reliability,restor,restore,7,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:206,safety,Error,Error,206,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:269,safety,Error,Error,269,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:806,security,Team,Team,806,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:206,usability,Error,Error,206,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:269,usability,Error,Error,269,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:374,usability,support,supported,374,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/issues/8647:970,usability,help,help,970,"TGHtml restore from TBrowser TFile; ### Explain what you would like to see improved. TGHtml objects can be stored into a TFile. However, when opening a TBrowser, right click or double click leads to:. ```. Error in <TQClass::New>: cannot create object of class TGHtml. Error in <TKey::ReadObj>: Cannot create new object of class TGHtml. ```. It would be nice if it would be supported in the TBrowser. ### Optional: share how it could be improved. - Right click, dump, prints the HTML code to terminal. - Double click reproduces the TGHtml on a canvas? ### To Reproduce. 1. Store TGHtml object to TFile. 2. Open TFile with TBrowser and double-click. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8647
https://github.com/root-project/root/pull/8648:20,availability,state,statement,20,"[v624][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8648
https://github.com/root-project/root/pull/8648:79,availability,state,statement,79,"[v624][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8648
https://github.com/root-project/root/pull/8648:20,integrability,state,statement,20,"[v624][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8648
https://github.com/root-project/root/pull/8648:79,integrability,state,statement,79,"[v624][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8648
https://github.com/root-project/root/pull/8649:21,availability,state,statement,21,"[v6.22][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8649
https://github.com/root-project/root/pull/8649:80,availability,state,statement,80,"[v6.22][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8649
https://github.com/root-project/root/pull/8649:21,integrability,state,statement,21,"[v6.22][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8649
https://github.com/root-project/root/pull/8649:80,integrability,state,statement,80,"[v6.22][RF] Fix `if` statement in HypoTestInverterResult::FindIndex(); The `if` statement in `HypoTestInverterResult::FindIndex()` didn't. consider the `xvalue == 1` case, resulting in no index being found. Backport of https://github.com/root-project/root/pull/8645.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8649
https://github.com/root-project/root/issues/8650:38,availability,sla,slash,38,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:129,availability,sla,slash,129,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:116,deployability,contain,containing,116,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:513,performance,TIME,TIME,513,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:38,reliability,sla,slash,38,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:129,reliability,sla,slash,129,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:797,security,Team,Team,797,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:286,usability,user,user-images,286,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:395,usability,behavi,behavior,395,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/issues/8650:961,usability,help,help,961,"TFile::ls hangs in infinite loop when slash in key; - [x] Checked for duplicates. ### Describe the bug. In a TNamed containing a slash, TFile::ls hangs infinitely. (It thinks it's a directory instead of a TNamed?). On the other hand, TBrowser works fine in listing it. ![image](https://user-images.githubusercontent.com/10653970/125351279-345fef00-e360-11eb-94ff-2c48d1b894cf.png). ### Expected behavior. No infinite loop. ### To Reproduce. ```. TFile* aFile = new TFile(""/tmp/tnamed.root"", ""RECREATE"");. TNamed(""TIME/CLK"", ""0x6"").Write();. aFile->ls();. ```. It hangs. Open instead a TBrowser. That works fine and key is listed correctly. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.25/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on May 17 2021, 10:49:42 |. | From heads/master@v6-25-01-861-g5ea261143f |. | With |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8650
https://github.com/root-project/root/pull/8651:144,deployability,updat,updated,144,"Use -isystem for RCpp, suppresses its warnings.; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8651
https://github.com/root-project/root/pull/8651:114,safety,test,tested,114,"Use -isystem for RCpp, suppresses its warnings.; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8651
https://github.com/root-project/root/pull/8651:144,safety,updat,updated,144,"Use -isystem for RCpp, suppresses its warnings.; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8651
https://github.com/root-project/root/pull/8651:144,security,updat,updated,144,"Use -isystem for RCpp, suppresses its warnings.; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8651
https://github.com/root-project/root/pull/8651:114,testability,test,tested,114,"Use -isystem for RCpp, suppresses its warnings.; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8651
https://github.com/root-project/root/issues/8652:302,availability,state,states,302,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:141,deployability,releas,releasing,141,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:302,integrability,state,states,302,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:36,performance,I/O,I/O,36,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:197,performance,I/O,I/O,197,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:230,performance,I/O,I/O,230,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:543,performance,I/O,I/O,543,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:12,safety,accid,accidentally,12,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:92,usability,Stop,Stop,92,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:98,usability,stop,stop,98,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:189,usability,support,support,189,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:292,usability,minim,minimiser,292,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:336,usability,support,support,336,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:394,usability,support,support,394,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/issues/8652:535,usability,support,support,535,"[RF] Remove accidentally introduced I/O capabilities of RooMinimizer.; @guitargeek @egpbos. Stop, stop!! e3b73a8 needs to be reverted before releasing ROOT. `ClassDef(..., 0)` means: Don't support I/O. In e3b73a8, you switched on I/O capabilities, so please revert! When people start writing minimiser states to files, you will have to support deserialisation in the future. It's better to not support that. **That by the way also holds for any classes the are introduced in the MP-PRs. Please consider well wether they are allowed to support I/O or not.**. _Originally posted by @hageboeck in https://github.com/root-project/root/issues/8569#issuecomment-878850453_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8652
https://github.com/root-project/root/pull/8653:88,deployability,version,version,88,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8653:88,integrability,version,version,88,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8653:88,modifiability,version,version,88,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8653:31,performance,I/O,I/O,31,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8653:165,performance,I/O,I/O,165,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8653:7,safety,accid,accidentally,7,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8653:216,usability,guid,guides,216,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8653:223,usability,user,users-guide,223,"Remove accidentally introduced I/O capabilities of RooMinimizer; #8569 set the ClassDef version to 1, while it was zero before. Zero was a special value meaning ""no I/O needed"" (see https://root.cern.ch/root/html534/guides/users-guide/AddingaClass.html#motivation). This PR/commit resets it to zero. Fixes #8652.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8653
https://github.com/root-project/root/pull/8654:152,deployability,integr,integration,152,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:95,integrability,repositor,repository,95,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:152,integrability,integr,integration,152,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:95,interoperability,repositor,repository,95,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:152,interoperability,integr,integration,152,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:152,modifiability,integr,integration,152,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:152,reliability,integr,integration,152,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:70,safety,test,tested,70,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:152,security,integr,integration,152,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:70,testability,test,tested,70,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:152,testability,integr,integration,152,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/pull/8654:11,usability,workflow,workflow,11,"Add GitHub workflow to warn about closing issues without a project; I tested this in a private repository, but unfortunately I can only check the final integration after merging...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8654
https://github.com/root-project/root/issues/8655:1,deployability,Build,Build,1,"[Build system] ROOT installs its builtins directly into `CMAKE_INSTALL_PREFIX`.; - [x] Checked for duplicates. ### Describe the bug. When you install a ROOT with builtins, it also installs the builtin headers (+ libraries probably) into the system directory. This might be at least surprising, if not annoying. ### Expected behavior. If builtins are needed, they could go into `${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}` or similar. This unfortunately requires going through all builtins, and changing their install locations, but I don't see a way around that. ### To Reproduce. ```. cmake -DCMAKE_INSTALL_PREFIX=/tmp/dummyInstallation <path/to/root>. make -j install. ```. ### Setup. Master, linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8655
https://github.com/root-project/root/issues/8655:20,deployability,instal,installs,20,"[Build system] ROOT installs its builtins directly into `CMAKE_INSTALL_PREFIX`.; - [x] Checked for duplicates. ### Describe the bug. When you install a ROOT with builtins, it also installs the builtin headers (+ libraries probably) into the system directory. This might be at least surprising, if not annoying. ### Expected behavior. If builtins are needed, they could go into `${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}` or similar. This unfortunately requires going through all builtins, and changing their install locations, but I don't see a way around that. ### To Reproduce. ```. cmake -DCMAKE_INSTALL_PREFIX=/tmp/dummyInstallation <path/to/root>. make -j install. ```. ### Setup. Master, linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8655
https://github.com/root-project/root/issues/8655:142,deployability,instal,install,142,"[Build system] ROOT installs its builtins directly into `CMAKE_INSTALL_PREFIX`.; - [x] Checked for duplicates. ### Describe the bug. When you install a ROOT with builtins, it also installs the builtin headers (+ libraries probably) into the system directory. This might be at least surprising, if not annoying. ### Expected behavior. If builtins are needed, they could go into `${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}` or similar. This unfortunately requires going through all builtins, and changing their install locations, but I don't see a way around that. ### To Reproduce. ```. cmake -DCMAKE_INSTALL_PREFIX=/tmp/dummyInstallation <path/to/root>. make -j install. ```. ### Setup. Master, linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8655
https://github.com/root-project/root/issues/8655:180,deployability,instal,installs,180,"[Build system] ROOT installs its builtins directly into `CMAKE_INSTALL_PREFIX`.; - [x] Checked for duplicates. ### Describe the bug. When you install a ROOT with builtins, it also installs the builtin headers (+ libraries probably) into the system directory. This might be at least surprising, if not annoying. ### Expected behavior. If builtins are needed, they could go into `${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}` or similar. This unfortunately requires going through all builtins, and changing their install locations, but I don't see a way around that. ### To Reproduce. ```. cmake -DCMAKE_INSTALL_PREFIX=/tmp/dummyInstallation <path/to/root>. make -j install. ```. ### Setup. Master, linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8655
https://github.com/root-project/root/issues/8655:513,deployability,instal,install,513,"[Build system] ROOT installs its builtins directly into `CMAKE_INSTALL_PREFIX`.; - [x] Checked for duplicates. ### Describe the bug. When you install a ROOT with builtins, it also installs the builtin headers (+ libraries probably) into the system directory. This might be at least surprising, if not annoying. ### Expected behavior. If builtins are needed, they could go into `${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}` or similar. This unfortunately requires going through all builtins, and changing their install locations, but I don't see a way around that. ### To Reproduce. ```. cmake -DCMAKE_INSTALL_PREFIX=/tmp/dummyInstallation <path/to/root>. make -j install. ```. ### Setup. Master, linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8655
https://github.com/root-project/root/issues/8655:666,deployability,instal,install,666,"[Build system] ROOT installs its builtins directly into `CMAKE_INSTALL_PREFIX`.; - [x] Checked for duplicates. ### Describe the bug. When you install a ROOT with builtins, it also installs the builtin headers (+ libraries probably) into the system directory. This might be at least surprising, if not annoying. ### Expected behavior. If builtins are needed, they could go into `${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}` or similar. This unfortunately requires going through all builtins, and changing their install locations, but I don't see a way around that. ### To Reproduce. ```. cmake -DCMAKE_INSTALL_PREFIX=/tmp/dummyInstallation <path/to/root>. make -j install. ```. ### Setup. Master, linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8655
https://github.com/root-project/root/issues/8655:324,usability,behavi,behavior,324,"[Build system] ROOT installs its builtins directly into `CMAKE_INSTALL_PREFIX`.; - [x] Checked for duplicates. ### Describe the bug. When you install a ROOT with builtins, it also installs the builtin headers (+ libraries probably) into the system directory. This might be at least surprising, if not annoying. ### Expected behavior. If builtins are needed, they could go into `${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}` or similar. This unfortunately requires going through all builtins, and changing their install locations, but I don't see a way around that. ### To Reproduce. ```. cmake -DCMAKE_INSTALL_PREFIX=/tmp/dummyInstallation <path/to/root>. make -j install. ```. ### Setup. Master, linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8655
https://github.com/root-project/root/pull/8656:131,security,sign,signal,131,"Pass emit argument to TGNumberEntryField::SetNumber; # This Pull request:. ## Changes or fixes:. Adds capability of not emitting a signal when calling SetNumber from user-code, in analogy with SetText.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8656
https://github.com/root-project/root/pull/8656:166,usability,user,user-code,166,"Pass emit argument to TGNumberEntryField::SetNumber; # This Pull request:. ## Changes or fixes:. Adds capability of not emitting a signal when calling SetNumber from user-code, in analogy with SetText.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8656
https://github.com/root-project/root/pull/8657:68,availability,error,errors,68,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8657:234,availability,operat,operator,234,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8657:68,performance,error,errors,68,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8657:68,safety,error,errors,68,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8657:430,safety,prevent,prevent,430,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8657:430,security,preven,prevent,430,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8657:68,usability,error,errors,68,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8657:442,usability,command,command,442,"Fix /std:c++17 on Windows + silent some warnings; - Fix compilation errors with `/std:c++17` (and later) option on Windows. - Add `/std:c++17` flag for ACLiC. - Add the `-wd4146` compiler flag to ignore the warning C4146: unary minus operator applied to unsigned type, result still unsigned (in LLVM). - Add a the missing `#include <typeinfo>` and `#include <stdexcept>` with `/std:c++17`. - Don't add the `-fPIC` flag with MSVC (prevent the command line warning D9002: ignoring unknown option '-fPIC')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8657
https://github.com/root-project/root/pull/8658:109,availability,ping,pinging,109,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8658:163,deployability,version,version,163,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8658:163,integrability,version,version,163,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8658:163,modifiability,version,version,163,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8658:11,usability,workflow,workflow,11,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8658:40,usability,close,closed,40,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8658:121,usability,person,person,121,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8658:132,usability,close,closed,132,"Add GitHub workflow with daily check of closed issues [skip-ci]; Nudge about those issues without a project, pinging the person who closed and all assignees. (new version of #8654 which runs daily instead of immediately after closing an issue)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8658
https://github.com/root-project/root/pull/8659:17,deployability,updat,update,17,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:202,deployability,Updat,Update,202,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:235,deployability,releas,release,235,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:17,safety,updat,update,17,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:151,safety,avoid,avoid,151,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:202,safety,Updat,Update,202,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:17,security,updat,update,17,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:164,security,Modif,Modified,164,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:202,security,Updat,Update,202,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8659:51,usability,interact,interactive,51,"Fix `TWebCanvas` update and zooming; 1. When doing interactive zooming, do not reset zoom range from TCanvas range. 2. When apply changes from client, avoid `TPad::Modified()` if nothing is changed. 3. Update JSROOT with code of 6.2.0 release",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8659
https://github.com/root-project/root/pull/8660:463,availability,sli,slight,463,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:353,deployability,log,logic,353,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:563,energy efficiency,current,current,563,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:594,energy efficiency,Current,Currently,594,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:293,integrability,sub,sub,293,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:521,integrability,sub,sub-TEntryList,521,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:571,integrability,sub,sub-tree,571,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:704,integrability,sub,sub-TEntryList,704,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:775,integrability,sub,sublists,775,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:268,interoperability,specif,specifically,268,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:463,reliability,sli,slight,463,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:343,safety,avoid,avoid,343,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:353,safety,log,logic,353,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:908,safety,valid,valid,908,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:353,security,log,logic,353,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:470,security,modif,modification,470,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:353,testability,log,logic,353,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8660:16,usability,support,supporting,16,"Possible way of supporting multiple files with same name with TEntryList; This PR shows the ingredients needed to provide a fix (or more like a workaround) to https://github.com/root-project/root/issues/8505. * A new function `TEntryList::AddSubList` which purpose is specifically of adding a sub list to the main TEntryList. With this we can avoid the logic of `TEntryList::Add` that merges multiple TEntryList referring to the same tree into a global list. * A slight modification in `TChain::SetEntryList` to grab the sub-TEntryList with the same index as the current sub-tree in the chain. Currently, this is done instead with `GetEntryList(treename, filename, opt)` that will always report the same sub-TEntryList referring to the ""first"" file (because all files of the sublists of the global TEntryList have the same name). The changes are not definitive at all. I wanted to ask your opinion if it's a valid way forward. If so, I will polish the code and prepare it for a real PR. With this commit, the following snippet. ```cpp. int main(){. auto start_1{0};. auto start_2{0};. auto end_1{20};. auto end_2{10};. TEntryList elists;. TEntryList elist1{""e"",""e"",""entries"",""file_20entries_1.root""};. TEntryList elist2{""e"",""e"",""entries"",""file_20entries_1.root""};. for(auto entry = start_1; entry < end_1; entry++){. elist1.Enter(entry);. }. for(auto entry = start_2; entry < end_2; entry++){. elist2.Enter(entry);. }. elists.AddSubList(&elist1);. elists.AddSubList(&elist2);. TChain chain{""entries""};. chain.Add(""file_20entries_1.root"");. chain.Add(""file_20entries_1.root"");. chain.SetEntryList(&elists, ""sync"");. ROOT::RDataFrame df{chain};. std::cout << df.Count().GetValue() << ""\n"";. }. ```. Outputs the correct result:. ```. $: ./tentrylist_emptysource_addsublist . 30. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8660
https://github.com/root-project/root/pull/8661:199,availability,avail,available,199,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:327,availability,avail,available-after-loading-dictionary,327,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:267,energy efficiency,load,loaded,267,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:343,energy efficiency,load,loading-dictionary,343,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:267,performance,load,loaded,267,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:343,performance,load,loading-dictionary,343,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:199,reliability,availab,available,199,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:327,reliability,availab,available-after-loading-dictionary,327,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:199,safety,avail,available,199,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:327,safety,avail,available-after-loading-dictionary,327,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:199,security,availab,available,199,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8661:327,security,availab,available-after-loading-dictionary,327,"[dictgen] Also forward declare namespaces, typedefs, enums:; They were picked up as side effects of classes, but not forward declared as. and by themselves. This fixes namespaces and enums not being available / known at the ROOT prompt despite their dictionary being loaded:. https://root-forum.cern.ch/t/enum-in-namespace-not-available-after-loading-dictionary/45757.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8661
https://github.com/root-project/root/pull/8662:15,usability,interact,interactive,15,Fix TWebCanvas interactive zooming [6.24];,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8662
https://github.com/root-project/root/pull/8664:45,interoperability,Bind,BindKeys,45,[gui][skip-ci] Fix typo in `TRootGuiBuilder::BindKeys()` documentation; # This Pull request:. ## Changes or fixes:. Typo in `TRootGuiBuilder::BindKeys` docu. This PR supersedes https://github.com/root-project/root/pull/8663.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8664
https://github.com/root-project/root/pull/8664:142,interoperability,Bind,BindKeys,142,[gui][skip-ci] Fix typo in `TRootGuiBuilder::BindKeys()` documentation; # This Pull request:. ## Changes or fixes:. Typo in `TRootGuiBuilder::BindKeys` docu. This PR supersedes https://github.com/root-project/root/pull/8663.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8664
https://github.com/root-project/root/pull/8664:45,modifiability,Bind,BindKeys,45,[gui][skip-ci] Fix typo in `TRootGuiBuilder::BindKeys()` documentation; # This Pull request:. ## Changes or fixes:. Typo in `TRootGuiBuilder::BindKeys` docu. This PR supersedes https://github.com/root-project/root/pull/8663.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8664
https://github.com/root-project/root/pull/8664:142,modifiability,Bind,BindKeys,142,[gui][skip-ci] Fix typo in `TRootGuiBuilder::BindKeys()` documentation; # This Pull request:. ## Changes or fixes:. Typo in `TRootGuiBuilder::BindKeys` docu. This PR supersedes https://github.com/root-project/root/pull/8663.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8664
https://github.com/root-project/root/pull/8664:57,usability,document,documentation,57,[gui][skip-ci] Fix typo in `TRootGuiBuilder::BindKeys()` documentation; # This Pull request:. ## Changes or fixes:. Typo in `TRootGuiBuilder::BindKeys` docu. This PR supersedes https://github.com/root-project/root/pull/8663.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8664
https://github.com/root-project/root/issues/8665:446,integrability,event,event,446,"GrabKey not working with kKeyControlMask on TGX11; - [x] Checked for duplicates. ### Describe the bug. In TGMainWindow, if I call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kKeyControlMask, kTRUE); //capture CTRL+C`. and press CTRL+C, it never reaches the HandleKey function. If I instead call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kAnyModifier, kTRUE);`. it reaches the HandleKey function:. `event->fState = 20, event->fState & kKeyControlMask = 4`. This is also the reason why some of TRootGuiBuilder shortcuts are not working. ![image](https://user-images.githubusercontent.com/10653970/125503490-0ccae6c6-8757-42f7-aad4-acf563b0b9a6.png). ### Expected behavior. GrabKey works well with kKeyControlMask on TGX11. ### To Reproduce. 1. new TRootGuiBuilder. 2. Press CTRL+N. 3. It does not do anything. ### Setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8665
https://github.com/root-project/root/issues/8665:466,integrability,event,event,466,"GrabKey not working with kKeyControlMask on TGX11; - [x] Checked for duplicates. ### Describe the bug. In TGMainWindow, if I call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kKeyControlMask, kTRUE); //capture CTRL+C`. and press CTRL+C, it never reaches the HandleKey function. If I instead call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kAnyModifier, kTRUE);`. it reaches the HandleKey function:. `event->fState = 20, event->fState & kKeyControlMask = 4`. This is also the reason why some of TRootGuiBuilder shortcuts are not working. ![image](https://user-images.githubusercontent.com/10653970/125503490-0ccae6c6-8757-42f7-aad4-acf563b0b9a6.png). ### Expected behavior. GrabKey works well with kKeyControlMask on TGX11. ### To Reproduce. 1. new TRootGuiBuilder. 2. Press CTRL+N. 3. It does not do anything. ### Setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8665
https://github.com/root-project/root/issues/8665:834,reliability,doe,does,834,"GrabKey not working with kKeyControlMask on TGX11; - [x] Checked for duplicates. ### Describe the bug. In TGMainWindow, if I call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kKeyControlMask, kTRUE); //capture CTRL+C`. and press CTRL+C, it never reaches the HandleKey function. If I instead call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kAnyModifier, kTRUE);`. it reaches the HandleKey function:. `event->fState = 20, event->fState & kKeyControlMask = 4`. This is also the reason why some of TRootGuiBuilder shortcuts are not working. ![image](https://user-images.githubusercontent.com/10653970/125503490-0ccae6c6-8757-42f7-aad4-acf563b0b9a6.png). ### Expected behavior. GrabKey works well with kKeyControlMask on TGX11. ### To Reproduce. 1. new TRootGuiBuilder. 2. Press CTRL+N. 3. It does not do anything. ### Setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8665
https://github.com/root-project/root/issues/8665:556,usability,shortcut,shortcuts,556,"GrabKey not working with kKeyControlMask on TGX11; - [x] Checked for duplicates. ### Describe the bug. In TGMainWindow, if I call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kKeyControlMask, kTRUE); //capture CTRL+C`. and press CTRL+C, it never reaches the HandleKey function. If I instead call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kAnyModifier, kTRUE);`. it reaches the HandleKey function:. `event->fState = 20, event->fState & kKeyControlMask = 4`. This is also the reason why some of TRootGuiBuilder shortcuts are not working. ![image](https://user-images.githubusercontent.com/10653970/125503490-0ccae6c6-8757-42f7-aad4-acf563b0b9a6.png). ### Expected behavior. GrabKey works well with kKeyControlMask on TGX11. ### To Reproduce. 1. new TRootGuiBuilder. 2. Press CTRL+N. 3. It does not do anything. ### Setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8665
https://github.com/root-project/root/issues/8665:600,usability,user,user-images,600,"GrabKey not working with kKeyControlMask on TGX11; - [x] Checked for duplicates. ### Describe the bug. In TGMainWindow, if I call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kKeyControlMask, kTRUE); //capture CTRL+C`. and press CTRL+C, it never reaches the HandleKey function. If I instead call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kAnyModifier, kTRUE);`. it reaches the HandleKey function:. `event->fState = 20, event->fState & kKeyControlMask = 4`. This is also the reason why some of TRootGuiBuilder shortcuts are not working. ![image](https://user-images.githubusercontent.com/10653970/125503490-0ccae6c6-8757-42f7-aad4-acf563b0b9a6.png). ### Expected behavior. GrabKey works well with kKeyControlMask on TGX11. ### To Reproduce. 1. new TRootGuiBuilder. 2. Press CTRL+N. 3. It does not do anything. ### Setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8665
https://github.com/root-project/root/issues/8665:709,usability,behavi,behavior,709,"GrabKey not working with kKeyControlMask on TGX11; - [x] Checked for duplicates. ### Describe the bug. In TGMainWindow, if I call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kKeyControlMask, kTRUE); //capture CTRL+C`. and press CTRL+C, it never reaches the HandleKey function. If I instead call:. `gVirtualX->GrabKey(GetId(), gVirtualX->KeysymToKeycode(kKey_c), kAnyModifier, kTRUE);`. it reaches the HandleKey function:. `event->fState = 20, event->fState & kKeyControlMask = 4`. This is also the reason why some of TRootGuiBuilder shortcuts are not working. ![image](https://user-images.githubusercontent.com/10653970/125503490-0ccae6c6-8757-42f7-aad4-acf563b0b9a6.png). ### Expected behavior. GrabKey works well with kKeyControlMask on TGX11. ### To Reproduce. 1. new TRootGuiBuilder. 2. Press CTRL+N. 3. It does not do anything. ### Setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8665
https://github.com/root-project/root/pull/8666:337,energy efficiency,Model,Models,337,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:452,energy efficiency,model,model,452,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:524,energy efficiency,model,model,524,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:564,energy efficiency,model,model,564,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:577,energy efficiency,model,model,577,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:692,energy efficiency,model,model,692,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:729,energy efficiency,model,model,729,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:753,energy efficiency,model,model,753,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:760,energy efficiency,model,model,760,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:784,energy efficiency,model,model,784,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:804,energy efficiency,model,model,804,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:828,energy efficiency,model,model,828,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:259,safety,test,tested,259,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:289,safety,Test,Tests,289,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:303,safety,Test,Tests,303,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:153,security,modif,modifying,153,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:337,security,Model,Models,337,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:452,security,model,model,452,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:524,security,model,model,524,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:564,security,model,model,564,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:577,security,model,model,577,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:692,security,model,model,692,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:729,security,model,model,729,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:753,security,model,model,753,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:760,security,model,model,760,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:784,security,model,model,784,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:804,security,model,model,804,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:828,security,model,model,828,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:259,testability,test,tested,259,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:289,testability,Test,Tests,289,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:303,testability,Test,Tests,303,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:117,usability,custom,custom,117,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:330,usability,Custom,Custom,330,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:592,usability,Close,Close,592,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8666:774,usability,Close,Close,774,"[GSoC][TMVA][SOFIE] Serialisation of RModel; ### Description. This PR implements serialisation of RModel by adding a custom streamer in class RModel and modifying the definition of structure TMVA::Experimental::SOFIE::InitializedTensor. ### Checklist:. - [x] tested changes locally. . ### Tests . - [x] Tests for Serialisation of Custom Models . ### Example usage . **Writing the RModel object** . ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""CREATE"");. SOFIE::RModelParser_ONNX parser;. SOFIE::RModel model = parser.Parse(""Linear_2.onnx"");. model.Write(""model"");. file.Close();. ```. **Reading the RModel object**. ```. using namespace TMVA::Experimental;. TFile file(""model.root"",""READ"");. SOFIE::RModel *model;. file.GetObject(""model"",model);. file.Close();. model->Generate();. model->OutputGenerated(""model.hxx"");. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8666
https://github.com/root-project/root/pull/8667:1678,deployability,updat,updated,1678,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:941,integrability,pub,public,941,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:963,integrability,pub,public,963,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:65,safety,hot,hotkey,65,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:270,safety,hot,hotkey,270,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:1648,safety,test,tested,1648,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:1678,safety,updat,updated,1678,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:1678,security,updat,updated,1678,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:1648,testability,test,tested,1648,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:27,usability,stop,stop,27,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:140,usability,stop,stops,140,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:277,usability,shortcut,shortcut,277,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:538,usability,dialog,dialog,538,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:599,usability,stop,stops,599,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8667:1069,usability,Close,CloseWindow,1069,"[TGMainFrame] grabbed keys stop working if TGTextButton with Alt hotkey; # This Pull request:. ## Changes or fixes:. TGMainFrame::HandleKey stops prematurely, see https://github.com/root-project/root/blob/master/gui/gui/src/TGFrame.cxx#L1593, if any TGTextButton with a hotkey shortcut (`""&Sort data""`) is used in a GUI, even if the actual Key is CTRL+S instead of Alt+S or even if button is disabled. ## Reproducer. Based on @bellenot from https://github.com/root-project/root/issues/8665. To try it, press CTRL+S, it should open a file dialog to save the frame. Instead, it thinks it is Alt+S and stops the function too early. ```. #include ""KeySymbols.h"". #include ""TGFrame.h"". #include <iostream>. #include ""TVirtualX.h"". #include ""TGButton.h"". //______________________________________________________________________________. //. //. //______________________________________________________________________________. class MyMainFrame : public TGMainFrame {. public:. MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h);. virtual ~MyMainFrame() { Cleanup(); }. void CloseWindow() { delete this; }. ClassDef(MyMainFrame, 0). };. //______________________________________________________________________________. MyMainFrame::MyMainFrame(const TGWindow *p, UInt_t w, UInt_t h) : TGMainFrame(p, w, h). {. auto sortdata = new TGTextButton(this, ""&Sort data"");. AddFrame(sortdata);. MapSubwindows();. Layout();. MapWindow();. Resize(150,100);. }. //______________________________________________________________________________. void test_grab_key(). {. MyMainFrame *main = new MyMainFrame(gClient->GetRoot(), 150, 100);. }. ```. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8667
https://github.com/root-project/root/pull/8668:181,availability,heal,healthy,181,"Show ROOT passing CII best practices. [skip-ci]; Rationale: document that we do The Right Thing, and remind the future project what that might be :-) Also shows that the project is healthy according to more ""bureaucratic measures"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8668
https://github.com/root-project/root/pull/8668:221,energy efficiency,measur,measures,221,"Show ROOT passing CII best practices. [skip-ci]; Rationale: document that we do The Right Thing, and remind the future project what that might be :-) Also shows that the project is healthy according to more ""bureaucratic measures"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8668
https://github.com/root-project/root/pull/8668:27,reliability,pra,practices,27,"Show ROOT passing CII best practices. [skip-ci]; Rationale: document that we do The Right Thing, and remind the future project what that might be :-) Also shows that the project is healthy according to more ""bureaucratic measures"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8668
https://github.com/root-project/root/pull/8668:60,usability,document,document,60,"Show ROOT passing CII best practices. [skip-ci]; Rationale: document that we do The Right Thing, and remind the future project what that might be :-) Also shows that the project is healthy according to more ""bureaucratic measures"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8668
https://github.com/root-project/root/pull/8669:285,deployability,updat,updated,285,"[RF] Dictionary, RooCategory Pythonizations for RooFit; # This Pull request:. ## Changes or fixes:. - Dictionary pythonizations for std::map constructors ( RooDataHist, RooCategory) . - Pythonization and formatting of tutorial files. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8669
https://github.com/root-project/root/pull/8669:204,interoperability,format,formatting,204,"[RF] Dictionary, RooCategory Pythonizations for RooFit; # This Pull request:. ## Changes or fixes:. - Dictionary pythonizations for std::map constructors ( RooDataHist, RooCategory) . - Pythonization and formatting of tutorial files. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8669
https://github.com/root-project/root/pull/8669:255,safety,test,tested,255,"[RF] Dictionary, RooCategory Pythonizations for RooFit; # This Pull request:. ## Changes or fixes:. - Dictionary pythonizations for std::map constructors ( RooDataHist, RooCategory) . - Pythonization and formatting of tutorial files. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8669
https://github.com/root-project/root/pull/8669:285,safety,updat,updated,285,"[RF] Dictionary, RooCategory Pythonizations for RooFit; # This Pull request:. ## Changes or fixes:. - Dictionary pythonizations for std::map constructors ( RooDataHist, RooCategory) . - Pythonization and formatting of tutorial files. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8669
https://github.com/root-project/root/pull/8669:285,security,updat,updated,285,"[RF] Dictionary, RooCategory Pythonizations for RooFit; # This Pull request:. ## Changes or fixes:. - Dictionary pythonizations for std::map constructors ( RooDataHist, RooCategory) . - Pythonization and formatting of tutorial files. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8669
https://github.com/root-project/root/pull/8669:255,testability,test,tested,255,"[RF] Dictionary, RooCategory Pythonizations for RooFit; # This Pull request:. ## Changes or fixes:. - Dictionary pythonizations for std::map constructors ( RooDataHist, RooCategory) . - Pythonization and formatting of tutorial files. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8669
https://github.com/root-project/root/pull/8670:162,deployability,log,logical,162,[cmake] Remove warning about mismatched argument to if/endif; The warning is visible e.g. with cmake 3.11:. CMake Warning (dev) in interpreter/CMakeLists.txt:. A logical block opening on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:477 (if). closes on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:483 (endif). with mis-matching arguments.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8670
https://github.com/root-project/root/pull/8670:29,interoperability,mismatch,mismatched,29,[cmake] Remove warning about mismatched argument to if/endif; The warning is visible e.g. with cmake 3.11:. CMake Warning (dev) in interpreter/CMakeLists.txt:. A logical block opening on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:477 (if). closes on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:483 (endif). with mis-matching arguments.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8670
https://github.com/root-project/root/pull/8670:162,safety,log,logical,162,[cmake] Remove warning about mismatched argument to if/endif; The warning is visible e.g. with cmake 3.11:. CMake Warning (dev) in interpreter/CMakeLists.txt:. A logical block opening on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:477 (if). closes on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:483 (endif). with mis-matching arguments.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8670
https://github.com/root-project/root/pull/8670:162,security,log,logical,162,[cmake] Remove warning about mismatched argument to if/endif; The warning is visible e.g. with cmake 3.11:. CMake Warning (dev) in interpreter/CMakeLists.txt:. A logical block opening on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:477 (if). closes on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:483 (endif). with mis-matching arguments.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8670
https://github.com/root-project/root/pull/8670:162,testability,log,logical,162,[cmake] Remove warning about mismatched argument to if/endif; The warning is visible e.g. with cmake 3.11:. CMake Warning (dev) in interpreter/CMakeLists.txt:. A logical block opening on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:477 (if). closes on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:483 (endif). with mis-matching arguments.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8670
https://github.com/root-project/root/pull/8670:259,usability,close,closes,259,[cmake] Remove warning about mismatched argument to if/endif; The warning is visible e.g. with cmake 3.11:. CMake Warning (dev) in interpreter/CMakeLists.txt:. A logical block opening on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:477 (if). closes on the line. /data/ssdext4/rvec2/root/interpreter/CMakeLists.txt:483 (endif). with mis-matching arguments.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8670
https://github.com/root-project/root/pull/8671:248,availability,consist,consistent,248,"[CONTRIBUTING] Move ""we require tests"" / (c) assign from web: [skip-ci]; With https://github.com/root-project/web/pull/622 https://root.cern/contribute/ will point to CONTRIBUTING.md. That. latter file is linked by GitHub and should be mostly self consistent. Make it a bit easier to read.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8671
https://github.com/root-project/root/pull/8671:32,safety,test,tests,32,"[CONTRIBUTING] Move ""we require tests"" / (c) assign from web: [skip-ci]; With https://github.com/root-project/web/pull/622 https://root.cern/contribute/ will point to CONTRIBUTING.md. That. latter file is linked by GitHub and should be mostly self consistent. Make it a bit easier to read.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8671
https://github.com/root-project/root/pull/8671:32,testability,test,tests,32,"[CONTRIBUTING] Move ""we require tests"" / (c) assign from web: [skip-ci]; With https://github.com/root-project/web/pull/622 https://root.cern/contribute/ will point to CONTRIBUTING.md. That. latter file is linked by GitHub and should be mostly self consistent. Make it a bit easier to read.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8671
https://github.com/root-project/root/pull/8671:248,usability,consist,consistent,248,"[CONTRIBUTING] Move ""we require tests"" / (c) assign from web: [skip-ci]; With https://github.com/root-project/web/pull/622 https://root.cern/contribute/ will point to CONTRIBUTING.md. That. latter file is linked by GitHub and should be mostly self consistent. Make it a bit easier to read.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8671
https://github.com/root-project/root/pull/8672:155,deployability,updat,updated,155,Add missing #include <time.h> (on Windows with /std:c++17); # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8672
https://github.com/root-project/root/pull/8672:22,performance,time,time,22,Add missing #include <time.h> (on Windows with /std:c++17); # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8672
https://github.com/root-project/root/pull/8672:125,safety,test,tested,125,Add missing #include <time.h> (on Windows with /std:c++17); # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8672
https://github.com/root-project/root/pull/8672:155,safety,updat,updated,155,Add missing #include <time.h> (on Windows with /std:c++17); # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8672
https://github.com/root-project/root/pull/8672:155,security,updat,updated,155,Add missing #include <time.h> (on Windows with /std:c++17); # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8672
https://github.com/root-project/root/pull/8672:125,testability,test,tested,125,Add missing #include <time.h> (on Windows with /std:c++17); # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8672
https://github.com/root-project/root/pull/8673:293,deployability,updat,updated,293,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8673:167,integrability,batch,batch,167,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8673:167,performance,batch,batch,167,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8673:263,safety,test,tested,263,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8673:293,safety,updat,updated,293,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8673:293,security,updat,updated,293,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8673:263,testability,test,tested,263,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8673:199,usability,interact,interact,199,"[TGMainFrame] disengage SaveFrame code from GUI so that it can also run from script; # This Pull request:. ## Changes or fixes:. Adds an option to call SaveFrame from batch script, without having to interact, giving the filename as argument. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8673
https://github.com/root-project/root/pull/8675:880,availability,slo,slot,880,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:909,availability,slo,slot,909,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1285,deployability,integr,integrate,1285,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1506,deployability,updat,updated,1506,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:25,integrability,event,event,25,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:165,integrability,event,event,165,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:693,integrability,Event,Events,693,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1285,integrability,integr,integrate,1285,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1285,interoperability,integr,integrate,1285,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1285,modifiability,integr,integrate,1285,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:880,reliability,slo,slot,880,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:909,reliability,slo,slot,909,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1285,reliability,integr,integrate,1285,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1476,safety,test,tested,1476,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1506,safety,updat,updated,1506,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1285,security,integr,integrate,1285,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1506,security,updat,updated,1506,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1285,testability,integr,integrate,1285,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1476,testability,test,tested,1476,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:10,usability,progress,progress,10,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:65,usability,Progress,ProgressHelper,65,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:188,usability,progress,progress,188,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:638,usability,Progress,ProgressHelper,638,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:653,usability,progress,progress,653,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:857,usability,progress,progress,857,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:900,usability,progress,progress,900,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1155,usability,user,user-images,1155,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1272,usability,help,helpers,1272,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8675:1327,usability,prefer,preferably,1327,"[RDF] Add progress bar + event statistics; # This Pull request:. ProgressHelper is a class that offers callback functions for RDataFrame,. and can compute and print event statistics and a progress bar. With a change like this:. ```diff. --- a/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. +++ b/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C. @@ -28,6 +28,7 @@. #include ""TLatex.h"". #include ""Math/Vector4D.h"". #include ""TStyle.h"". +#include ""ROOT/RDFHelpers.hxx"". . using namespace ROOT::VecOps;. . @@ -52,6 +53,9 @@ void df102_NanoAODDimuonAnalysis(). // Request cut-flow report. auto report = df_mass.Report();. . + ROOT::RDF::ProgressHelper progress(10000, ROOT::RDF::CountEvents(""Events"", ""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""));. + h.OnPartialResultSlot(10000, [&progress](unsigned int slot, TH1D& histo){ progress(slot, histo); });. +. // Produce plot. gStyle->SetOptStat(0); gStyle->SetTextFont(42);. auto c = new TCanvas(""c"", """", 800, 700);. ```. one gets:. `bin/root -q ~/code/root-src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.C+O`. ![image](https://user-images.githubusercontent.com/16205615/125669114-03ebfeb1-96e4-4dcc-afd9-b6690aafb4a1.png). ## TODO. - [ ] Write helpers that integrate this into the head node of RDF, preferably with a single line of code. - [ ] *Optional*: Finalise callbacks for RDF, since a carriage return is always missing. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8675
https://github.com/root-project/root/pull/8676:54,deployability,version,version,54,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:154,deployability,version,version,154,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:449,deployability,updat,updated,449,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:187,energy efficiency,energ,energy,187,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:54,integrability,version,version,54,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:154,integrability,version,version,154,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:54,modifiability,version,version,54,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:154,modifiability,version,version,154,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:194,modifiability,scal,scaling,194,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:297,modifiability,reu,reuse,297,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:419,safety,test,tested,419,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:449,safety,updat,updated,449,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:449,security,updat,updated,449,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8676:419,testability,test,tested,419,"Eve-7: Add XZ,YZ, ZX, and ZY projection types. Zeroth version of Lego view type; . ## Changes or fixes:. * Add XZ,YZ, ZX, and ZY projection types. * Zero version of Lego view type. * Add energy scaling in REveDataProxyBuilderBase. * Ability to set camera type through REveViewer. * Corrections in reuse of compounds in REveDataSimpleProxyBuilder. * Fix selection/highlight in REveStraightLineSet. ## Checklist:. - [ x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8676
https://github.com/root-project/root/pull/8677:210,deployability,updat,updated,210,grab CTRL+s in TGMainFrame also if NumLock active; # This Pull request:. ## Changes or fixes:. CTRL shortcuts X11Grab were not working if NumLock was enabled. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8665.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8677
https://github.com/root-project/root/pull/8677:180,safety,test,tested,180,grab CTRL+s in TGMainFrame also if NumLock active; # This Pull request:. ## Changes or fixes:. CTRL shortcuts X11Grab were not working if NumLock was enabled. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8665.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8677
https://github.com/root-project/root/pull/8677:210,safety,updat,updated,210,grab CTRL+s in TGMainFrame also if NumLock active; # This Pull request:. ## Changes or fixes:. CTRL shortcuts X11Grab were not working if NumLock was enabled. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8665.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8677
https://github.com/root-project/root/pull/8677:210,security,updat,updated,210,grab CTRL+s in TGMainFrame also if NumLock active; # This Pull request:. ## Changes or fixes:. CTRL shortcuts X11Grab were not working if NumLock was enabled. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8665.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8677
https://github.com/root-project/root/pull/8677:180,testability,test,tested,180,grab CTRL+s in TGMainFrame also if NumLock active; # This Pull request:. ## Changes or fixes:. CTRL shortcuts X11Grab were not working if NumLock was enabled. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8665.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8677
https://github.com/root-project/root/pull/8677:100,usability,shortcut,shortcuts,100,grab CTRL+s in TGMainFrame also if NumLock active; # This Pull request:. ## Changes or fixes:. CTRL shortcuts X11Grab were not working if NumLock was enabled. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8665.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8677
https://github.com/root-project/root/pull/8678:108,availability,error,errors,108,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:12,deployability,build,build,12,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:135,deployability,build,build,135,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:305,deployability,updat,updated,305,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:108,performance,error,errors,108,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:108,safety,error,errors,108,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:279,safety,test,tested,279,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:305,safety,updat,updated,305,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:305,security,updat,updated,305,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:279,testability,test,tested,279,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8678:108,usability,error,errors,108,[cmake] Fix build with builtin_llvm=off; # This Pull request:. ## Changes or fixes:. This fixes both of the errors seen when trying to build with builtin_llvm=off. https://root-forum.cern.ch/t/compiling-root-6-24-with-external-llvm-but-built-in-clang/45258. ## Checklist:. - [x] tested changes locally. - updated the docs (if necessary). This PR fixes #8141,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8678
https://github.com/root-project/root/pull/8679:135,availability,error,error,135,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:18,deployability,fail,failing,18,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:97,deployability,fail,failing,97,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:227,deployability,Stack,Stack,227,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:243,modifiability,paramet,parameters,243,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:135,performance,error,error,135,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:18,reliability,fail,failing,18,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:97,reliability,fail,failing,97,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:135,safety,error,error,135,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:148,safety,Unhandl,Unhandled,148,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:158,safety,except,exception,158,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8679:135,usability,error,error,135,"[skip-ci] Disable failing rf316_llratioplot.py on Windows; Disable rf316_llratioplot.py which is failing on Windows with the following error:. ```. Unhandled exception at 0x55176657 (libcppyy3_8.pyd) in python.exe: 0xC00000FD: Stack overflow (parameters: 0x00000000, 0x01002000). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8679
https://github.com/root-project/root/pull/8680:82,deployability,version,version,82,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:129,deployability,version,version,129,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:200,deployability,version,version,200,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:248,deployability,version,version,248,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:292,deployability,version,version,292,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:82,integrability,version,version,82,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:116,integrability,messag,message,116,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:129,integrability,version,version,129,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:200,integrability,version,version,200,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:248,integrability,version,version,248,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:292,integrability,version,version,292,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:116,interoperability,messag,message,116,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:82,modifiability,version,version,82,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:129,modifiability,version,version,129,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:200,modifiability,version,version,200,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:248,modifiability,version,version,248,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:292,modifiability,version,version,292,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:75,safety,Input,Input,75,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:39,usability,workflow,workflow,39,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:63,usability,UI,UI,63,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:75,usability,Input,Input,75,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:158,usability,support,supported,158,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8680:318,usability,support,supported,318,"Fix deprecation warning for new GitHub workflow [skip-ci]; The UI says:. > Input 'version' has been deprecated with message: The version property will not be supported after October 1, 2019. Use node-version instead. Also bump to the latest NodeJS version 16.x which will become the next LTS version in October and be supported until 2024 (12.x will go EOL in April 2022, next year).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8680
https://github.com/root-project/root/pull/8681:540,deployability,updat,updated,540,"use proper bitmap_pad in XCreateImage; # This Pull request:. ## Changes or fixes:. XCreateImage bitmap_pad argument was not being set properly. It caused problems with depths of e.g. 30, see https://github.com/root-project/root/issues/8086#issuecomment-850620085 by @juw. Now it matches the behaviour of:. https://github.com/root-project/root/blob/master/graf2d/x11/src/GX11Gui.cxx#L2612. https://github.com/root-project/root/blob/master/graf2d/asimage/src/libAfterImage/asvisual.c#L1549. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8086.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8681
https://github.com/root-project/root/pull/8681:510,safety,test,tested,510,"use proper bitmap_pad in XCreateImage; # This Pull request:. ## Changes or fixes:. XCreateImage bitmap_pad argument was not being set properly. It caused problems with depths of e.g. 30, see https://github.com/root-project/root/issues/8086#issuecomment-850620085 by @juw. Now it matches the behaviour of:. https://github.com/root-project/root/blob/master/graf2d/x11/src/GX11Gui.cxx#L2612. https://github.com/root-project/root/blob/master/graf2d/asimage/src/libAfterImage/asvisual.c#L1549. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8086.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8681
https://github.com/root-project/root/pull/8681:540,safety,updat,updated,540,"use proper bitmap_pad in XCreateImage; # This Pull request:. ## Changes or fixes:. XCreateImage bitmap_pad argument was not being set properly. It caused problems with depths of e.g. 30, see https://github.com/root-project/root/issues/8086#issuecomment-850620085 by @juw. Now it matches the behaviour of:. https://github.com/root-project/root/blob/master/graf2d/x11/src/GX11Gui.cxx#L2612. https://github.com/root-project/root/blob/master/graf2d/asimage/src/libAfterImage/asvisual.c#L1549. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8086.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8681
https://github.com/root-project/root/pull/8681:540,security,updat,updated,540,"use proper bitmap_pad in XCreateImage; # This Pull request:. ## Changes or fixes:. XCreateImage bitmap_pad argument was not being set properly. It caused problems with depths of e.g. 30, see https://github.com/root-project/root/issues/8086#issuecomment-850620085 by @juw. Now it matches the behaviour of:. https://github.com/root-project/root/blob/master/graf2d/x11/src/GX11Gui.cxx#L2612. https://github.com/root-project/root/blob/master/graf2d/asimage/src/libAfterImage/asvisual.c#L1549. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8086.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8681
https://github.com/root-project/root/pull/8681:510,testability,test,tested,510,"use proper bitmap_pad in XCreateImage; # This Pull request:. ## Changes or fixes:. XCreateImage bitmap_pad argument was not being set properly. It caused problems with depths of e.g. 30, see https://github.com/root-project/root/issues/8086#issuecomment-850620085 by @juw. Now it matches the behaviour of:. https://github.com/root-project/root/blob/master/graf2d/x11/src/GX11Gui.cxx#L2612. https://github.com/root-project/root/blob/master/graf2d/asimage/src/libAfterImage/asvisual.c#L1549. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8086.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8681
https://github.com/root-project/root/pull/8681:291,usability,behavi,behaviour,291,"use proper bitmap_pad in XCreateImage; # This Pull request:. ## Changes or fixes:. XCreateImage bitmap_pad argument was not being set properly. It caused problems with depths of e.g. 30, see https://github.com/root-project/root/issues/8086#issuecomment-850620085 by @juw. Now it matches the behaviour of:. https://github.com/root-project/root/blob/master/graf2d/x11/src/GX11Gui.cxx#L2612. https://github.com/root-project/root/blob/master/graf2d/asimage/src/libAfterImage/asvisual.c#L1549. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes https://github.com/root-project/root/issues/8086.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8681
https://github.com/root-project/root/pull/8682:66,availability,failur,failures,66,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8682:66,deployability,fail,failures,66,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8682:108,deployability,build,builds,108,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8682:135,deployability,modul,modules,135,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8682:135,modifiability,modul,modules,135,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8682:66,performance,failur,failures,66,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8682:66,reliability,fail,failures,66,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8682:135,safety,modul,modules,135,[DF] Add RCutFlowReport to LinkDef; This should fix some sporadic failures in cling's symbol resolution. in builds without runtime cxx modules.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8682
https://github.com/root-project/root/pull/8684:583,availability,operat,operations,583,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:485,deployability,Modul,Module,485,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:511,deployability,Modul,ModuleList,511,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:522,deployability,contain,containers,522,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1237,deployability,Configurat,Configuration,1237,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:213,energy efficiency,Model,Models,213,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:393,energy efficiency,model,model,393,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:989,energy efficiency,model,model,989,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:666,integrability,Interfac,Interface,666,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1237,integrability,Configur,Configuration,1237,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:128,interoperability,format,format,128,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:666,interoperability,Interfac,Interface,666,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:485,modifiability,Modul,Module,485,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:511,modifiability,Modul,ModuleList,511,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:576,modifiability,Layer,Layers,576,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:666,modifiability,Interfac,Interface,666,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:764,modifiability,paramet,parameter,764,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1237,modifiability,Configur,Configuration,1237,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:485,safety,Modul,Module,485,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:511,safety,Modul,ModuleList,511,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:728,safety,input,input,728,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:832,safety,input,input,832,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:967,safety,input,inputShape,967,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1064,safety,input,inputShape,1064,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1106,safety,test,tested,1106,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1147,safety,Test,Tests,1147,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1207,safety,Test,Tests,1207,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1255,safety,test,tests,1255,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:213,security,Model,Models,213,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:393,security,model,model,393,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:989,security,model,model,989,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1237,security,Configur,Configuration,1237,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1106,testability,test,tested,1106,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1147,testability,Test,Tests,1147,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1207,testability,Test,Tests,1207,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1255,testability,test,tests,1255,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:204,usability,Learn,Learning,204,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:342,usability,Progress,Progress,342,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:462,usability,Support,Support,462,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:540,usability,Support,Supports,540,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:728,usability,input,input,728,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:832,usability,input,input,832,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:967,usability,input,inputShape,967,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1064,usability,input,inputShape,1064,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/pull/8684:1266,usability,Document,Documentation,1266,"[GSoC][TMVA][SOFIE] PyTorch Parser TMVA; ## Description. Development of the functionality for parsing a PyTorch PT file to ROOT format using the Fast Inference System SOFIE for the **ROOT Storage of Deep Learning Models** Project of *Google Summer of Code'21*. Project Link: https://summerofcode.withgoogle.com/projects/#5424575602491392. ## Progress. - [x] Parser function for extracting the model information and weights and instantiate a RModel Object. - [x] Support for PyTorch nn.Module, nn.Sequential, nn.ModuleList containers. - [x] Supports Linear, ReLU and Transpose Layers/operations. - [x] Header file for the function. - [x] Function implementation . ## Interface. The parser requires the shape and data type of the input tensors. Shape is a mandatory parameter, whereas the function defaults to Float data-type for the input tensors, if not explicitly mentioned. . **Example usage**. ```. std::vector<size_t> s1{120,1};. std::vector<std::vector<size_t>> inputShape{s1};. auto model = TMVA::Experimental::SOFIE::PyTorch::Parse(""trained_model_dense.pt"",inputShape);. ```. . ## Checklist:. - [x] tested changes locally. - [x] Parser. ## Tests . - [x] Emit Files for generating header files. - [x] Tests for Parser. - [x] CMake Configuration for tests . ## Documentation. - [x] Doxygen Docs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8684
https://github.com/root-project/root/issues/8685:193,energy efficiency,estimat,estimate,193,"RDF progress bar; ### Is your feature request related to a problem? Please describe. It would be great to have a progress bar for RDF, one that does not need to open all files before giving an estimate on the remaining processing time. ### Describe the solution you'd like. Similar to https://github.com/root-project/root/pull/8675 but with the approach sketched in https://github.com/root-project/root/pull/8675#discussion_r670348181.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8685
https://github.com/root-project/root/issues/8685:230,performance,time,time,230,"RDF progress bar; ### Is your feature request related to a problem? Please describe. It would be great to have a progress bar for RDF, one that does not need to open all files before giving an estimate on the remaining processing time. ### Describe the solution you'd like. Similar to https://github.com/root-project/root/pull/8675 but with the approach sketched in https://github.com/root-project/root/pull/8675#discussion_r670348181.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8685
https://github.com/root-project/root/issues/8685:144,reliability,doe,does,144,"RDF progress bar; ### Is your feature request related to a problem? Please describe. It would be great to have a progress bar for RDF, one that does not need to open all files before giving an estimate on the remaining processing time. ### Describe the solution you'd like. Similar to https://github.com/root-project/root/pull/8675 but with the approach sketched in https://github.com/root-project/root/pull/8675#discussion_r670348181.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8685
https://github.com/root-project/root/issues/8685:4,usability,progress,progress,4,"RDF progress bar; ### Is your feature request related to a problem? Please describe. It would be great to have a progress bar for RDF, one that does not need to open all files before giving an estimate on the remaining processing time. ### Describe the solution you'd like. Similar to https://github.com/root-project/root/pull/8675 but with the approach sketched in https://github.com/root-project/root/pull/8675#discussion_r670348181.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8685
https://github.com/root-project/root/issues/8685:113,usability,progress,progress,113,"RDF progress bar; ### Is your feature request related to a problem? Please describe. It would be great to have a progress bar for RDF, one that does not need to open all files before giving an estimate on the remaining processing time. ### Describe the solution you'd like. Similar to https://github.com/root-project/root/pull/8675 but with the approach sketched in https://github.com/root-project/root/pull/8675#discussion_r670348181.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8685
https://github.com/root-project/root/pull/8686:112,deployability,API,API,112,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:166,deployability,contain,container,166,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:112,integrability,API,API,112,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:149,integrability,configur,configure,149,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:112,interoperability,API,API,112,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:149,modifiability,configur,configure,149,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:23,reliability,RCa,RCanvas,23,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:149,security,configur,configure,149,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:103,testability,simpl,simplify,103,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:82,usability,support,supported,82,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8686:103,usability,simpl,simplify,103,"Use integer pixels for RCanvas width and height; No any other dimension kinds are supported, therefore simplify API. Use canvas size in `jupyter` to configure output container",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8686
https://github.com/root-project/root/pull/8687:20,deployability,updat,updates,20,[NFC][skip-ci] Sall updates to RNTuple docs; .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8687
https://github.com/root-project/root/pull/8687:20,safety,updat,updates,20,[NFC][skip-ci] Sall updates to RNTuple docs; .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8687
https://github.com/root-project/root/pull/8687:20,security,updat,updates,20,[NFC][skip-ci] Sall updates to RNTuple docs; .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8687
https://github.com/root-project/root/pull/8688:26,performance,multi-thread,multi-threaded,26,[ntuple] Add tutorial for multi-threaded filling; # This Pull request:. Add `RNTupleWriter::CreateEntry()` and uses it in a demonstration on multi-threaded writing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8688
https://github.com/root-project/root/pull/8688:141,performance,multi-thread,multi-threaded,141,[ntuple] Add tutorial for multi-threaded filling; # This Pull request:. Add `RNTupleWriter::CreateEntry()` and uses it in a demonstration on multi-threaded writing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8688
https://github.com/root-project/root/pull/8689:48,deployability,build,building,48,Add Minuit2 On by default; This PR sets Minuit2 building to ON by default in the make ROOT build option file. . This is needed now since Roofit now depends on Minuit2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8689
https://github.com/root-project/root/pull/8689:91,deployability,build,build,91,Add Minuit2 On by default; This PR sets Minuit2 building to ON by default in the make ROOT build option file. . This is needed now since Roofit now depends on Minuit2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8689
https://github.com/root-project/root/pull/8689:148,deployability,depend,depends,148,Add Minuit2 On by default; This PR sets Minuit2 building to ON by default in the make ROOT build option file. . This is needed now since Roofit now depends on Minuit2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8689
https://github.com/root-project/root/pull/8689:148,integrability,depend,depends,148,Add Minuit2 On by default; This PR sets Minuit2 building to ON by default in the make ROOT build option file. . This is needed now since Roofit now depends on Minuit2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8689
https://github.com/root-project/root/pull/8689:148,modifiability,depend,depends,148,Add Minuit2 On by default; This PR sets Minuit2 building to ON by default in the make ROOT build option file. . This is needed now since Roofit now depends on Minuit2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8689
https://github.com/root-project/root/pull/8689:148,safety,depend,depends,148,Add Minuit2 On by default; This PR sets Minuit2 building to ON by default in the make ROOT build option file. . This is needed now since Roofit now depends on Minuit2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8689
https://github.com/root-project/root/pull/8689:148,testability,depend,depends,148,Add Minuit2 On by default; This PR sets Minuit2 building to ON by default in the make ROOT build option file. . This is needed now since Roofit now depends on Minuit2,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8689
https://github.com/root-project/root/pull/8690:7,modifiability,Variab,Variable,7,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8690
https://github.com/root-project/root/pull/8690:60,modifiability,Variab,Variable,60,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8690
https://github.com/root-project/root/pull/8690:99,safety,input,inputs,99,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8690
https://github.com/root-project/root/pull/8690:483,safety,test,tested,483,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8690
https://github.com/root-project/root/pull/8690:483,testability,test,tested,483,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8690
https://github.com/root-project/root/pull/8690:99,usability,input,inputs,99,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8690
https://github.com/root-project/root/pull/8691:48,availability,error,errors,48,Fix in tmva-sofie some warnings and compilation errors found with g++ 11;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8691
https://github.com/root-project/root/pull/8691:48,performance,error,errors,48,Fix in tmva-sofie some warnings and compilation errors found with g++ 11;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8691
https://github.com/root-project/root/pull/8691:48,safety,error,errors,48,Fix in tmva-sofie some warnings and compilation errors found with g++ 11;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8691
https://github.com/root-project/root/pull/8691:48,usability,error,errors,48,Fix in tmva-sofie some warnings and compilation errors found with g++ 11;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8691
https://github.com/root-project/root/issues/8693:62,deployability,build,build,62,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/issues/8693:507,deployability,build,build,507,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/issues/8693:548,deployability,build,build,548,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/issues/8693:636,deployability,build,build,636,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/issues/8693:17,usability,command,command,17,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/issues/8693:477,usability,command,command,477,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/issues/8693:593,usability,command,command,593,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/issues/8693:681,usability,command,command,681,"""Running utility command for G__TreeFormulaEvent"" even if the build should be no-op; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. Ninja always runs the following command, even the incremental build should be a no-op:. ```. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. $ cmake --build _build -- -j 16. [1/1] Running utility command for G__TreeFormulaEvent. ```. Some more discussion at https://mattermost.web.cern.ch/root/pl/74b1gpnr97ripgqdhaw7n87byr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8693
https://github.com/root-project/root/pull/8694:591,modifiability,reu,reused,591,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:644,modifiability,reu,reuse,644,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:1143,modifiability,paramet,parameter,1143,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:23,safety,Test,TestStatistics,23,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:47,safety,test,test,47,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:107,safety,test,test,107,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:1031,safety,test,test,1031,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:746,security,access,access,746,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:23,testability,Test,TestStatistics,23,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:47,testability,test,test,47,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:107,testability,test,test,107,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:350,testability,Simul,Simultaneously,350,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:498,testability,plan,planned,498,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:1031,testability,test,test,1031,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:458,usability,minim,minimal,458,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:524,usability,support,support,524,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/pull/8694:824,usability,support,support,824,"RooFit::MultiProcess & TestStatistics part 5b: test RooGradMinimizerFcn; This PR reactivates and fixes the test for RooGradMinimizerFcn (introduced in #8596). The first commit provides a way for external gradient calculators to use previous gradient information (gradient itself, second derivatives, step size) to calculate the next gradient values. Simultaneously, it allows the external calculator to pass back (via the same arrays to keep the redesign as minimal as possible, in anticipation of planned dedicated Hessian support) the second derivative and step sizes, so they can also be reused in the next gradient calculation. All of this reuse was already going on in Numerical2PGradientCalculator, but external gradient calculators had no access to this data, because the FCNGradAdaptor and IMultiGradFunction had no support for passing it back and forth. The commit also implements use of this mechanism in ExternalInternalGradientCalculator and in RooGradMinimizerFcn. The second commit reactivates the (already existing) test, and fixes it, because it turned out it had a small remaining bug. The bug was fixed by removing an unused parameter from `NumericalGradient::SetInitialGradient`, so that was two birds with one stone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8694
https://github.com/root-project/root/issues/8695:312,availability,mainten,maintenance,312,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:514,availability,state,states,514,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:790,availability,state,statement,790,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:2082,availability,state,state,2082,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:293,energy efficiency,reduc,reducing,293,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1877,energy efficiency,load,load,1877,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:514,integrability,state,states,514,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:790,integrability,state,statement,790,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:2082,integrability,state,state,2082,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:545,interoperability,compatib,compatibility,545,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1368,interoperability,specif,specifically,1368,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1077,performance,time,time,1077,"this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurate",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1715,performance,Lock,LockDefaultUnits,1715,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1810,performance,Lock,LockDefaultUnits,1810,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1857,performance,lock,locked,1857,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1877,performance,load,load,1877,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:312,reliability,mainten,maintenance,312,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1715,security,Lock,LockDefaultUnits,1715,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1810,security,Lock,LockDefaultUnits,1810,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1857,security,lock,locked,1857,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:34,testability,unit,units,34,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:209,testability,unit,units,209,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:402,testability,unit,units,402,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:584,testability,unit,units,584,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1030,testability,unit,units,1030," units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1043,testability,unit,units,1043," not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1157,testability,unit,units,1157,"6be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1274,testability,unit,units,1274,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1534,testability,unit,units,1534,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1590,testability,simpl,simply,1590,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1600,testability,unit,units,1600,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1622,testability,unit,units,1622,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1651,testability,unit,units,1651,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1847,testability,unit,units,1847,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:2100,testability,unit,units,2100,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:2184,testability,unit,units,2184,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:0,usability,Document,Documentation,0,"Documentation incorrect - default units are G4 not ROOT; A commit from earlier this year (https://github.com/root-project/root/commit/3d545273d7763e09aa85449ba86be5d2493f7f13) adjusted the handling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1424,usability,support,supports,1424,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1434,usability,experien,experienced,1434,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:1590,usability,simpl,simply,1590,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/issues/8695:2154,usability,user,user,2154,"andling of default units in ROOT's geometry system. Although this commit is an ostensible improvement, reducing points of maintenance, there are some consequences that were maybe not anticipated. I refer to the [units README file](https://github.com/root-project/root/blob/master/geom/geom/README_units.md). In that file it states:. > To ensure backwards compatibility ROOT's default system of units is - as it was before - based on centimeters, seconds and GigaElectronVolts, ie. the defaults are equivalent to:. > . > ```c++. > TGeoManager::SetDefaultUnits(kRootUnits);. > ```. Unfortunately, this statement is not true. As you see from the definition of the `TGeoManager::fgDefaultUnits` static data member https://github.com/root-project/root/blob/49d0be0b9455e026e6d68e2e651113af3f1e4654/geom/geom/src/TGeoManager.cxx#L302 the default units are G4 units, which it has been for some time (perhaps the beginning?). There was thus an inconsistency with the default units and with those assumed by TGDMLParse, which, before the above commit, made an unconditional assumption of ROOT units. The above commit addresses this inconsistency, but the neutrino community at Fermilab (specifically the LArSoft project and the experiments it supports) experienced an [unintended consequence](https://github.com/LArSoft/larcorealg/pull/18)--the default units are now honored by the TGDML parser, but they are simply G4 units instead of ROOT units. In order to make ROOT units the default, we use the workaround:. ```c++. TGeoManager::LockDefaultUnits(false);. TGeoManager::SetDefaultUnits(TGeoManager::kRootUnits);. TGeoManager::LockDefaultUnits(true);. ```. as the units are locked upon library load: https://github.com/root-project/root/blob/612b68ea1f70c3f5ce7deb8a6b664b8a08987991/geom/geom/src/TGeoManager.cxx#L304. This issue requests two things:. - Please correct the README file to accurately state the default units (G4). - Suggest a better mechanism to allow the user to establish the default units.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8695
https://github.com/root-project/root/pull/8696:38,safety,test,test,38,"[ntuple] Add RNTupleModel::GetField + test; Before this commit, in order to retrieve a given field from the. RNTupleModel it was required to walk the tree of fields starting. from fFieldZero. This commit adds a convenience method that takes a field name and. returns a pointer to RFieldBase (null if the field could not be found).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8696
https://github.com/root-project/root/pull/8696:38,testability,test,test,38,"[ntuple] Add RNTupleModel::GetField + test; Before this commit, in order to retrieve a given field from the. RNTupleModel it was required to walk the tree of fields starting. from fFieldZero. This commit adds a convenience method that takes a field name and. returns a pointer to RFieldBase (null if the field could not be found).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8696
https://github.com/root-project/root/issues/8697:5,safety,test,testRooGradMinimizerFcn,5,[RF] testRooGradMinimizerFcn needs to be re-enabled; Commit fb2e642952c2163e7f1c0cf0f4c18de53d9877b5 disabled testRooGradMinimizerFcn; this needs to be reenabled. (This is just a reminder.),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8697
https://github.com/root-project/root/issues/8697:110,safety,test,testRooGradMinimizerFcn,110,[RF] testRooGradMinimizerFcn needs to be re-enabled; Commit fb2e642952c2163e7f1c0cf0f4c18de53d9877b5 disabled testRooGradMinimizerFcn; this needs to be reenabled. (This is just a reminder.),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8697
https://github.com/root-project/root/issues/8697:5,testability,test,testRooGradMinimizerFcn,5,[RF] testRooGradMinimizerFcn needs to be re-enabled; Commit fb2e642952c2163e7f1c0cf0f4c18de53d9877b5 disabled testRooGradMinimizerFcn; this needs to be reenabled. (This is just a reminder.),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8697
https://github.com/root-project/root/issues/8697:110,testability,test,testRooGradMinimizerFcn,110,[RF] testRooGradMinimizerFcn needs to be re-enabled; Commit fb2e642952c2163e7f1c0cf0f4c18de53d9877b5 disabled testRooGradMinimizerFcn; this needs to be reenabled. (This is just a reminder.),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8697
https://github.com/root-project/root/pull/8698:7,modifiability,Variab,Variable,7,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8698
https://github.com/root-project/root/pull/8698:60,modifiability,Variab,Variable,60,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8698
https://github.com/root-project/root/pull/8698:99,safety,input,inputs,99,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8698
https://github.com/root-project/root/pull/8698:483,safety,test,tested,483,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8698
https://github.com/root-project/root/pull/8698:483,testability,test,tested,483,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8698
https://github.com/root-project/root/pull/8698:99,usability,input,inputs,99,[TMVA] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8698
https://github.com/root-project/root/pull/8699:281,deployability,updat,updated,281,Added Histogram ROOT File Tutorial ; # This Pull request:. ## Changes or fixes:. Adds a tutorial demonstrating how a Histogram can be read from a ROOT File. I also added one that demos how a rootfile with a histogram can be made. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). As mentioned in [this](https://root-forum.cern.ch/t/read-a-histogram-from-a-root-file/8930) forum post.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8699
https://github.com/root-project/root/pull/8699:251,safety,test,tested,251,Added Histogram ROOT File Tutorial ; # This Pull request:. ## Changes or fixes:. Adds a tutorial demonstrating how a Histogram can be read from a ROOT File. I also added one that demos how a rootfile with a histogram can be made. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). As mentioned in [this](https://root-forum.cern.ch/t/read-a-histogram-from-a-root-file/8930) forum post.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8699
https://github.com/root-project/root/pull/8699:281,safety,updat,updated,281,Added Histogram ROOT File Tutorial ; # This Pull request:. ## Changes or fixes:. Adds a tutorial demonstrating how a Histogram can be read from a ROOT File. I also added one that demos how a rootfile with a histogram can be made. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). As mentioned in [this](https://root-forum.cern.ch/t/read-a-histogram-from-a-root-file/8930) forum post.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8699
https://github.com/root-project/root/pull/8699:281,security,updat,updated,281,Added Histogram ROOT File Tutorial ; # This Pull request:. ## Changes or fixes:. Adds a tutorial demonstrating how a Histogram can be read from a ROOT File. I also added one that demos how a rootfile with a histogram can be made. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). As mentioned in [this](https://root-forum.cern.ch/t/read-a-histogram-from-a-root-file/8930) forum post.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8699
https://github.com/root-project/root/pull/8699:251,testability,test,tested,251,Added Histogram ROOT File Tutorial ; # This Pull request:. ## Changes or fixes:. Adds a tutorial demonstrating how a Histogram can be read from a ROOT File. I also added one that demos how a rootfile with a histogram can be made. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). As mentioned in [this](https://root-forum.cern.ch/t/read-a-histogram-from-a-root-file/8930) forum post.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8699
https://github.com/root-project/root/pull/8700:547,deployability,observ,observables,547,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:843,deployability,build,builders,843,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1944,deployability,build,building,1944,"ferent kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimizat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2007,deployability,build,building,2007,"tion ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only fo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2130,deployability,configurat,configuration,2130,"::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` cla",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2189,deployability,fail,fails,2189,"se the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](h",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2803,deployability,build,build,2803," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3251,deployability,depend,dependencies-,3251," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3421,deployability,integr,integration,3421," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3470,deployability,integr,integration,3470," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:268,energy efficiency,optim,optimization,268,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:474,energy efficiency,optim,optimization,474,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1003,energy efficiency,optim,optimization,1003,"ultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of bu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1199,energy efficiency,GPU,GPU,1199,"atistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails becaus",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:458,integrability,sub,subsidiary,458,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:524,integrability,compon,components,524,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:585,integrability,compon,components,585,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:661,integrability,compon,components,661,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:873,integrability,Wrap,Wrapper,873,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:895,integrability,abstract,abstract,895,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:904,integrability,interfac,interfaces,904,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1242,integrability,coupl,coupling,1242,"alculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1348,integrability,Wrap,Wrappers,1348,"the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1388,integrability,compon,components,1388,"is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to he",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1428,integrability,coupl,couple,1428,"ihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Final",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1918,integrability,sub,subsidiary,1918,"an be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2130,integrability,configur,configuration,2130,"::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` cla",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3251,integrability,depend,dependencies-,3251," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3421,integrability,integration test,integration test,3421," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3470,integrability,integration test,integration test,3470," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:524,interoperability,compon,components,524,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:585,interoperability,compon,components,585,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:661,interoperability,compon,components,661,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:873,interoperability,Wrapper,Wrapper,873,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:904,interoperability,interfac,interfaces,904,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1348,interoperability,Wrapper,Wrappers,1348,"the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1388,interoperability,compon,components,1388,"is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to he",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3421,interoperability,integr,integration,3421," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3470,interoperability,integr,integration,3470," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:114,modifiability,refact,refactoring,114,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:172,modifiability,inherit,inheritance,172,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:524,modifiability,compon,components,524,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:585,modifiability,compon,components,585,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:661,modifiability,compon,components,661,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:895,modifiability,abstract,abstract,895,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:904,modifiability,interfac,interfaces,904,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1242,modifiability,coupl,coupling,1242,"alculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1388,modifiability,compon,components,1388,"is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to he",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1428,modifiability,coupl,couple,1428,"ihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Final",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2130,modifiability,configur,configuration,2130,"::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` cla",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2583,modifiability,reu,reuse,2583," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3251,modifiability,depend,dependencies-,3251," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3421,modifiability,integr,integration,3421," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3470,modifiability,integr,integration,3470," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:114,performance,refactor,refactoring,114,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:268,performance,optimiz,optimization,268,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:474,performance,optimiz,optimization,474,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:675,performance,parallel,parallelizable,675,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1003,performance,optimiz,optimization,1003,"ultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of bu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1199,performance,GPU,GPU,1199,"atistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails becaus",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2699,performance,time,time,2699," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3101,performance,parallel,parallel,3101," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:501,reliability,stabil,stability,501,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2189,reliability,fail,fails,2189,"se the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](h",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2206,reliability,doe,doesn,2206,"ernal tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3421,reliability,integr,integration,3421," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3470,reliability,integr,integration,3470," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:23,safety,Test,TestStatistics,23,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:58,safety,Test,TestStatistics,58,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:145,safety,Test,TestStatistic,145,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1486,safety,review,reviewers,1486,"numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2157,safety,test,testRooRealL,2157,"sible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2282,safety,reme,remember,2282,"er` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2420,safety,test,test,2420,"ill a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2864,safety,test,test,2864," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2994,safety,test,test,2994," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3149,safety,test,test,3149," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3233,safety,test,teststatistics-pr-dependencies-,3233," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3433,safety,test,test,3433," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3482,safety,test,test,3482," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2130,security,configur,configuration,2130,"::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` cla",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3421,security,integr,integration,3421," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3470,security,integr,integration,3470," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:23,testability,Test,TestStatistics,23,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:58,testability,Test,TestStatistics,58,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:145,testability,Test,TestStatistic,145,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:344,testability,unit,unit,344,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:547,testability,observ,observables,547,"RooFit::MultiProcess & TestStatistics part 6: add RooFit::TestStatistics; ## Changes:. This PR introduces a major refactoring of the `RooAbs(Opt)TestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1242,testability,coupl,coupling,1242,"alculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1428,testability,coupl,couple,1428,"ihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Final",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1486,testability,review,reviewers,1486,"numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1829,testability,simpl,simple,1829,"likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2157,testability,test,testRooRealL,2157,"sible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2420,testability,test,test,2420,"ill a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2864,testability,test,test,2864," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2985,testability,coverag,coverage,2985," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2994,testability,test,test,2994," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3149,testability,test,test,3149," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3233,testability,test,teststatistics-pr-dependencies-,3233," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3421,testability,integr,integration,3421," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3433,testability,test,test,3433," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3470,testability,integr,integration,3470," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3482,testability,test,test,3482," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1215,usability,tool,tools,1215,"asses on the one hand;. 2. calculation/evaluation/optimization based classes on the other hand. The likelihood is the central unit on the statistics side. The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1500,usability,help,help,1500,"tability that gathers components like global observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1543,usability,help,helper,1543," observables) and ""sum"" (over multiple components of the other types). These classes provide ways to compute their components in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a set of likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGrad",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:1829,usability,simpl,simple,1829,"likelihood builders. The calculator ""`...Wrapper`"" classes are abstract interfaces. These can be implemented for different kinds of algorithms, or with different kinds of optimization ""back-ends"" in mind. In an upcoming PR, we will introduce the fork-based multi-processing implementation based on `RooFit::MultiProcess`. Other possible implementations could use the GPU or external tools like TensorFlow. The coupling of all these classes to `RooMinimizer` is made via the `MinuitFcnGrad` class, which owns the `...Wrappers` that calculate the likelihood components. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2391,usability,help,help,2391,"nents. ## Todo:. There are still a couple of things that require attention, which I hope the reviewers can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMini",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:2939,usability,minim,minimization,2939," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8700:3032,usability,minim,minimization,3032," can help me with:. 1. I have a Kahan summation helper class. This should probably be replaced with the new Kahan summation class in ROOT itself, but I didn't get to this yet. Maybe it is not urgent to do now, up for discussion. 2. `likelihood_builders.cxx` is still missing the top level entry point function. This should be quite a simple function: it should just check whether the pdf is binned, unbinned or sum and has subsidiary terms. All the building blocks are already present, so it is just a matter of building it, but didn't get to it yet. 3. `optional_parameter_types.h`: maybe we could replace this with @guitargeek's new configuration structs. 4. `testRooRealL.getValRooAddition` fails because it doesn't know `RooFormulaVar`... I'm not sure what this means, but I vaguely remember that (I think) @hageboeck and @cburgard were talking about this, so I was hoping you may be able to help me out with fixing that test. Finally, one thing that in an ideal world I would have liked to do is add a serial implementation of the `LikelihoodGradientWrapper` class. Probably, we can reuse a lot of `RooGradMinimizerFcn` for this and it should be rather straightforward. However, I'm rather short on time right now, and these things almost always tend to take longer than one expects, so I'm hesitant to build it now. The **advantage** would be that we could add a test to this PR that covers all that is added, basically by just running a minimization. Note that I do have such a full-coverage test, but only for the `MultiProcess` minimization, where I implemented `LikelihoodGradientWrapper` in the parallel `LikelihoodGradientJob` class. So this test will come in [""PR 7"" (see overview)](https://whimsical.com/roofit-multiprocess-teststatistics-pr-dependencies-QP47k9PyS24VuboQUP5W6P). So, up for discussion, two choices: **A:** add ""`LikelihoodGradientSerial`"" class (based on `RooGradMinimizerFcn`) so we can add an integration test in this PR; **B:** wait for the integration test in PR 7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8700
https://github.com/root-project/root/pull/8701:7,modifiability,Variab,Variable,7,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8701
https://github.com/root-project/root/pull/8701:60,modifiability,Variab,Variable,60,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8701
https://github.com/root-project/root/pull/8701:99,safety,input,inputs,99,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8701
https://github.com/root-project/root/pull/8701:483,safety,test,tested,483,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8701
https://github.com/root-project/root/pull/8701:483,testability,test,tested,483,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8701
https://github.com/root-project/root/pull/8701:99,usability,input,inputs,99,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created two tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva005_RVariablePlotter_RTensor.C . ## Checklist:. - [ ✅] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8701
https://github.com/root-project/root/pull/8702:162,availability,operat,operator,162,"[RF] Use RooAbsCollection::assign() in RooFit code; After the `RooAbsCollection::assign()` function was introduced as a. better alternative to `RooAbsCollection::operator=()` in commit. 4fff188, this commit now makes use of it in all the RooFit code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8702
https://github.com/root-project/root/pull/8703:115,availability,cluster,cluster,115,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:276,availability,cluster,clusters,276,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:425,availability,cluster,cluster,425,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:592,availability,cluster,clusters,592,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:629,availability,cluster,clusters,629,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:734,availability,cluster,clusters,734,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:820,availability,cluster,cluster,820,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:891,availability,cluster,clusters,891,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:938,availability,cluster,clusters,938,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1456,availability,cluster,cluster,1456,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1563,availability,cluster,cluster,1563,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1616,availability,cluster,cluster,1616,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1701,availability,cluster,cluster,1701,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1771,availability,cluster,clusters,1771,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1818,availability,cluster,cluster,1818,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:2137,availability,cluster,cluster,2137,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:115,deployability,cluster,cluster,115,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:276,deployability,cluster,clusters,276,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:425,deployability,cluster,cluster,425,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:592,deployability,cluster,clusters,592,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:629,deployability,cluster,clusters,629,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:734,deployability,cluster,clusters,734,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:820,deployability,cluster,cluster,820,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:891,deployability,cluster,clusters,891,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:938,deployability,cluster,clusters,938,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1456,deployability,cluster,cluster,1456,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1563,deployability,cluster,cluster,1563,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1616,deployability,cluster,cluster,1616,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1701,deployability,cluster,cluster,1701,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1771,deployability,cluster,clusters,1771,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1818,deployability,cluster,cluster,1818,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:2137,deployability,cluster,cluster,2137,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:296,energy efficiency,measur,measured,296,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1137,energy efficiency,reduc,reduce,1137,"e of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the clu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1448,energy efficiency,current,current,1448,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1555,energy efficiency,current,current,1555,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1588,energy efficiency,estimat,estimate,1588,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1659,energy efficiency,estimat,estimated,1659,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1829,energy efficiency,estimat,estimate,1829,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:759,integrability,buffer,buffered,759,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1227,integrability,buffer,buffer,1227," needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:2035,integrability,buffer,buffers,2035,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:2077,integrability,buffer,buffer,2077,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:2103,integrability,buffer,buffer,2103,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:841,performance,memor,memory,841,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1148,performance,memor,memory,1148,"e. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1282,reliability,doe,does,1282," and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:911,safety,Prevent,Prevents,911,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1982,safety,prevent,prevent,1982,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:911,security,Preven,Prevents,911,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1982,security,preven,prevent,1982,"e good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets flushed with an undersized tail page, the small page is appended to the previous page before flushing. Therefore, tail pages sizes are between `[0.5 * target size .. 1.5 * target size]`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:841,usability,memor,memory,841,"[ntuple] Overhaul tuning and default settings when writing; # This Pull request:. The PR sets new defaults for the cluster size and page size of RNTuple. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/pull/8703:1148,usability,memor,memory,1148,"e. The default should work well in the majority of cases but can be adjusted if needed. The idea is to give target sizes for clusters and pages (measured in bytes). RNTuple will try make good decisions and approximate the target sizes. The PR replaces previous defaults for cluster size and page size given in number of entries and number of elements resp. ## Changes or fixes:. The PR sets three new defaults:. - Target size for compressed clusters of 50MB. In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed. However, clusters also need to be buffered during write and (partially) during read, so larger cluster increase the memory footprint. - Maximum size for uncompressed clusters of 512MiB. Prevents very compressible clusters from growing too large. That is mostly a problem for writing. - Target size for uncompressed pages of 64KiB. In general, larger pages give better compression ratios. Smaller pages, however, reduce the memory footprint. When reading, every active column requires at least one page buffer. For the number of read requests, the page size does not matter because pages of the same column are written consecutively and therefore read in one go. Given the three settings, writing works as follows: when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally. When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too. The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise. The following clusters use the compression ratio of the last cluster as estimate. Pages are filled until the target size and then flushed. If a column has enough elements to fill at least half a page, there is a mechanism to prevent undersized tail pages: writing uses two page buffers in turns and flushes the previous buffer only once the next buffer is at least at 50%. If the cluster gets f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8703
https://github.com/root-project/root/issues/8704:48,energy efficiency,Draw,Draw,48,"[DF] Add support for 'missing' columns; `TTree::Draw` supports a special function `Alt$` which allows to specify a value to be used if a column (or element of a collection) in missing. RDataFrame could use a similar feature (for example `DefineAlternative(column_name, alternative_value)`. [As a side note, `TTreeReaderValue` currently seem to complain if the underlying column is missing).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8704
https://github.com/root-project/root/issues/8704:326,energy efficiency,current,currently,326,"[DF] Add support for 'missing' columns; `TTree::Draw` supports a special function `Alt$` which allows to specify a value to be used if a column (or element of a collection) in missing. RDataFrame could use a similar feature (for example `DefineAlternative(column_name, alternative_value)`. [As a side note, `TTreeReaderValue` currently seem to complain if the underlying column is missing).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8704
https://github.com/root-project/root/issues/8704:105,interoperability,specif,specify,105,"[DF] Add support for 'missing' columns; `TTree::Draw` supports a special function `Alt$` which allows to specify a value to be used if a column (or element of a collection) in missing. RDataFrame could use a similar feature (for example `DefineAlternative(column_name, alternative_value)`. [As a side note, `TTreeReaderValue` currently seem to complain if the underlying column is missing).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8704
https://github.com/root-project/root/issues/8704:344,safety,compl,complain,344,"[DF] Add support for 'missing' columns; `TTree::Draw` supports a special function `Alt$` which allows to specify a value to be used if a column (or element of a collection) in missing. RDataFrame could use a similar feature (for example `DefineAlternative(column_name, alternative_value)`. [As a side note, `TTreeReaderValue` currently seem to complain if the underlying column is missing).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8704
https://github.com/root-project/root/issues/8704:344,security,compl,complain,344,"[DF] Add support for 'missing' columns; `TTree::Draw` supports a special function `Alt$` which allows to specify a value to be used if a column (or element of a collection) in missing. RDataFrame could use a similar feature (for example `DefineAlternative(column_name, alternative_value)`. [As a side note, `TTreeReaderValue` currently seem to complain if the underlying column is missing).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8704
https://github.com/root-project/root/issues/8704:9,usability,support,support,9,"[DF] Add support for 'missing' columns; `TTree::Draw` supports a special function `Alt$` which allows to specify a value to be used if a column (or element of a collection) in missing. RDataFrame could use a similar feature (for example `DefineAlternative(column_name, alternative_value)`. [As a side note, `TTreeReaderValue` currently seem to complain if the underlying column is missing).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8704
https://github.com/root-project/root/issues/8704:54,usability,support,supports,54,"[DF] Add support for 'missing' columns; `TTree::Draw` supports a special function `Alt$` which allows to specify a value to be used if a column (or element of a collection) in missing. RDataFrame could use a similar feature (for example `DefineAlternative(column_name, alternative_value)`. [As a side note, `TTreeReaderValue` currently seem to complain if the underlying column is missing).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8704
https://github.com/root-project/root/pull/8705:325,deployability,updat,updated,325,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:5,integrability,Translat,Translated,5,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:79,integrability,Translat,Translated,79,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:5,interoperability,Translat,Translated,5,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:79,interoperability,Translat,Translated,79,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:295,safety,test,tested,295,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:325,safety,updat,updated,325,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:129,security,sign,signature,129,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:325,security,updat,updated,325,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:232,testability,simpl,simple,232,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:295,testability,test,tested,295,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/pull/8705:232,usability,simpl,simple,232,[RF] Translated rf_408_RDataFrameToRooFit.C to python; # This Pull request:. - Translated rf_408_RDataFrameToRooFit.C. - Changed signature of constructor to take RooAbsArg by reference. - Changed ROOT.RooArgList in args to accept a simple Python list. ## Changes or fixes:. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8705
https://github.com/root-project/root/issues/8706:464,availability,avail,available,464,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:603,availability,avail,available,603,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1319,availability,Operat,Operating,1319,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1394,availability,down,download,1394,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:20,deployability,releas,release,20,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:263,deployability,releas,releases,263,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:413,deployability,version,versions,413,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:447,deployability,releas,releases,447,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:526,deployability,version,version,526,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:592,deployability,releas,release,592,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:646,deployability,releas,releases,646,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:737,deployability,releas,releases,737,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:942,deployability,releas,release,942,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:961,deployability,automat,automatically,961,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:991,deployability,releas,release,991,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1238,deployability,build,build,1238,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1307,deployability,version,version,1307,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1376,deployability,instal,install,1376,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:276,energy efficiency,current,currently,276,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:0,integrability,Pub,Publish,0,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:413,integrability,version,versions,413,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:526,integrability,version,version,526,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:624,integrability,Pub,Publishing,624,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:925,integrability,Pub,Publishing,925,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1307,integrability,version,version,1307,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:504,interoperability,specif,specific,504,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:810,interoperability,share,share,810,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:413,modifiability,version,versions,413,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:526,modifiability,version,version,526,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1307,modifiability,version,version,1307,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:464,reliability,availab,available,464,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:538,reliability,pra,practically,538,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:603,reliability,availab,available,603,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:464,safety,avail,available,464,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:603,safety,avail,available,603,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1200,safety,input,input,1200,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:464,security,availab,available,464,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:603,security,availab,available,603,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:961,testability,automat,automatically,961,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1453,testability,context,context,1453,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1482,testability,context,context,1482,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1055,usability,behavi,behavior,1055,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8706:1200,usability,input,input,1200,"Publish every (new) release on Zenodo; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. On [Zenodo](https://zenodo.org/search?q=conceptrecid:""848818""&sort=-publication_date&all_versions=True), only 10 releases are currently listed and the reason of selection is not obvious. None of ROOT 5 are there whereas there are still some usages of that legacy versions. Even the most of ROOT 6 releases are not available. As a result, citing ""the DOI specific to your ROOT version"" is practically difficult. It would be great if every new release is available on Zenodo. Publishing historical releases, ex. all ROOT 6 and recent ROOT 5 used by major projects, will be a plus. Ancient releases like ROOT 3 and 4 may not be worth doing, though. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. Publishing a new release on Zenodo (automatically) as part of the release process? ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code: build it / `root myMacro.C` / ... -->. N/A. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. N/A. ### Additional context. <!--. Add any other context about the problem here. -->. N/A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8706
https://github.com/root-project/root/issues/8707:136,deployability,depend,dependencies,136,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:191,deployability,depend,dependencies,191,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:169,energy efficiency,current,currently,169,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:136,integrability,depend,dependencies,136,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:191,integrability,depend,dependencies,191,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:136,modifiability,depend,dependencies,136,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:191,modifiability,depend,dependencies,191,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:136,safety,depend,dependencies,136,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:153,safety,test,tests,153,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:191,safety,depend,dependencies,191,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:212,safety,test,tests,212,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:136,testability,depend,dependencies,136,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:153,testability,test,tests,153,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:191,testability,depend,dependencies,191,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8707:212,testability,test,tests,212,Add ctest fixtures to root / roottest; CTest fixtures which have previously been added to Rootbench have been useful in defining better dependencies for tests. Since we currently cannot have dependencies between tests fixtures should be added into both root and roottest.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8707
https://github.com/root-project/root/issues/8708:378,availability,echo,echo,378,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:385,availability,error,error,385,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:846,availability,error,error,846,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1,deployability,Build,Build,1,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:250,deployability,instal,installed,250,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:481,deployability,Instal,Install,481,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:607,deployability,depend,dependency,607,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:648,deployability,Build,Build,648,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1134,deployability,depend,depends,1134,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1164,deployability,depend,depends,1164,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1237,deployability,instal,installed,1237,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1476,deployability,build,build,1476,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1930,deployability,instal,installed,1930,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:882,energy efficiency,core,core,882,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:951,energy efficiency,core,core,951,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1327,energy efficiency,core,core,1327,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1340,energy efficiency,core,core,1340,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1353,energy efficiency,core,core,1353,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:607,integrability,depend,dependency,607,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1134,integrability,depend,depends,1134,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1164,integrability,depend,depends,1164,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1967,integrability,configur,configured,1967,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:607,modifiability,depend,dependency,607,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1134,modifiability,depend,depends,1134,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1164,modifiability,depend,depends,1164,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1967,modifiability,configur,configured,1967,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:385,performance,error,error,385,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:846,performance,error,error,846,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:385,safety,error,error,385,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:607,safety,depend,dependency,607,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:753,safety,accid,accidentally,753,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:846,safety,error,error,846,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1134,safety,depend,depends,1134,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1164,safety,depend,depends,1164,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1967,security,configur,configured,1967,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:607,testability,depend,dependency,607,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1134,testability,depend,depends,1134,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1164,testability,depend,depends,1164,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:385,usability,error,error,385,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:733,usability,command,command,733,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:846,usability,error,error,846,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:927,usability,command,command,927,"[Build system] ROOT can wrongly pick up includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1298,usability,command,command,1298,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/issues/8708:1544,usability,behavi,behavior,1544,"p includes from system directories; - [ ] Checked for duplicates. Yes, kind of. I thought that there was a ticket about this by @amadio, but I didn't find anything. ## Describe the bug. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. ### How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. Now ROOT should find VDT, and add a `-I/my/include/directory/` to the compile command, which will accidentally include other parts of ROOT. The problem is that it's difficult to provoke this error using only one header:. - All core includes are prepended to every compile command, so none of the core includes will be picked up wrongly. - Library A will always find its own includes in the correct location, because it's also prepended. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/` (e.g. VDT), and `C` is *also* installed in those system includes. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. Instead of picking up `C` from ROOT's build directory, it now comes from `/system/include/`. ### Expected behavior. ROOT picks up all its own includes first, and system includes last. This can be achieved with `-isystem ...`, so every `-I ...` is searched before `-isystem ...`. In CMake, this means:. - Using imported targets when software comes from system directories (these are implicitly system includes). - Explicitly marking some include directories `SYSTEM`. ### Setup. Centos8. ROOT installed in `/data/software/`. ROOT configured with. `cmake -DCMAKE_PREFIX_PATH=/data/software ... <root>`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8708
https://github.com/root-project/root/pull/8709:275,availability,echo,echo,275,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:282,availability,error,error,282,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1502,availability,error,error,1502,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1653,availability,error,error,1653,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:82,deployability,instal,installed,82,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:146,deployability,instal,installed,146,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:378,deployability,Instal,Install,378,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:504,deployability,depend,dependency,504,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:545,deployability,Build,Build,545,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:594,deployability,depend,depends,594,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:624,deployability,depend,depends,624,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:679,deployability,instal,installed,679,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1142,deployability,depend,dependency,1142,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1164,deployability,manag,management,1164,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1248,deployability,depend,dependency,1248,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1524,deployability,configurat,configuration,1524,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1584,deployability,depend,dependency,1584,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1787,deployability,depend,dependency,1787,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:777,energy efficiency,core,core,777,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:790,energy efficiency,core,core,790,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:803,energy efficiency,core,core,803,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1164,energy efficiency,manag,management,1164,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:504,integrability,depend,dependency,504,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:594,integrability,depend,depends,594,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:624,integrability,depend,depends,624,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1142,integrability,depend,dependency,1142,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1248,integrability,depend,dependency,1248,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1524,integrability,configur,configuration,1524,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1584,integrability,depend,dependency,1584,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1787,integrability,depend,dependency,1787,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:504,modifiability,depend,dependency,504,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:594,modifiability,depend,depends,594,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:624,modifiability,depend,depends,624,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1142,modifiability,depend,dependency,1142,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1248,modifiability,depend,dependency,1248,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1524,modifiability,configur,configuration,1524,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1584,modifiability,depend,dependency,1584,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1787,modifiability,depend,dependency,1787,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:282,performance,error,error,282,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1502,performance,error,error,1502,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1653,performance,error,error,1653,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:282,safety,error,error,282,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:504,safety,depend,dependency,504,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:594,safety,depend,depends,594,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:624,safety,depend,depends,624,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1142,safety,depend,dependency,1142,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1164,safety,manag,management,1164,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1248,safety,depend,dependency,1248,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1502,safety,error,error,1502,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1545,safety,detect,detected,1545,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1584,safety,depend,dependency,1584,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1653,safety,error,error,1653,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1787,safety,depend,dependency,1787,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1524,security,configur,configuration,1524,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1545,security,detect,detected,1545,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:504,testability,depend,dependency,504,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:594,testability,depend,depends,594,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:624,testability,depend,depends,624,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1142,testability,depend,dependency,1142,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1178,testability,simpl,simplified,1178,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1248,testability,depend,dependency,1248,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1584,testability,depend,dependency,1584,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1787,testability,depend,dependency,1787,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:282,usability,error,error,282,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:748,usability,command,command,748,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1178,usability,simpl,simplified,1178,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1502,usability,error,error,1502,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8709:1653,usability,error,error,1653,"[CMake] Move towards target-based CMake and partly fix picking up headers from an installed ROOT; Partial fix of #8708. In a setup where ROOT was installed in a system directory, ROOT was picking up headers from that directory instead of its own. . ## How to reproduce:. 1. `echo '#error This is the wrong header' > /my/include/directory/RooSpan.h` (or a few other headers). 2. Install some builtins into that directory, e.g. VDT. 3. `cmake -DCMAKE_PREFIX_PATH=/my/include/directory/ <root>` to create a dependency to that include directory. 4. Build. The problem only becomes visible when `A` depends on `B and C`, and `B` depends on something in `/system/include/`, and `C` is installed in those system includes as well. This generates a compile command such as:. ```. -I.../core/x -I.../core/y -I.../core/... -I.../A/include -I.../B/include -I/system/include/ -I.../C/include ... ```. ## In this PR:. - Includes for VDT and XROOTD are fixed by making them `IMPORTED` targets, so their includes have lowest precedence. - Some cheating where include directories are copied around between targets is removed. CMake should handle this. - Some dependency and target management is simplified (or rather modernised with target-based cmake). - A broken dependency in RooFit is fixed, which was previously hidden by the cheating with include directories. ## What remains to be done:. It is likely that more builtins (or rather `FindXXX` have to be converted to `IMPORTED` targets, so they don't provoke this error again. A broken configuration can be detected by. 1. Having CMake pick up a dependency in some common directory. 2. Either. - Placing a lot of `#error`-ROOT headers in there or. - Searching `compile_commands.json` for `-I/my/include/directory/`. 3. Fixing the `FindXXX` for this dependency.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8709
https://github.com/root-project/root/pull/8710:24,modifiability,variab,variable,24,[minuit2] Fix an unused variable warning with gcc 11;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8710
https://github.com/root-project/root/issues/8711:28,energy efficiency,model,models,28,"Allow definition of RNTuple models directly in the constructor; ### Explain what you would like to see improved. It would be a nice interface improvement to be able to define an RNTuple model directly in the constructor. As a result, somthing like the following would be possible:. auto ntuple = RNTupleWriter::Recreate({. RField<std::uint32_t>(""id""),. RField<std::vector<float>>(""vpx""),. RField<std::vector<float>>(""vpy""),. RField<std::vector<float>>(""vpz""). }, ""NTuple"", kNTupleFileName);. See #8688 for the full discussion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8711
https://github.com/root-project/root/issues/8711:186,energy efficiency,model,model,186,"Allow definition of RNTuple models directly in the constructor; ### Explain what you would like to see improved. It would be a nice interface improvement to be able to define an RNTuple model directly in the constructor. As a result, somthing like the following would be possible:. auto ntuple = RNTupleWriter::Recreate({. RField<std::uint32_t>(""id""),. RField<std::vector<float>>(""vpx""),. RField<std::vector<float>>(""vpy""),. RField<std::vector<float>>(""vpz""). }, ""NTuple"", kNTupleFileName);. See #8688 for the full discussion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8711
https://github.com/root-project/root/issues/8711:132,integrability,interfac,interface,132,"Allow definition of RNTuple models directly in the constructor; ### Explain what you would like to see improved. It would be a nice interface improvement to be able to define an RNTuple model directly in the constructor. As a result, somthing like the following would be possible:. auto ntuple = RNTupleWriter::Recreate({. RField<std::uint32_t>(""id""),. RField<std::vector<float>>(""vpx""),. RField<std::vector<float>>(""vpy""),. RField<std::vector<float>>(""vpz""). }, ""NTuple"", kNTupleFileName);. See #8688 for the full discussion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8711
https://github.com/root-project/root/issues/8711:132,interoperability,interfac,interface,132,"Allow definition of RNTuple models directly in the constructor; ### Explain what you would like to see improved. It would be a nice interface improvement to be able to define an RNTuple model directly in the constructor. As a result, somthing like the following would be possible:. auto ntuple = RNTupleWriter::Recreate({. RField<std::uint32_t>(""id""),. RField<std::vector<float>>(""vpx""),. RField<std::vector<float>>(""vpy""),. RField<std::vector<float>>(""vpz""). }, ""NTuple"", kNTupleFileName);. See #8688 for the full discussion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8711
https://github.com/root-project/root/issues/8711:132,modifiability,interfac,interface,132,"Allow definition of RNTuple models directly in the constructor; ### Explain what you would like to see improved. It would be a nice interface improvement to be able to define an RNTuple model directly in the constructor. As a result, somthing like the following would be possible:. auto ntuple = RNTupleWriter::Recreate({. RField<std::uint32_t>(""id""),. RField<std::vector<float>>(""vpx""),. RField<std::vector<float>>(""vpy""),. RField<std::vector<float>>(""vpz""). }, ""NTuple"", kNTupleFileName);. See #8688 for the full discussion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8711
https://github.com/root-project/root/issues/8711:28,security,model,models,28,"Allow definition of RNTuple models directly in the constructor; ### Explain what you would like to see improved. It would be a nice interface improvement to be able to define an RNTuple model directly in the constructor. As a result, somthing like the following would be possible:. auto ntuple = RNTupleWriter::Recreate({. RField<std::uint32_t>(""id""),. RField<std::vector<float>>(""vpx""),. RField<std::vector<float>>(""vpy""),. RField<std::vector<float>>(""vpz""). }, ""NTuple"", kNTupleFileName);. See #8688 for the full discussion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8711
https://github.com/root-project/root/issues/8711:186,security,model,model,186,"Allow definition of RNTuple models directly in the constructor; ### Explain what you would like to see improved. It would be a nice interface improvement to be able to define an RNTuple model directly in the constructor. As a result, somthing like the following would be possible:. auto ntuple = RNTupleWriter::Recreate({. RField<std::uint32_t>(""id""),. RField<std::vector<float>>(""vpx""),. RField<std::vector<float>>(""vpy""),. RField<std::vector<float>>(""vpz""). }, ""NTuple"", kNTupleFileName);. See #8688 for the full discussion.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8711
https://github.com/root-project/root/issues/8712:74,deployability,contain,contains,74,"Documentation in C++ classes gets mixed with PyROOT doc box; The box that contains PyROOT documentation for a given class used to appear after the documentation that is written in the C++ file for that class. This is not the case anymore, for example:. https://root.cern.ch/doc/master/classTTree.html. https://root.cern.ch/doc/master/classTFile.html. Currently the first sentence of the C++ file docs appears first, after that there is the PyROOT box and finally the rest of the docs present in the C++ file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8712
https://github.com/root-project/root/issues/8712:351,energy efficiency,Current,Currently,351,"Documentation in C++ classes gets mixed with PyROOT doc box; The box that contains PyROOT documentation for a given class used to appear after the documentation that is written in the C++ file for that class. This is not the case anymore, for example:. https://root.cern.ch/doc/master/classTTree.html. https://root.cern.ch/doc/master/classTFile.html. Currently the first sentence of the C++ file docs appears first, after that there is the PyROOT box and finally the rest of the docs present in the C++ file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8712
https://github.com/root-project/root/issues/8712:0,usability,Document,Documentation,0,"Documentation in C++ classes gets mixed with PyROOT doc box; The box that contains PyROOT documentation for a given class used to appear after the documentation that is written in the C++ file for that class. This is not the case anymore, for example:. https://root.cern.ch/doc/master/classTTree.html. https://root.cern.ch/doc/master/classTFile.html. Currently the first sentence of the C++ file docs appears first, after that there is the PyROOT box and finally the rest of the docs present in the C++ file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8712
https://github.com/root-project/root/issues/8712:90,usability,document,documentation,90,"Documentation in C++ classes gets mixed with PyROOT doc box; The box that contains PyROOT documentation for a given class used to appear after the documentation that is written in the C++ file for that class. This is not the case anymore, for example:. https://root.cern.ch/doc/master/classTTree.html. https://root.cern.ch/doc/master/classTFile.html. Currently the first sentence of the C++ file docs appears first, after that there is the PyROOT box and finally the rest of the docs present in the C++ file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8712
https://github.com/root-project/root/issues/8712:147,usability,document,documentation,147,"Documentation in C++ classes gets mixed with PyROOT doc box; The box that contains PyROOT documentation for a given class used to appear after the documentation that is written in the C++ file for that class. This is not the case anymore, for example:. https://root.cern.ch/doc/master/classTTree.html. https://root.cern.ch/doc/master/classTFile.html. Currently the first sentence of the C++ file docs appears first, after that there is the PyROOT box and finally the rest of the docs present in the C++ file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8712
https://github.com/root-project/root/issues/8713:163,deployability,log,logic,163,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:452,performance,network,network,452,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:163,safety,log,logic,163,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:163,security,log,logic,163,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:452,security,network,network,452,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:163,testability,log,logic,163,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:533,testability,context,context,533,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:562,testability,context,context,562,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:86,usability,clear,clear,86,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/issues/8713:134,usability,behavi,behavior,134,"[tree] TTreeCache is turned off when `fAutoFlush == 0`; ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Due to the logic in `TTree::GetCacheAutoSize`, if `fAutoFlush == 0` then the size of the `TTreeCache` is set to 0 which in turn disables it. However there are separate mechanisms to disable the `TTreeCache` if desired (e.g. `TTree::SetCacheSize`) and even if `fAutoFlush == 0`, when reading over the network, we can benefit greatly from `TTreeCache`'s pre-fetching. ### Additional context. <!--. Add any other context about the problem here. -->. - discussion and debugging: https://mattermost.web.cern.ch/root/pl/uzub3wwt3bdxxcdu4jmxxyrmby. - summary: https://mattermost.web.cern.ch/root/pl/xmtuq55j3pnc7cp7f8zyhf5ujw.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8713
https://github.com/root-project/root/pull/8714:67,deployability,log,logic,67,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:526,deployability,updat,updated,526,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:585,deployability,updat,update,585,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:59,energy efficiency,current,current,59,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:617,performance,cach,cachesize,617,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:67,safety,log,logic,67,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:399,safety,test,tested,399,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:423,safety,compl,complicated,423,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:526,safety,updat,updated,526,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:585,safety,updat,update,585,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:67,security,log,logic,67,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:423,security,compl,complicated,423,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:526,security,updat,updated,526,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:585,security,updat,update,585,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:67,testability,log,logic,67,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8714:399,testability,test,tested,399,"[tree] Enable TTreeCache even if fAutoFlush == 0; With the current logic, if for some reason fAutoFlush is set to 0. for the TTree, the TTreeCache is disabled. That is undesirable: we still can and want to do pre-fetching even. if auto-flushing was turned off when writing the TTree. Other more direct methods to turn off the TTreeCache still work,. e.g. tree->SetCacheSize(0). ## Checklist:. - [x] tested changes locally (complicated because of https://github.com/root-project/root/issues/7366 , but seems mostly ok) . - [ ] updated the docs (@pcanal let me know if there are docs to update). - [x] could we set the cachesize to a better value than the autoflush default of ~30MB? This PR fixes #8713 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8714
https://github.com/root-project/root/pull/8715:361,deployability,infrastructur,infrastructure,361,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:25,integrability,queue,queue,25,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:164,integrability,queue,queue,164,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:25,performance,queue,queue,25,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:164,performance,queue,queue,164,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:11,safety,safe,safe,11,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:150,safety,safe,safe,150,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:291,safety,input,input,291,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/pull/8715:291,usability,input,input,291,"Add thread-safe, bounded queue to sychronize producer-consumer threads; # This Pull request:. As a follow-up from #8688, this is a sketch of a thread-safe, bounded queue that could be used as a channel to transfer work items between consumer and producer threads. Opened as draft to solicit input if such a class would be a useful addition to the ROOT internal infrastructure.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8715
https://github.com/root-project/root/issues/8716:59,deployability,patch,patch,59,"Minuit2: FCNGradientBase::CheckGradient() is ignored; This patch. https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694. had an unintended side-effect. The code to check the external gradient against the numerical gradient when `CheckGradient()` returns `true` is now never executed. Whether the user provides an analytical gradient or not, only this implementation is called. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L42. while the other implementation is now never executed. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L103. I suggest to revert https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694, because it also confused iminuit users, see https://github.com/scikit-hep/iminuit/issues/644. People usually use the analytical gradient only when the calculation of the likelihood is extremely expensive, and then it is undesired that some gradients are still computed numerically.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8716
https://github.com/root-project/root/issues/8716:59,safety,patch,patch,59,"Minuit2: FCNGradientBase::CheckGradient() is ignored; This patch. https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694. had an unintended side-effect. The code to check the external gradient against the numerical gradient when `CheckGradient()` returns `true` is now never executed. Whether the user provides an analytical gradient or not, only this implementation is called. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L42. while the other implementation is now never executed. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L103. I suggest to revert https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694, because it also confused iminuit users, see https://github.com/scikit-hep/iminuit/issues/644. People usually use the analytical gradient only when the calculation of the likelihood is extremely expensive, and then it is undesired that some gradients are still computed numerically.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8716
https://github.com/root-project/root/issues/8716:59,security,patch,patch,59,"Minuit2: FCNGradientBase::CheckGradient() is ignored; This patch. https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694. had an unintended side-effect. The code to check the external gradient against the numerical gradient when `CheckGradient()` returns `true` is now never executed. Whether the user provides an analytical gradient or not, only this implementation is called. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L42. while the other implementation is now never executed. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L103. I suggest to revert https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694, because it also confused iminuit users, see https://github.com/scikit-hep/iminuit/issues/644. People usually use the analytical gradient only when the calculation of the likelihood is extremely expensive, and then it is undesired that some gradients are still computed numerically.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8716
https://github.com/root-project/root/issues/8716:327,usability,user,user,327,"Minuit2: FCNGradientBase::CheckGradient() is ignored; This patch. https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694. had an unintended side-effect. The code to check the external gradient against the numerical gradient when `CheckGradient()` returns `true` is now never executed. Whether the user provides an analytical gradient or not, only this implementation is called. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L42. while the other implementation is now never executed. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L103. I suggest to revert https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694, because it also confused iminuit users, see https://github.com/scikit-hep/iminuit/issues/644. People usually use the analytical gradient only when the calculation of the likelihood is extremely expensive, and then it is undesired that some gradients are still computed numerically.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8716
https://github.com/root-project/root/issues/8716:784,usability,user,users,784,"Minuit2: FCNGradientBase::CheckGradient() is ignored; This patch. https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694. had an unintended side-effect. The code to check the external gradient against the numerical gradient when `CheckGradient()` returns `true` is now never executed. Whether the user provides an analytical gradient or not, only this implementation is called. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L42. while the other implementation is now never executed. https://github.com/root-project/root/blob/master/math/minuit2/src/MnSeedGenerator.cxx#L103. I suggest to revert https://github.com/root-project/root/commit/ae9f8ae62553f9150fdee1f8739be6996d539694, because it also confused iminuit users, see https://github.com/scikit-hep/iminuit/issues/644. People usually use the analytical gradient only when the calculation of the likelihood is extremely expensive, and then it is undesired that some gradients are still computed numerically.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8716
https://github.com/root-project/root/pull/8717:368,availability,failur,failures,368,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:206,deployability,fail,fail,206,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:368,deployability,fail,failures,368,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:468,deployability,fail,fails,468,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:513,deployability,build,build,513,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:939,deployability,updat,updated,939,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:88,integrability,interfac,interfacing,88,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:758,integrability,interfac,interfacing,758,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:5,interoperability,conflict,conflict,5,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:73,interoperability,conflict,conflicts,73,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:88,interoperability,interfac,interfacing,88,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:743,interoperability,conflict,conflicts,743,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:758,interoperability,interfac,interfacing,758,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:88,modifiability,interfac,interfacing,88,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:160,modifiability,pac,package,160,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:524,modifiability,pac,package,524,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:758,modifiability,interfac,interfacing,758,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:368,performance,failur,failures,368,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:390,performance,parallel,parallel,390,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:479,performance,time,times,479,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:206,reliability,fail,fail,206,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:368,reliability,fail,failures,368,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:468,reliability,fail,fails,468,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:195,safety,test,tests,195,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:279,safety,test,tested,279,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:363,safety,test,test,363,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:909,safety,test,tested,909,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:939,safety,updat,updated,939,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:939,security,updat,updated,939,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:195,testability,test,tests,195,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:279,testability,test,tested,279,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:363,testability,test,test,363,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8717:909,testability,test,tested,909,"Llvm conflict fix; @vgvassilev, here is the PR so solve the LLVM library conflicts when interfacing ROOT with Julia. I've limited the change to the interpreter package. I have 25 out of the 2140 tests that fail. It's likely to be due to my local environment. If it can easily be tested with the jenkins system, it will be faster that me trying to investigate the test failures. . Note. The parallel compilation is not working properly, independently of my changes: it fails many times and need to be restarted or build some package in single process mode. Is it a know problem ? # This Pull request:. ## Changes or fixes:. Adds -Bsymbolic linker option for libCling.so in order get the symbols resolved internally. . This is expected to solve conflicts when interfacing with other software using LLVM, like Julia. See https://github.com/JuliaHEP/ROOT.jl/issues/17#issuecomment-882719292. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8717
https://github.com/root-project/root/pull/8718:188,deployability,updat,updated,188,Added histMax tutorial; # This Pull request:. ## Changes or fixes:. Adds a tutorial demoing how the hist->GetMaximumBin() can be used. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8718
https://github.com/root-project/root/pull/8718:158,safety,test,tested,158,Added histMax tutorial; # This Pull request:. ## Changes or fixes:. Adds a tutorial demoing how the hist->GetMaximumBin() can be used. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8718
https://github.com/root-project/root/pull/8718:188,safety,updat,updated,188,Added histMax tutorial; # This Pull request:. ## Changes or fixes:. Adds a tutorial demoing how the hist->GetMaximumBin() can be used. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8718
https://github.com/root-project/root/pull/8718:188,security,updat,updated,188,Added histMax tutorial; # This Pull request:. ## Changes or fixes:. Adds a tutorial demoing how the hist->GetMaximumBin() can be used. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8718
https://github.com/root-project/root/pull/8718:158,testability,test,tested,158,Added histMax tutorial; # This Pull request:. ## Changes or fixes:. Adds a tutorial demoing how the hist->GetMaximumBin() can be used. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8718
https://github.com/root-project/root/pull/8719:185,deployability,updat,updated,185,Added Kronecker Delta Function; # This Pull request:. ## Changes or fixes:. Adds the Kronecker Delta function used widely in Physics. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719
https://github.com/root-project/root/pull/8719:155,safety,test,tested,155,Added Kronecker Delta Function; # This Pull request:. ## Changes or fixes:. Adds the Kronecker Delta function used widely in Physics. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719
https://github.com/root-project/root/pull/8719:185,safety,updat,updated,185,Added Kronecker Delta Function; # This Pull request:. ## Changes or fixes:. Adds the Kronecker Delta function used widely in Physics. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719
https://github.com/root-project/root/pull/8719:185,security,updat,updated,185,Added Kronecker Delta Function; # This Pull request:. ## Changes or fixes:. Adds the Kronecker Delta function used widely in Physics. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719
https://github.com/root-project/root/pull/8719:155,testability,test,tested,155,Added Kronecker Delta Function; # This Pull request:. ## Changes or fixes:. Adds the Kronecker Delta function used widely in Physics. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8719
https://github.com/root-project/root/issues/8720:265,energy efficiency,current,current,265,Apply TChain::SetImplicitMT() to underlying trees; - [X] Checked for duplicates. ### Describe the bug. Setting `TChain::SetImplicitMT()` does not apply the setting to the underlying trees. ### Expected behavior. A call to `TChain::SetImplicitMT()` should influence current and future (`TChain::LoadTree`) backing trees. ### Additional context. Discussed in the I/O MM channel.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8720
https://github.com/root-project/root/issues/8720:294,energy efficiency,Load,LoadTree,294,Apply TChain::SetImplicitMT() to underlying trees; - [X] Checked for duplicates. ### Describe the bug. Setting `TChain::SetImplicitMT()` does not apply the setting to the underlying trees. ### Expected behavior. A call to `TChain::SetImplicitMT()` should influence current and future (`TChain::LoadTree`) backing trees. ### Additional context. Discussed in the I/O MM channel.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8720
https://github.com/root-project/root/issues/8720:294,performance,Load,LoadTree,294,Apply TChain::SetImplicitMT() to underlying trees; - [X] Checked for duplicates. ### Describe the bug. Setting `TChain::SetImplicitMT()` does not apply the setting to the underlying trees. ### Expected behavior. A call to `TChain::SetImplicitMT()` should influence current and future (`TChain::LoadTree`) backing trees. ### Additional context. Discussed in the I/O MM channel.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8720
https://github.com/root-project/root/issues/8720:361,performance,I/O,I/O,361,Apply TChain::SetImplicitMT() to underlying trees; - [X] Checked for duplicates. ### Describe the bug. Setting `TChain::SetImplicitMT()` does not apply the setting to the underlying trees. ### Expected behavior. A call to `TChain::SetImplicitMT()` should influence current and future (`TChain::LoadTree`) backing trees. ### Additional context. Discussed in the I/O MM channel.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8720
https://github.com/root-project/root/issues/8720:137,reliability,doe,does,137,Apply TChain::SetImplicitMT() to underlying trees; - [X] Checked for duplicates. ### Describe the bug. Setting `TChain::SetImplicitMT()` does not apply the setting to the underlying trees. ### Expected behavior. A call to `TChain::SetImplicitMT()` should influence current and future (`TChain::LoadTree`) backing trees. ### Additional context. Discussed in the I/O MM channel.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8720
https://github.com/root-project/root/issues/8720:335,testability,context,context,335,Apply TChain::SetImplicitMT() to underlying trees; - [X] Checked for duplicates. ### Describe the bug. Setting `TChain::SetImplicitMT()` does not apply the setting to the underlying trees. ### Expected behavior. A call to `TChain::SetImplicitMT()` should influence current and future (`TChain::LoadTree`) backing trees. ### Additional context. Discussed in the I/O MM channel.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8720
https://github.com/root-project/root/issues/8720:202,usability,behavi,behavior,202,Apply TChain::SetImplicitMT() to underlying trees; - [X] Checked for duplicates. ### Describe the bug. Setting `TChain::SetImplicitMT()` does not apply the setting to the underlying trees. ### Expected behavior. A call to `TChain::SetImplicitMT()` should influence current and future (`TChain::LoadTree`) backing trees. ### Additional context. Discussed in the I/O MM channel.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8720
https://github.com/root-project/root/issues/8721:138,safety,test,testvec,138,"TTree::Branch() is crashing on big arrarys; Hi,. the following code is crashing when Branching more than 10 arrays to the tree:. ```. int testvec() {. 	TTree *t = new TTree(""tree"",""tree"");. 	const int n = 92000;. 	unsigned int myN = n;. 	float arr1[n];. 	float arr2[n];. 	float arr3[n];. 	float arr4[n];. 	float arr5[n];. 	float arr6[n];. 	float arr7[n];. 	float arr8[n];. 	float arr9[n];. 	float arr10[n];. 	float arr11[n];. 	. 	t->Branch(""n"",&myN);. 	. 	t->Branch(""arr1"",arr1,""arr1[n]"");. 	t->Branch(""arr2"",arr2,""arr2[n]"");. 	t->Branch(""arr3"",arr3,""arr3[n]"");. 	t->Branch(""arr4"",arr4,""arr4[n]"");. 	t->Branch(""arr5"",arr5,""arr5[n]"");. 	t->Branch(""arr6"",arr6,""arr6[n]"");. 	t->Branch(""arr7"",arr7,""arr7[n]"");. 	t->Branch(""arr8"",arr8,""arr8[n]"");. 	t->Branch(""arr9"",arr9,""arr9[n]"");. 	t->Branch(""arr10"",arr10,""arr10[n]"");. 	t->Branch(""arr11"",arr11,""arr11[n]""); // Removing this line and the code will work. 	return 0;. }. ```. using a smaller ""n"" works, too. Using less than ten arrays works. Makes no difference to use arr[n] or arr[100000]. . Is there a maximum number of allowed references by a tree?? I'm using 6.22/02 on windows64 bit. Georg",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8721
https://github.com/root-project/root/issues/8721:138,testability,test,testvec,138,"TTree::Branch() is crashing on big arrarys; Hi,. the following code is crashing when Branching more than 10 arrays to the tree:. ```. int testvec() {. 	TTree *t = new TTree(""tree"",""tree"");. 	const int n = 92000;. 	unsigned int myN = n;. 	float arr1[n];. 	float arr2[n];. 	float arr3[n];. 	float arr4[n];. 	float arr5[n];. 	float arr6[n];. 	float arr7[n];. 	float arr8[n];. 	float arr9[n];. 	float arr10[n];. 	float arr11[n];. 	. 	t->Branch(""n"",&myN);. 	. 	t->Branch(""arr1"",arr1,""arr1[n]"");. 	t->Branch(""arr2"",arr2,""arr2[n]"");. 	t->Branch(""arr3"",arr3,""arr3[n]"");. 	t->Branch(""arr4"",arr4,""arr4[n]"");. 	t->Branch(""arr5"",arr5,""arr5[n]"");. 	t->Branch(""arr6"",arr6,""arr6[n]"");. 	t->Branch(""arr7"",arr7,""arr7[n]"");. 	t->Branch(""arr8"",arr8,""arr8[n]"");. 	t->Branch(""arr9"",arr9,""arr9[n]"");. 	t->Branch(""arr10"",arr10,""arr10[n]"");. 	t->Branch(""arr11"",arr11,""arr11[n]""); // Removing this line and the code will work. 	return 0;. }. ```. using a smaller ""n"" works, too. Using less than ten arrays works. Makes no difference to use arr[n] or arr[100000]. . Is there a maximum number of allowed references by a tree?? I'm using 6.22/02 on windows64 bit. Georg",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8721
https://github.com/root-project/root/pull/8722:317,deployability,resourc,resource,317,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:435,deployability,updat,updated,435,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:317,energy efficiency,resourc,resource,317,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:243,performance,parallel,parallel,243,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:288,performance,lock,lock,288,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:317,performance,resourc,resource,317,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:326,performance,lock,lock,326,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:235,safety,prevent,prevent,235,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:267,safety,test,test,267,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:317,safety,resourc,resource,317,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:367,safety,test,test,367,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:405,safety,test,tested,405,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:435,safety,updat,updated,435,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:235,security,preven,prevent,235,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:288,security,lock,lock,288,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:326,security,lock,lock,326,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:435,security,updat,updated,435,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:267,testability,test,test,267,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:317,testability,resourc,resource,317,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:367,testability,test,test,367,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:405,testability,test,tested,405,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8722:12,usability,support,support,12,"add fixture support to ROOT_ADD_TEST; This PR is related to https://github.com/root-project/root/issues/8707. ROOT_ADD_TEST now takes FIXTURES_SETUP, FIXTURES_CLEANUP and. FIXTURES_REQUIRED arguments (lists). also add RESOURCE_LOCK to prevent parallel execution of a test. takes a single lock name. n.b: fixtures and resource lock namespaces are each different from. test namespaces. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (in the file).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8722
https://github.com/root-project/root/pull/8723:7,modifiability,Variab,Variable,7,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created six tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva006_RVariablePlotter_RTensor.C . * /tutorials/tmva/tmva007_RVariablePlotter_Higgs_Output.C. * /tutorials/tmva/tmva008_RVariablePlotter_RTensor_Output.C. * /tutorials/tmva/tmva009_RVariablePlotter_Higgs_ROC.C. * /tutorials/tmva/tmva010_RVariablePlotter_Higgs_MultiROC.C. ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8723
https://github.com/root-project/root/pull/8723:60,modifiability,Variab,Variable,60,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created six tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva006_RVariablePlotter_RTensor.C . * /tutorials/tmva/tmva007_RVariablePlotter_Higgs_Output.C. * /tutorials/tmva/tmva008_RVariablePlotter_RTensor_Output.C. * /tutorials/tmva/tmva009_RVariablePlotter_Higgs_ROC.C. * /tutorials/tmva/tmva010_RVariablePlotter_Higgs_MultiROC.C. ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8723
https://github.com/root-project/root/pull/8723:99,safety,input,inputs,99,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created six tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva006_RVariablePlotter_RTensor.C . * /tutorials/tmva/tmva007_RVariablePlotter_Higgs_Output.C. * /tutorials/tmva/tmva008_RVariablePlotter_RTensor_Output.C. * /tutorials/tmva/tmva009_RVariablePlotter_Higgs_ROC.C. * /tutorials/tmva/tmva010_RVariablePlotter_Higgs_MultiROC.C. ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8723
https://github.com/root-project/root/pull/8723:720,safety,test,tested,720,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created six tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva006_RVariablePlotter_RTensor.C . * /tutorials/tmva/tmva007_RVariablePlotter_Higgs_Output.C. * /tutorials/tmva/tmva008_RVariablePlotter_RTensor_Output.C. * /tutorials/tmva/tmva009_RVariablePlotter_Higgs_ROC.C. * /tutorials/tmva/tmva010_RVariablePlotter_Higgs_MultiROC.C. ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8723
https://github.com/root-project/root/pull/8723:720,testability,test,tested,720,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created six tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva006_RVariablePlotter_RTensor.C . * /tutorials/tmva/tmva007_RVariablePlotter_Higgs_Output.C. * /tutorials/tmva/tmva008_RVariablePlotter_RTensor_Output.C. * /tutorials/tmva/tmva009_RVariablePlotter_Higgs_ROC.C. * /tutorials/tmva/tmva010_RVariablePlotter_Higgs_MultiROC.C. ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8723
https://github.com/root-project/root/pull/8723:99,usability,input,inputs,99,[tmva] Variable Plotter Implementation; Implementation of a Variable Plotter for RNode and RTensor inputs. See [PR 4211](https://github.com/root-project/root/pull/4211) for a first attempt / inspiration. . ## Changes or fixes:. Created main class: . * /tmva/tmvagui/src/RVariablePlotter.cxx. * /tmva/tmvagui/inc/RVariablePlotter.hxx. Created six tutorials: . * /tutorials/tmva/tmva005_RVariablePlotter.C . * /tutorials/tmva/tmva006_RVariablePlotter_RTensor.C . * /tutorials/tmva/tmva007_RVariablePlotter_Higgs_Output.C. * /tutorials/tmva/tmva008_RVariablePlotter_RTensor_Output.C. * /tutorials/tmva/tmva009_RVariablePlotter_Higgs_ROC.C. * /tutorials/tmva/tmva010_RVariablePlotter_Higgs_MultiROC.C. ## Checklist:. - [ ✅] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8723
https://github.com/root-project/root/pull/8724:69,deployability,log,logic,69,[ntuple] Fix RNTupleModel::GetField in case of empty argument; Wrong logic ended up returning fFieldZero instead of nullptr.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8724
https://github.com/root-project/root/pull/8724:69,safety,log,logic,69,[ntuple] Fix RNTupleModel::GetField in case of empty argument; Wrong logic ended up returning fFieldZero instead of nullptr.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8724
https://github.com/root-project/root/pull/8724:69,security,log,logic,69,[ntuple] Fix RNTupleModel::GetField in case of empty argument; Wrong logic ended up returning fFieldZero instead of nullptr.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8724
https://github.com/root-project/root/pull/8724:69,testability,log,logic,69,[ntuple] Fix RNTupleModel::GetField in case of empty argument; Wrong logic ended up returning fFieldZero instead of nullptr.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8724
https://github.com/root-project/root/pull/8725:22,energy efficiency,model,models,22,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:43,energy efficiency,current,current,43,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:265,energy efficiency,model,models,265,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:279,energy efficiency,current,current,279,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:133,safety,input,input,133,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:412,safety,test,tested,412,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:22,security,model,models,22,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:265,security,model,models,265,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:412,testability,test,tested,412,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8725:133,usability,input,input,133,"[TMVA][SOFIE] Parsing models not only from current working directory; . # This Pull request:. This is for not losing the path of the input filename after getting its filename without its path. This allows the parser to read files in any directory (previously, only models in the current working directory could be parsed). ## Changed files:. - /tmva/sofie_parsers/src/RModelParser_ONNX.cxx. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8725
https://github.com/root-project/root/pull/8726:210,deployability,updat,updated,210,[skip-ci] More descriptive descriptions in TH1; # This Pull request:. ## Changes or fixes:. Makes the descriptions for TH1::GetMaximum etc more descriptive. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8726
https://github.com/root-project/root/pull/8726:180,safety,test,tested,180,[skip-ci] More descriptive descriptions in TH1; # This Pull request:. ## Changes or fixes:. Makes the descriptions for TH1::GetMaximum etc more descriptive. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8726
https://github.com/root-project/root/pull/8726:210,safety,updat,updated,210,[skip-ci] More descriptive descriptions in TH1; # This Pull request:. ## Changes or fixes:. Makes the descriptions for TH1::GetMaximum etc more descriptive. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8726
https://github.com/root-project/root/pull/8726:210,security,updat,updated,210,[skip-ci] More descriptive descriptions in TH1; # This Pull request:. ## Changes or fixes:. Makes the descriptions for TH1::GetMaximum etc more descriptive. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8726
https://github.com/root-project/root/pull/8726:180,testability,test,tested,180,[skip-ci] More descriptive descriptions in TH1; # This Pull request:. ## Changes or fixes:. Makes the descriptions for TH1::GetMaximum etc more descriptive. . ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8726
https://github.com/root-project/root/pull/8728:193,interoperability,compatib,compatibility,193,"[RF] Merge RooListProxy and RooSetProxy classes into template class; Merge RooListProxy and RooSetProxy classes into the new template. RooCollectionProxy. This change should cause no backwards compatibility. issues, because the memory layouts remain the same.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8728
https://github.com/root-project/root/pull/8728:228,performance,memor,memory,228,"[RF] Merge RooListProxy and RooSetProxy classes into template class; Merge RooListProxy and RooSetProxy classes into the new template. RooCollectionProxy. This change should cause no backwards compatibility. issues, because the memory layouts remain the same.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8728
https://github.com/root-project/root/pull/8728:228,usability,memor,memory,228,"[RF] Merge RooListProxy and RooSetProxy classes into template class; Merge RooListProxy and RooSetProxy classes into the new template. RooCollectionProxy. This change should cause no backwards compatibility. issues, because the memory layouts remain the same.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8728
https://github.com/root-project/root/pull/8729:63,integrability,messag,messages,63,[RF] Some RooFit code modernization; See the individual commit messages.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8729
https://github.com/root-project/root/pull/8729:63,interoperability,messag,messages,63,[RF] Some RooFit code modernization; See the individual commit messages.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8729
https://github.com/root-project/root/pull/8730:272,modifiability,interm,intermediate,272,"[RF] Change signature of RooFit cross-collection constructors; In RooFit, there is a RooArgList constructor taking a RooArgSet and the. other way around. This is bad for pyROOT, because these constructors. might call each other, causing a RooArgList to be created via an. intermediate RooArgSet and vice versa. To fix this, the signature of these constructors is changed to take a. general RooAbsCollection.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8730
https://github.com/root-project/root/pull/8730:12,security,sign,signature,12,"[RF] Change signature of RooFit cross-collection constructors; In RooFit, there is a RooArgList constructor taking a RooArgSet and the. other way around. This is bad for pyROOT, because these constructors. might call each other, causing a RooArgList to be created via an. intermediate RooArgSet and vice versa. To fix this, the signature of these constructors is changed to take a. general RooAbsCollection.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8730
https://github.com/root-project/root/pull/8730:328,security,sign,signature,328,"[RF] Change signature of RooFit cross-collection constructors; In RooFit, there is a RooArgList constructor taking a RooArgSet and the. other way around. This is bad for pyROOT, because these constructors. might call each other, causing a RooArgList to be created via an. intermediate RooArgSet and vice versa. To fix this, the signature of these constructors is changed to take a. general RooAbsCollection.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8730
https://github.com/root-project/root/pull/8732:8,deployability,instal,install,8,Changed install location for builtins; # This Pull request:. ## Changes or fixes:. Changes the builtins install location to ${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #8655 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732
https://github.com/root-project/root/pull/8732:104,deployability,instal,install,104,Changed install location for builtins; # This Pull request:. ## Changes or fixes:. Changes the builtins install location to ${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #8655 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732
https://github.com/root-project/root/pull/8732:223,deployability,updat,updated,223,Changed install location for builtins; # This Pull request:. ## Changes or fixes:. Changes the builtins install location to ${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #8655 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732
https://github.com/root-project/root/pull/8732:193,safety,test,tested,193,Changed install location for builtins; # This Pull request:. ## Changes or fixes:. Changes the builtins install location to ${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #8655 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732
https://github.com/root-project/root/pull/8732:223,safety,updat,updated,223,Changed install location for builtins; # This Pull request:. ## Changes or fixes:. Changes the builtins install location to ${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #8655 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732
https://github.com/root-project/root/pull/8732:223,security,updat,updated,223,Changed install location for builtins; # This Pull request:. ## Changes or fixes:. Changes the builtins install location to ${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #8655 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732
https://github.com/root-project/root/pull/8732:193,testability,test,tested,193,Changed install location for builtins; # This Pull request:. ## Changes or fixes:. Changes the builtins install location to ${CMAKE_INSTALL_PREFIX}/include/ROOT_builtins}. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #8655 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8732
https://github.com/root-project/root/pull/8733:336,deployability,contain,contains-a-roouniform,336,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:115,integrability,batch,batch,115,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:221,integrability,batch,batches,221,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:115,performance,batch,batch,115,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:221,performance,batch,batches,221,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:165,safety,input,input,165,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:215,safety,input,input,215,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:165,usability,input,input,165,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8733:215,usability,input,input,215,"[RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. The backport of this PR to 6.24 is https://github.com/root-project/root/pull/8734.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8733
https://github.com/root-project/root/pull/8734:342,deployability,contain,contains-a-roouniform,342,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:121,integrability,batch,batch,121,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:227,integrability,batch,batches,227,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:121,performance,batch,batch,121,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:227,performance,batch,batches,227,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:171,safety,input,input,171,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:221,safety,input,input,221,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:171,usability,input,input,171,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/pull/8734:221,usability,input,input,221,"[v624][RF] Fix size of output span from `RooUniform::evaluateSpan()`; The size of the output span from the RooUniform in batch mode should be. the same as the size of the input spans, not the product of all sizes of. the input batches. This fixes a bug reported on the forum:. https://root-forum.cern.ch/t/rooaddpdf-evaluatespan-breaks-if-it-contains-a-roouniform. This is a backport of https://github.com/root-project/root/pull/8733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8734
https://github.com/root-project/root/issues/8735:1057,energy efficiency,cool,cool,1057,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:57,modifiability,variab,variable,57,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:703,modifiability,variab,variable,703,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:1165,modifiability,variab,variables,1165,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:895,reliability,doe,doesn,895,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:296,testability,simpl,simple,296,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:340,testability,simpl,simple,340,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:487,testability,simpl,simple,487,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:142,usability,clear,clear,142,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:296,usability,simpl,simple,296,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:340,usability,simpl,simple,340,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:396,usability,clear,clear,396,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/issues/8735:487,usability,simpl,simple,487,"TF1 Derivative of the whole Function with respect to any variable; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [...] when I want to [...]"". -->. Getting the derivative of a TF1 is not that simple. It's a common thing so it should be simple. . ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. At the moment it's not that simple to get the derivative of a TF1. There is a method to determine the derivative at a point but it would be nice if you could. - get the derivative of the whole function. - get the derivative with respect to any variable (d/dx, d/dy, d/dz ...) not just x. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? -->. I read that there is a Derivator but it doesn't seem that easy to use. If a TF1 derivative method is not added, maybe the Derivator docs could be improved/tutorials made. REASONING:. There are a lot of cool math functions that I would like to add and they rely on partial derivatives with respect to different variables and at the moment they are near impossible to make.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8735
https://github.com/root-project/root/pull/8736:72,usability,user,users,72,"[math] Remove unused headers.; These header files cannot be included by users (because they are in `src/`), and are not included by ROOT. Which means we don't need them.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8736
https://github.com/root-project/root/pull/8737:62,availability,error,error,62,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:139,availability,error,error,139,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:206,availability,error,error,206,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:499,availability,Error,Error,499,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:652,availability,error,error,652,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:695,availability,error,error,695,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:761,integrability,Filter,FilteringDiagConsumer,761,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:1339,integrability,repositor,repository,1339,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:1339,interoperability,repositor,repository,1339,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:740,modifiability,Required chang,Required changes,740,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:62,performance,error,error,62,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:139,performance,error,error,139,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:206,performance,error,error,206,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:499,performance,Error,Error,499,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:652,performance,error,error,652,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:695,performance,error,error,695,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:37,reliability,diagno,diagnostics,37,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:99,reliability,diagno,diagnostics,99,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:923,reliability,Diagno,DiagnosticConsumer,923,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:1005,reliability,diagno,diagnostic,1005,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:1096,reliability,diagno,diagnostic,1096,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:62,safety,error,error,62,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:139,safety,error,error,139,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:206,safety,error,error,206,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:499,safety,Error,Error,499,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:652,safety,error,error,652,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:695,safety,error,error,695,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:37,testability,diagno,diagnostics,37,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:99,testability,diagno,diagnostics,99,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:923,testability,Diagno,DiagnosticConsumer,923,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:1005,testability,diagno,diagnostic,1005,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:1096,testability,diagno,diagnostic,1096,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:62,usability,error,error,62,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:139,usability,error,error,139,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:206,usability,error,error,206,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:242,usability,user,user,242,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:499,usability,Error,Error,499,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:652,usability,error,error,652,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:695,usability,error,error,695,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8737:1228,usability,close,closes,1228,"[cling,tcling] Allow reporting cling diagnostics via the ROOT error handler; This PR enables cling diagnostics to be reported via the ROOT error handler, as required by the experiments. Independently, this error handler may be changed by the user (see `TError.h`), e.g. ```. root [0] int f() { return; }. ROOT_prompt_0:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [1] gInterpreter->ReportDiagnosticsToErrorHandler();. root [2] int f() { return; }. Error in <cling>: ROOT_prompt_2:1:11: non-void function 'f' should return a value [-Wreturn-type]. int f() { return; }. ^. root [3] // Note the previous error is reported through the default ROOT error handler. ```. ## Changes in this PR. - Required changes to `FilteringDiagConsumer` (in IncrementalParser.cpp). . - Two member functions have been added to the `Interpreter` class:. - `void replaceDiagnosticConsumer(clang::DiagnosticConsumer* Consumer, bool Own)`: replaces the default CIFactory-provided diagnostic consumer. - `bool hasReplacedDiagnosticConsumer()`: returns whether the default diagnostic consumer has been replaced. - Added `void TCling::ReportDiagnosticsToErrorHandler(bool enable)` member function. This PR closes JIRA issue [ROOT-7587](https://sft.its.cern.ch/jira/browse/ROOT-7587). Link to sibling PR in `roottest` repository: https://github.com/root-project/roottest/pull/761.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8737
https://github.com/root-project/root/pull/8738:226,availability,avail,available,226,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:487,deployability,updat,updated,487,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:226,reliability,availab,available,226,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:226,safety,avail,available,226,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:457,safety,test,tested,457,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:487,safety,updat,updated,487,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:226,security,availab,available,226,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:487,security,updat,updated,487,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:457,testability,test,tested,457,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:8,usability,document,documentation,8,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:25,usability,Visual,VisualizeError,25,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:49,usability,command,command,49,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:108,usability,document,documentation,108,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:129,usability,Visual,VisualizeError,129,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:144,usability,command,command,144,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/pull/8738:202,usability,command,command,202,improve documentation of VisualizeError plotting command; . # This Pull request:. ## Changes or fixes:. The documentation of the VisualizeError command in RooAbsPdf::plotOn and RooAbsReal::plotOn. This command has two methods available which are explained in the code comments in roofit tutorial 610 but not in the class reference online. I copied a brief description from the tutorial. No changes are made to the function of the code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8738
https://github.com/root-project/root/issues/8739:420,availability,Error,Error,420,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:1064,availability,slo,slow,1064,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:633,deployability,log,logic,633,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:49,modifiability,extens,extension,49,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:683,modifiability,extens,extension,683,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:420,performance,Error,Error,420,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:802,performance,network,network,802,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:465,reliability,doe,does,465,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:1064,reliability,slo,slow,1064,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:420,safety,Error,Error,420,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:633,safety,log,logic,633,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:633,security,log,logic,633,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:802,security,network,network,802,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:633,testability,log,logic,633,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:911,testability,context,context,911,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:940,testability,context,context,940,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/issues/8739:420,usability,Error,Error,420,"[DF] Cannot read files that don't have a `.root` extension with IMT on; Reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. #include <iostream>. int main() {. ROOT::RDataFrame(10). .Define(""x"", [] { return 42; }). .Snapshot<int>(""t"", ""thefile"", {""x""});. std::cout << ""done writing\n"";. ROOT::EnableImplicitMT();. ROOT::RDataFrame(""t"", ""thefile"").Max<int>(""x"").GetValue();. return 0;. }. ```. prints. ```. done writing. Error in <TFile::TFile>: file /tmp/thefile/t does not exist. Warning in <TTreeReader::SetEntryBase()>: There was an issue opening the last file associated to the TChain being processed. ```. This is likely due to logic in `TChain::AddFile` that expects a `.root` extension to be present in order to distinguish `/path/to/file.root/treename` from just `/path/to/file.root` (over the network or via xrootd it's difficult/expensive to figure out which case we are in otherwise). ### Additional context. <!--. Add any other context about the problem here. -->. First reported at https://root-forum.cern.ch/t/getting-value-from-tbranch-is-extremely-slow/45950",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8739
https://github.com/root-project/root/pull/8740:480,integrability,interfac,interface,480,"[TREE] Utility to enter a range of entries in TEntryList; Add a utility function to call `TEntryList::Enter` with entries in a certain range, instead of having to do the loop manually. Especially useful in PyROOT to avoid doing the same in a Python loop. ### Initial idea. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.GetN(). 0. >>> ROOT.ROOT.Detail.EnterRange(e, 0, 10). >>> e.GetN(). 10. ```. Not sure about the namespace and the naming, can be discussed. ### Final interface. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.EnterRange(0,10). >>> e.GetN(). 10. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8740
https://github.com/root-project/root/pull/8740:480,interoperability,interfac,interface,480,"[TREE] Utility to enter a range of entries in TEntryList; Add a utility function to call `TEntryList::Enter` with entries in a certain range, instead of having to do the loop manually. Especially useful in PyROOT to avoid doing the same in a Python loop. ### Initial idea. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.GetN(). 0. >>> ROOT.ROOT.Detail.EnterRange(e, 0, 10). >>> e.GetN(). 10. ```. Not sure about the namespace and the naming, can be discussed. ### Final interface. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.EnterRange(0,10). >>> e.GetN(). 10. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8740
https://github.com/root-project/root/pull/8740:480,modifiability,interfac,interface,480,"[TREE] Utility to enter a range of entries in TEntryList; Add a utility function to call `TEntryList::Enter` with entries in a certain range, instead of having to do the loop manually. Especially useful in PyROOT to avoid doing the same in a Python loop. ### Initial idea. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.GetN(). 0. >>> ROOT.ROOT.Detail.EnterRange(e, 0, 10). >>> e.GetN(). 10. ```. Not sure about the namespace and the naming, can be discussed. ### Final interface. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.EnterRange(0,10). >>> e.GetN(). 10. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8740
https://github.com/root-project/root/pull/8740:216,safety,avoid,avoid,216,"[TREE] Utility to enter a range of entries in TEntryList; Add a utility function to call `TEntryList::Enter` with entries in a certain range, instead of having to do the loop manually. Especially useful in PyROOT to avoid doing the same in a Python loop. ### Initial idea. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.GetN(). 0. >>> ROOT.ROOT.Detail.EnterRange(e, 0, 10). >>> e.GetN(). 10. ```. Not sure about the namespace and the naming, can be discussed. ### Final interface. ```py. >>> import ROOT. >>> e = ROOT.TEntryList(). >>> e.EnterRange(0,10). >>> e.GetN(). 10. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8740
https://github.com/root-project/root/pull/8741:47,deployability,build,building,47,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:329,deployability,build,building,329,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:447,integrability,event,event,447,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:244,interoperability,specif,specified,244,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:414,modifiability,extens,extension,414,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:434,performance,multi-thread,multi-thread,434,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:124,reliability,doe,does,124,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:531,safety,test,test,531,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/pull/8741:531,testability,test,test,531,"[TTreeProcessorMT] Use unambiguous syntax when building chains ; chain->Add(""filename/treename"") is ambiguous when filename does not. end in `.root`: in that case `TChain` interprets its argument. as the full path to the file, with no treename specified. We now instead use the unambiguous syntax ""filename?query#treename"". when building chains in TTreeProcessorMT. This fixes #8739 (reading files with no `.root` extension in RDF's. multi-thread event loops). Companion PR https://github.com/root-project/roottest/pull/758 adds a test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8741
https://github.com/root-project/root/issues/8742:7,deployability,build,build,7,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:243,deployability,build,build,243,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:451,deployability,build,build,451,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:514,deployability,build,build,514,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:22,usability,document,documentation,22,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:162,usability,document,documentation,162,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:258,usability,document,documentation,258,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:466,usability,document,documentation,466,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:533,usability,document,documentation,533,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8742:651,usability,user,user-images,651,"How to build just the documentation; After some questions on doxygen (e.g. https://github.com/doxygen/doxygen/issues/8693 by @couet I got a bit interested in the documentation of ROOT so I looked at it and it looks nice. I thought maybe can I build just the documentation myself. . So:. - I cloned https://github.com/root-project/root.git. - cd root. - mkdir build_normal. - cd build_normal. - cmake .. - ?? Unfortunately I could not find a target to build just the documentation. - What is the right procedure to build **just** the documentation? I already saw something ""strange"" in https://root.cern/doc/master/loopdir11_8C.html:. ![image](https://user-images.githubusercontent.com/5223533/127141628-4cfa4b3d-3b8a-4c8a-9f5b-e41856686bea.png). - the `C\V` part and the missing first 2 characters and the not so nice `\` (didn't find quickly its source). - the text:. > Example of script to loop on all the objects of a ROOT file directory and print on Postscript all TH1 derived objects. . would probably be better:. > Example script to loop over all the objects of a ROOT file directory and print in Postscript all the TH1 derived objects.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8742
https://github.com/root-project/root/issues/8743:24,deployability,updat,updated,24,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:95,deployability,build,building,95,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:181,deployability,updat,updated,181,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:289,deployability,instal,install,289,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:11,interoperability,standard,standard,11,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:24,safety,updat,updated,24,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:181,safety,updat,updated,181,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:24,security,updat,updated,24,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:181,security,updat,updated,181,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:35,usability,document,documentation,35,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:81,usability,indicat,indicated,81,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8743:157,usability,document,documentation,157,"ROOT 7 c++ standard not updated on documentation; The `CMAKE_CXX_STANDARD` value indicated for building ROOT7 is `c++14`, however it now requires `c++17` so documentation should be updated, namely (and maybe not limited to):. - https://root.cern/for_developers/root7/. - https://root.cern/install/build_from_source/#enabling-experimental-features-aka-root7",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8743
https://github.com/root-project/root/issues/8744:25,availability,failur,failure,25,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:98,availability,failur,failure,98,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:25,deployability,fail,failure,25,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:98,deployability,fail,failure,98,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:25,performance,failur,failure,25,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:98,performance,failur,failure,98,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:25,reliability,fail,failure,25,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:98,reliability,fail,failure,98,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:59,safety,test,test,59,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8744:59,testability,test,test,59,"root/treeformula/clones: failure of runNestedClones.C; Old test said:. > one of the reason of the failure is the fact that the first	. > clones array is empty! https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/runNestedClones.C and https://github.com/root-project/roottest/blob/v6-24-02/root/treeformula/clones/nestedclones.root are reproducing this (before it was removed, because roottest isn't a place to keep reproducers).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8744
https://github.com/root-project/root/issues/8745:2207,availability,Operat,Operating,2207," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:2282,availability,down,download,2282," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:693,deployability,modul,module,693,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1158,deployability,modul,module,1158,"s for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT sour",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1603,deployability,modul,module,1603," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:2195,deployability,version,version,2195," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:2264,deployability,instal,install,2264," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:2195,integrability,version,version,2195," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:693,modifiability,modul,module,693,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1158,modifiability,modul,module,1158,"s for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT sour",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1603,modifiability,modul,module,1603," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:2195,modifiability,version,version,2195," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:232,reliability,doe,doesn,232,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:0,safety,Avoid,Avoid,0,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:107,safety,avoid,avoid,107,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:693,safety,modul,module,693,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1158,safety,modul,module,1158,"s for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT sour",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1603,safety,modul,module,1603," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1931,safety,avoid,avoid,1931," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:2081,safety,avoid,avoid,2081," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:528,security,access,access,528,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:552,security,session,session,552,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:303,testability,simpl,simple,303,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:629,testability,Trace,Traceback,629,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1094,testability,Trace,Traceback,1094,"ible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1539,testability,Trace,Traceback,1539," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:303,usability,simpl,simple,303,"Avoid needing to type `ROOT.ROOT` twice in PyROOT; ### Describe the bug. In PyROOT it has been possible to avoid the double `ROOT.ROOT` for some classes/functions for a while. ```py. import ROOT. df = ROOT.RDataFrame. ```. But that doesn't happen for every new class/function defined in C++ . This is a simple reproducer: create some entities in a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:1985,usability,behavi,behavior,1985," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/issues/8745:2003,usability,clear,clear,2003," a namespace:. ```py. import ROOT. ROOT.gInterpreter.Declare(. """""". namespace ROOT{. namespace Detail{. struct MyStruct{};. void dostuff(){}. int myint;. }}. """""". ). ```. Then try to access them in a Python session. ```py. $ python -i namespace_function.py. >>> ROOT.Detail.MyStruct. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'MyStruct'. Full details:. type object 'Detail' has no attribute 'MyStruct'. 'Detail::MyStruct' is not a known C++ class. 'MyStruct' is not a known C++ template. 'MyStruct' is not a known C++ enum. >>> ROOT.ROOT.Detail.MyStruct. <class cppyy.gbl.ROOT.Detail.MyStruct at 0x55e51fe1dd60>. >>> ROOT.Detail.dostuff. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'dostuff'. Full details:. type object 'Detail' has no attribute 'dostuff'. 'Detail::dostuff' is not a known C++ class. 'dostuff' is not a known C++ template. 'dostuff' is not a known C++ enum. >>> ROOT.ROOT.Detail.dostuff. <cppyy.CPPOverload object at 0x7f522b684eb0>. >>> ROOT.Detail.myint. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: <namespace cppyy.gbl.Detail at 0x55e51fdc7f50> has no attribute 'myint'. Full details:. type object 'Detail' has no attribute 'myint'. 'Detail::myint' is not a known C++ class. 'myint' is not a known C++ template. 'myint' is not a known C++ enum. >>> ROOT.ROOT.Detail.myint. 0. ```. It's unclear how to avoid the double `ROOT.ROOT` in general. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Be able to avoid typing the name twice, at least for classes/functions defined in ROOT source code. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8745
https://github.com/root-project/root/pull/8746:39,deployability,Patch,Patch,39,Fix in Cocoa. XSGui crashed on Mac M1; Patch proposed by Timur.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8746
https://github.com/root-project/root/pull/8746:39,safety,Patch,Patch,39,Fix in Cocoa. XSGui crashed on Mac M1; Patch proposed by Timur.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8746
https://github.com/root-project/root/pull/8746:39,security,Patch,Patch,39,Fix in Cocoa. XSGui crashed on Mac M1; Patch proposed by Timur.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8746
https://github.com/root-project/root/pull/8747:502,availability,error,error,502,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:508,availability,state,state,508,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:666,availability,state,state,666,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:658,energy efficiency,current,current,658,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:154,integrability,event,event,154,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:286,integrability,event,event,286,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:508,integrability,state,state,508,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:581,integrability,event,event,581,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:666,integrability,state,state,666,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:738,integrability,event,event,738,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:194,interoperability,compatib,compatible,194,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:502,performance,error,error,502,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:502,safety,error,error,502,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:563,safety,compl,completion,563,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:563,security,compl,completion,563,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:465,usability,indicat,indicate,465,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:502,usability,error,error,502,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:544,usability,indicat,indicates,544,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8747:604,usability,clear,clear,604,"[DF][treereader] Use kEntryBeyondEnd, not kEntryNotFound if appropriate ; kEntryBeyondEnd is what is expected to be set at the end of a `while(r.Next())` event loop. This change is not backward-compatible if anyone relied on `kEntryNotFound` being set even at the end of a well-behaved event loop. On the other hand, the second usage example in TTreeReader's docs (https://root.cern/doc/master/classTTreeReader.html) as well as the names of the enum values seem to indicate that `kEntryNotFound` is an error state and `kEntryBeyondEnd` is what indicates a normal completion of the event loop. P.S. to be clear, the problem I'm trying to solve is that in the current state it's hard (maybe impossible) to distinguish between a TTreeReader event loop that ended well and one that ended because an entry that was supposed to be there was not found",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8747
https://github.com/root-project/root/pull/8748:150,availability,error,error,150,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/pull/8748:93,integrability,event,event,93,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/pull/8748:150,performance,error,error,150,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/pull/8748:189,performance,multi-thread,multi-thread,189,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/pull/8748:208,performance,perform,perform,208,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/pull/8748:150,safety,error,error,150,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/pull/8748:150,usability,error,error,150,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/pull/8748:208,usability,perform,perform,208,"[DF] Throw from MT loops if TTreeReader had a problem ; Before this commit, in single-thread event loops RDF was throwing. in case TTreeReader had an error flag at the end of the loop. Now multi-thread loops perform the same check at the end of each task.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8748
https://github.com/root-project/root/issues/8750:1293,availability,cluster,clustersinfiles,1293,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1587,availability,error,error,1587,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1865,availability,Operat,Operating,1865,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1940,availability,down,download,1940,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:180,deployability,log,logic,180,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:866,deployability,modul,module,866,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1293,deployability,cluster,clustersinfiles,1293,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1853,deployability,version,version,1853,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1922,deployability,instal,install,1922,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:172,energy efficiency,current,current,172,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1607,energy efficiency,current,current,1607,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:20,integrability,sub,subtrees,20,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:526,integrability,sub,sub,526,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1615,integrability,sub,sub,1615,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1853,integrability,version,version,1853,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:53,interoperability,distribut,distributed,53,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:213,interoperability,distribut,distributed,213,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:351,interoperability,bind,bindings,351,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:615,interoperability,Distribut,Distributed,615,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:952,interoperability,Prox,Proxy,952,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1775,interoperability,Distribut,Distributed,1775,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:351,modifiability,bind,bindings,351,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:866,modifiability,modul,module,866,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1853,modifiability,version,version,1853,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1587,performance,error,error,1587,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:457,reliability,doe,doesn,457,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:180,safety,log,logic,180,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:866,safety,modul,module,866,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1351,safety,input,inputfiles,1351,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1587,safety,error,error,1587,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1651,safety,input,input,1651,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:180,security,log,logic,180,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:180,testability,log,logic,180,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:440,testability,simpl,simple,440,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:802,testability,Trace,Traceback,802,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:0,usability,Support,Support,0,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:102,usability,clear,clear,102,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:150,usability,behavi,behavior,150,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:440,usability,simpl,simple,440,"Support chains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1351,usability,input,inputfiles,1351,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1587,usability,error,error,1587,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1651,usability,input,input,1651,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1690,usability,behavi,behavior,1690,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1708,usability,clear,clear,1708,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/issues/8750:1805,usability,support,support,1805,"hains with subtrees with different names in distributed RDF; . ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. The current logic to construct a TChain in a distributed task to pass to the RDF constructor is at. https://github.com/root-project/root/blob/b494a9b145246b66868fa38e2fd3e1f37fa73c47/bindings/experimental/distrdf/python/DistRDF/Backends/Base.py#L166-L168. But this is too simple, since it doesn't account for the common use case of a TChain with no name and sub trees with different names:. ```py. >>> import ROOT. >>> RDF = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. >>> c = ROOT.TChain(). >>> c.Add(""10entries.root/entries""). 1. >>> c.Add(""other10entries.root/otherentries""). 1. >>> df = RDF(c). >>> df.Count().GetValue(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Proxy.py"", line 127, in GetValue. headnode.backend.execute(generator). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Backends/Base.py"", line 135, in execute. ranges = headnode.build_ranges(). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/HeadNode.py"", line 307, in build_ranges. clustersinfiles = Ranges.get_clusters(self.treename, self.inputfiles). File ""/home/vpadulan/Programs/rootproject/rootbuild/devdebugtest/lib/DistRDF/Ranges.py"", line 220, in get_clusters. entries = t.GetEntriesFast(). AttributeError: 'TObject' object has no attribute 'GetEntriesFast'. ```. The error is due to the current sub tree not being found (since the input chain has no name). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Distributed RDataFrame should support this use case. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master built on Fedora32.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8750
https://github.com/root-project/root/pull/8751:86,integrability,interfac,interface,86,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:168,integrability,interfac,interface,168,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:86,interoperability,interfac,interface,86,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:168,interoperability,interfac,interface,168,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:86,modifiability,interfac,interface,86,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:168,modifiability,interfac,interface,168,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:317,safety,compl,complete,317,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:317,security,compl,complete,317,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:110,usability,support,support,110,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8751:127,usability,user,user,127,"[RF][PyROOT] Pythonize RooArgSet constructor to accept a Python `set`; For the pyROOT interface, we wanted to support that the user can pass a. Python set whenever the interface expects a RooArgSet. This is achieved by pythonizing the `__init__` function of the RooArgSet Python mirror class. This PR also includes a complete migration of all RooFit tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8751
https://github.com/root-project/root/pull/8752:98,deployability,automat,automatically,98,Deflate axis at painting time; To Fix : https://github.com/root-project/root/issues/8598. Calling automatically deflate at drawing time makes sense as nobody wants to see extra blank labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8752
https://github.com/root-project/root/pull/8752:123,energy efficiency,draw,drawing,123,Deflate axis at painting time; To Fix : https://github.com/root-project/root/issues/8598. Calling automatically deflate at drawing time makes sense as nobody wants to see extra blank labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8752
https://github.com/root-project/root/pull/8752:25,performance,time,time,25,Deflate axis at painting time; To Fix : https://github.com/root-project/root/issues/8598. Calling automatically deflate at drawing time makes sense as nobody wants to see extra blank labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8752
https://github.com/root-project/root/pull/8752:131,performance,time,time,131,Deflate axis at painting time; To Fix : https://github.com/root-project/root/issues/8598. Calling automatically deflate at drawing time makes sense as nobody wants to see extra blank labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8752
https://github.com/root-project/root/pull/8752:98,testability,automat,automatically,98,Deflate axis at painting time; To Fix : https://github.com/root-project/root/issues/8598. Calling automatically deflate at drawing time makes sense as nobody wants to see extra blank labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8752
https://github.com/root-project/root/pull/8753:14,safety,test,tests,14,[DF] Add more tests to dataframe_snapshot.cxx; Some Snapshot output files were not being checked.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8753
https://github.com/root-project/root/pull/8753:14,testability,test,tests,14,[DF] Add more tests to dataframe_snapshot.cxx; Some Snapshot output files were not being checked.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8753
https://github.com/root-project/root/pull/8754:75,deployability,contain,containing,75,"[DF] Use R_rdf instead of __rdf as the ""secret RDF namespace""; Identifiers containing a double underscore are reserved in C++. We have to do this now because we kind of expose `__rdf` to RDataSource. implementations via the (unreleased) `#var` aliasing mechanism.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8754
https://github.com/root-project/root/pull/8754:63,security,Ident,Identifiers,63,"[DF] Use R_rdf instead of __rdf as the ""secret RDF namespace""; Identifiers containing a double underscore are reserved in C++. We have to do this now because we kind of expose `__rdf` to RDataSource. implementations via the (unreleased) `#var` aliasing mechanism.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8754
https://github.com/root-project/root/pull/8754:169,security,expos,expose,169,"[DF] Use R_rdf instead of __rdf as the ""secret RDF namespace""; Identifiers containing a double underscore are reserved in C++. We have to do this now because we kind of expose `__rdf` to RDataSource. implementations via the (unreleased) `#var` aliasing mechanism.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8754
https://github.com/root-project/root/pull/8755:33,deployability,log,logic,33,"[DF] Remove wrong RepresentGraph logic; If a `RResultPtr<RInterface<RLoopManager, void>>` is passed to. `SaveGraph`, we used to switch to the graph-wide representation. That's not intended, and it's most likely an oversight.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8755
https://github.com/root-project/root/pull/8755:33,safety,log,logic,33,"[DF] Remove wrong RepresentGraph logic; If a `RResultPtr<RInterface<RLoopManager, void>>` is passed to. `SaveGraph`, we used to switch to the graph-wide representation. That's not intended, and it's most likely an oversight.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8755
https://github.com/root-project/root/pull/8755:33,security,log,logic,33,"[DF] Remove wrong RepresentGraph logic; If a `RResultPtr<RInterface<RLoopManager, void>>` is passed to. `SaveGraph`, we used to switch to the graph-wide representation. That's not intended, and it's most likely an oversight.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8755
https://github.com/root-project/root/pull/8755:33,testability,log,logic,33,"[DF] Remove wrong RepresentGraph logic; If a `RResultPtr<RInterface<RLoopManager, void>>` is passed to. `SaveGraph`, we used to switch to the graph-wide representation. That's not intended, and it's most likely an oversight.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8755
https://github.com/root-project/root/issues/8758:1235,availability,redund,redundantly,1235,"ot.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFact",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1235,deployability,redundan,redundantly,1235,"ot.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFact",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1542,energy efficiency,Model,ModelInspector,1542,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:5,integrability,Translat,Translate,5,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:55,integrability,translat,translations,55,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:191,integrability,translat,translate,191,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:484,integrability,translat,translated,484,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:548,integrability,translat,translation,548,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:999,integrability,translat,translated,999," Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1084,integrability,sub,submit,1084,"ials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1095,integrability,translat,translation,1095," were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDem",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1179,integrability,translat,translation,1179,"is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1410,integrability,translat,translated,1410,"/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] St",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:5,interoperability,Translat,Translate,5,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:55,interoperability,translat,translations,55,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:191,interoperability,translat,translate,191,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:484,interoperability,translat,translated,484,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:548,interoperability,translat,translation,548,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:581,interoperability,Standard,StandardHypoTestInvDemo,581,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:798,interoperability,format,formatted,798,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:999,interoperability,translat,translated,999," Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1095,interoperability,translat,translation,1095," were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDem",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1179,interoperability,translat,translation,1179,"is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1410,interoperability,translat,translated,1410,"/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] St",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2078,interoperability,Standard,StandardBayesianMCMCDemo,2078,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2112,interoperability,Standard,StandardBayesianNumericalDemo,2112,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2151,interoperability,Standard,StandardFeldmanCousinsDemo,2151,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2187,interoperability,Standard,StandardFrequentistDiscovery,2187,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2225,interoperability,Standard,StandardHistFactoryPlotsWithCategories,2225,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2273,interoperability,Standard,StandardHypoTestDemo,2273,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2303,interoperability,Standard,StandardHypoTestInvDemo,2303,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2336,interoperability,Standard,StandardProfileInspectorDemo,2336,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2374,interoperability,Standard,StandardProfileLikelihoodDemo,2374,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2413,interoperability,Standard,StandardTestStatDistributionDemo,2413,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1112,performance,time,time,1112,"ed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] St",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1259,performance,time,time,1259,"roup__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategori",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1235,reliability,redundan,redundantly,1235,"ot.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFact",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:107,safety,compl,completed,107,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1034,safety,review,review,1034,"Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1235,safety,redund,redundantly,1235,"ot.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFact",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1293,safety,review,reviewer,1293,"ROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2455,safety,Test,TestNonCentral,2455,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:107,security,compl,completed,107,"[RF] Translate RooStats tutorials to Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1542,security,Model,ModelInspector,1542,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1034,testability,review,review,1034,"Python; After the translations of the RooFit tutorials to PyROOT were completed (see https://github.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1293,testability,review,reviewer,1293,"ROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:2455,testability,Test,TestNonCentral,2455,"with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] StandardFeldmanCousinsDemo.C. - [ ] StandardFrequentistDiscovery.C. - [ ] StandardHistFactoryPlotsWithCategories.C. - [ ] StandardHypoTestDemo.C. - [ ] StandardHypoTestInvDemo.C. - [x] StandardProfileInspectorDemo.C. - [x] StandardProfileLikelihoodDemo.C. - [ ] StandardTestStatDistributionDemo.C. - [x] TestNonCentral.C. - [x] TwoSidedFrequentistUpperLimitWithBands.C. - [x] Zbi_Zgamma.C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1131,usability,feedback,feedback,1131,"b.com/root-project/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumeric",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8758:1150,usability,help,help,1150,"t/root/issues/8523), a next step is to translate also the [RooStats tutorials](https://root.cern/doc/master/group__tutorial__roostats.html) to pyROOT. The RooStats tutorials can be found in the [tutorials/roostats](https://github.com/root-project/root/tree/master/tutorials/roostats) directory. Right now, none of the tutorials are translated to Python yet. For a start, one could start with the translation of the very popular [StandardHypoTestInvDemo](https://root.cern.ch/doc/master/StandardHypoTestInvDemo_8C.html) tutorial, which explains the widely used AsymptoticCalculator and HypoTestInverter classes. Any new Python tutorials should be formatted with [black](https://github.com/psf/black):. ```. black --line-length=120 <tutorial file>.py. ```. *Please note:* if you want to work on this issue, please don't open a PR with all tutorials translated at once! This makes the review process unsustainable. For example, if you submit one translation at a time, you will get feedback that will help you improving your next translation, so the same comments don't have to be made redundantly. This saves time for both the contributor and reviewer :slightly_smiling_face: . Here is the list of all the RooStats tutorials and whether they have already been translated:. - [x] FourBinInstructional.C. - [x] HybridInstructional.C. - [x] HybridStandardForm.C. - [x] IntervalExamples.C. - [ ] ModelInspector.C. - [x] MultivariateGaussianTest.C. - [ ] OneSidedFrequentistUpperLimitWithBands.C. - [x] rs101_limitexample.C. - [ ] rs102_hypotestwithshapes.C. - [x] rs301_splot.C. - [ ] rs302_JeffreysPriorDemo.C. - [x] rs401c_FeldmanCousins.C. - [ ] rs401d_FeldmanCousins.C. - [x] rs601_HLFactoryexample.C. - [ ] rs602_HLFactoryCombinationexample.C. - [ ] rs603_HLFactoryElaborateExample.C. - [x] rs701_BayesianCalculator.C. - [x] rs_bernsteinCorrection.C. - [ ] rs_numberCountingCombination.C. - [x] rs_numbercountingutils.C. - [ ] StandardBayesianMCMCDemo.C. - [ ] StandardBayesianNumericalDemo.C. - [ ] S",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8758
https://github.com/root-project/root/issues/8759:527,deployability,depend,depend,527,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:589,deployability,depend,dependency,589,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:821,deployability,depend,dependency,821,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:1015,deployability,build,building,1015,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:391,energy efficiency,current,current,391,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:527,integrability,depend,depend,527,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:579,integrability,interfac,interface,579,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:589,integrability,depend,dependency,589,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:759,integrability,INTERFAC,INTERFACE,759,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:821,integrability,depend,dependency,821,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:579,interoperability,interfac,interface,579,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:759,interoperability,INTERFAC,INTERFACE,759,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:34,modifiability,pac,package,34,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:527,modifiability,depend,depend,527,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:579,modifiability,interfac,interface,579,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:589,modifiability,depend,dependency,589,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:759,modifiability,INTERFAC,INTERFACE,759,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:821,modifiability,depend,dependency,821,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:992,performance,time,time,992,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:527,safety,depend,depend,527,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:589,safety,depend,dependency,589,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:821,safety,depend,dependency,821,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:527,testability,depend,depend,527,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:589,testability,depend,dependency,589,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/issues/8759:821,testability,depend,dependency,821,"[RF] Create separate RooFitLegacy package; So far, deprecated RooFit code has been moved into [roofit/roofitcore/inc/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/inc/RooFitLegacy) and [roofit/roofitcore/src/RooFitLegacy](https://github.com/root-project/root/tree/master/roofit/roofitcore/src/RooFitLegacy). But to really separate the legacy code from the current RooFit, we want to introduce a new library called RooFitLegacy in a new `roofit/roofitlegacy` directory. This new library would depend on RooFitCore. RooFitCore could only have an interface dependency on RooFitLegacy to make sure that the code using RooFitLegacy classes still links. In CMake, this would look like:. ```cmake. target_link_libraries(RooFitCore INTERFACE RooFitLegacy). ```. Or maybe we can even leave this dependency out, leading to a more aggressive deprecation by making old code not link anymore. Once the RooFitLegacy library becomes large enough to visibly impact compile time, we can also make building the legacy library optional by introducing a new `roofitlegacy` cmake flag.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8759
https://github.com/root-project/root/pull/8760:93,deployability,automat,automatically,93,Deflate axis; fix https://github.com/root-project/root/issues/8598. It is reasonable to call automatically LabelsDeflate at drawing time when plotting histogram with labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8760
https://github.com/root-project/root/pull/8760:124,energy efficiency,draw,drawing,124,Deflate axis; fix https://github.com/root-project/root/issues/8598. It is reasonable to call automatically LabelsDeflate at drawing time when plotting histogram with labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8760
https://github.com/root-project/root/pull/8760:132,performance,time,time,132,Deflate axis; fix https://github.com/root-project/root/issues/8598. It is reasonable to call automatically LabelsDeflate at drawing time when plotting histogram with labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8760
https://github.com/root-project/root/pull/8760:93,testability,automat,automatically,93,Deflate axis; fix https://github.com/root-project/root/issues/8598. It is reasonable to call automatically LabelsDeflate at drawing time when plotting histogram with labels.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8760
https://github.com/root-project/root/pull/8761:333,integrability,pub,public,333,"[DF] Provide a definition of ColumnNames_t in ROOT::RDF; ColumnNames_t is very user-visible, it's not an implementation. detail, so let's move it from ROOT::Detail::RDF to ROOT::RDF. These changes are also useful for documentation purposes: we now. have one definition that users can look up via Doxygen, and (fewer). others in less public namespaces or at class scope.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8761
https://github.com/root-project/root/pull/8761:79,usability,user,user-visible,79,"[DF] Provide a definition of ColumnNames_t in ROOT::RDF; ColumnNames_t is very user-visible, it's not an implementation. detail, so let's move it from ROOT::Detail::RDF to ROOT::RDF. These changes are also useful for documentation purposes: we now. have one definition that users can look up via Doxygen, and (fewer). others in less public namespaces or at class scope.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8761
https://github.com/root-project/root/pull/8761:217,usability,document,documentation,217,"[DF] Provide a definition of ColumnNames_t in ROOT::RDF; ColumnNames_t is very user-visible, it's not an implementation. detail, so let's move it from ROOT::Detail::RDF to ROOT::RDF. These changes are also useful for documentation purposes: we now. have one definition that users can look up via Doxygen, and (fewer). others in less public namespaces or at class scope.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8761
https://github.com/root-project/root/pull/8761:274,usability,user,users,274,"[DF] Provide a definition of ColumnNames_t in ROOT::RDF; ColumnNames_t is very user-visible, it's not an implementation. detail, so let's move it from ROOT::Detail::RDF to ROOT::RDF. These changes are also useful for documentation purposes: we now. have one definition that users can look up via Doxygen, and (fewer). others in less public namespaces or at class scope.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8761
https://github.com/root-project/root/issues/8762:339,availability,error,error,339,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:786,availability,error,error,786,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:882,availability,error,error,882,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:29,deployability,continu,continuation,29,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:140,deployability,continu,continuation,140,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:199,deployability,fail,fail,199,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:824,modifiability,paramet,parameter,824,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:339,performance,error,error,339,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:786,performance,error,error,786,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:882,performance,error,error,882,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:199,reliability,fail,fail,199,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:339,safety,error,error,339,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:631,safety,input,input,631,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:786,safety,error,error,786,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:882,safety,error,error,882,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:1019,safety,input,input,1019,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:16,usability,support,support,16,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:131,usability,support,supports,131,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:289,usability,cancel,cancel,289,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:339,usability,error,error,339,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:436,usability,close,closely,436,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:631,usability,input,input,631,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:741,usability,cancel,cancel,741,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:786,usability,error,error,786,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:882,usability,error,error,882,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:941,usability,behavi,behavior,941,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:1019,usability,input,input,1019,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/issues/8762:1103,usability,cancel,cancel,1103,"[rint] Properly support line continuation after backslash `\` ; - [X] Checked for duplicates. ### Describe the bug. Although cling supports continuation for lines ending with `,` or `\`, it seems to fail in the ROOT prompt, i.e. . ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". ROOT_prompt_0:1:26: error: expected ';' at end of declaration. const char *s = ""string "" \. ^. ;. ```. This issue is closely related to JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The problem seems to be in `TRint.cxx`, which unconditionally inserts a `#line` PP directive before each input line. This is especially visible here:. ```. root [0] #define def(arg) printf(""%s\n"", \. root (cont'ed, cancel with .@) [1]arg);. ROOT_prompt_0:2:2: error: '#' is not followed by a macro parameter. #line 1 ""ROOT_prompt_1"". ^. ROOT_prompt_0:3:4: error: extraneous ')' before ';'. arg);. ```. ### Expected behavior. As discussed, `#line` directives should not be inserted if the last input line ends with `\`. ```. root [0] const char *s = ""string "" \. root (cont'ed, cancel with .@) [1]""literal"". (const char *) ""string literal"". ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8762
https://github.com/root-project/root/pull/8763:23,safety,test,test,23,[DF] Re-enable RRootDS test; .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8763
https://github.com/root-project/root/pull/8763:23,testability,test,test,23,[DF] Re-enable RRootDS test; .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8763
https://github.com/root-project/root/pull/8764:72,availability,consist,consistently,72,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:904,availability,consist,consistent,904,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2988,deployability,contain,contains,2988," more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base cl",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:328,energy efficiency,model,models,328,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:470,energy efficiency,reduc,reducing,470,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:499,energy efficiency,model,models,499,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1174,energy efficiency,model,model,1174,"asses as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1206,integrability,pub,public,1206,"ey are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:264,performance,I/O,I/O,264,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:553,performance,I/O,I/O,553,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:627,performance,I/O,I/O,627,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:944,performance,cach,cache,944,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1014,performance,cach,cache,1014,"RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1054,performance,I/O,I/O,1054,"ent; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2165,performance,memor,memory,2165,"k the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2600,performance,time,times,2600,"ndl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:3375,performance,cach,caches,3375,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:3897,performance,memor,memory,3897,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:3959,performance,cach,caches,3959,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:4010,performance,cach,caches,4010,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:3555,reliability,doe,doesnt,3555,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:3607,reliability,diagno,diagnosis,3607,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:649,safety,except,exceptions,649,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:328,security,model,models,328,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:499,security,model,models,499,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1174,security,model,model,1174,"asses as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1089,testability,simpl,simple,1089,"he `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and read",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1998,testability,context,context,1998,"or for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `st",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2124,testability,understand,understand,2124,"ooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2413,testability,understand,understand,2413,"writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:3607,testability,diagno,diagnosis,3607,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:72,usability,consist,consistently,72,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:232,usability,effectiv,effectively,232,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:904,usability,consist,consistent,904,"[RF] Always mark RooAbsCache and child classes as transient; The commit consistently marks the `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:1089,usability,simpl,simple,1089,"he `RooAbsCache` class and the derived. `RooCacheManager` and `RooObjCacheManager` classes as transient. whereever they are used in RooFit, effectively excluding them from I/O. This change was made primarily to fix a bug happening when models are. read back from a ROOT file (the pointes in `RooAbsArg::_cacheList` were. not correct anymore), but it also has the nice effect of reducing the. size of RooFit models. The classes were almost de-facto removed from I/O already, because. almost all of their data members were excluded from I/O anyway. The only. exceptions are the following data members:. * `RooObjCacheManager::_clearOnRedirect`. * `RooObjCacheManager::_allowOptimize`. * `RooAbsCache::_owner`. All of these values are set in the respective constructors and are never. changed. To make these values consistent even if a class that uses a. cache is read back from a ROOT file, the correct constructor for the. cache is now also called in the default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and read",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2042,usability,workflow,workflow,2042,"default I/O constructors of the classes. A simple reproducer to see problem with `RooAbsArg::_cacheList` after reading back the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2165,usability,memor,memory,2165,"k the model:. ```C++. #define private public. #include ""RooWorkspace.h"". #include ""RooGaussian.h"". #include ""TFile.h"". void reproducer() {. {. RooWorkspace w(""w"",""w"");. w.factory(""RooGaussian::gaus(x[0,-10,10],mean[0,-10,10],sigma[1,0.1,10.0])"");. w.writeToFile(""file.root"");. auto gaus = w.pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:2542,usability,minim,minimal,2542,") << std::endl;. std::cout << gaus->numCaches() << std::endl;. gaus->IsA()->GetListOfDataMembers()->Print();. }. {. TFile f1(""file.root"");. auto w =f1.Get<RooWorkspace>(""w"");. auto gaus = w->pdf(""gaus"");. std::cout << &gaus->_normMgr << std::endl;. std::cout << gaus->getCache(0) << std::endl;. std::cout << gaus->numCaches() << std::endl;. delete w;. }. }. ```. Here the nice report from @will-cern (thanks!!) that motivated this PR to give some more context:. > have been recently working on a workflow that involved repeatedly writing and reading workspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_ca",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:3897,usability,memor,memory,3897,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8764:4046,usability,interact,interacting,4046,"kspaces, and I wanted to understand why this was leaking a lot of memory. This is in 6.22/08 but I think the problems persist in master. Thankfully the biggest leak is easy to fix and I'll make a PR for that soon (workspace not cleaning up all its RooLinkedLists). But the next biggest one has taken me a while to understand.... <br>Valgrind reported lots of leaking of RooObjCacheManager instances. I believe a way to evidence this is with a minimal reproducer (see above). <br>If you track how many times a RooObjCacheManager is constructed with these lines, the first line constructs one of them (the `_normMgr` of the RooAbsPdf class). But when the file is read back in on the second line, I see two RooObjCacheManagers get constructed. The first one comes from the constructor of the RooAbsPdf (via the gaussian), but the second comes from streaming of the RooAbsArg base class which contains a `std::deque<RooAbsCache*> _cacheList`. . <br>So what I'm seeing is that in the first line where the pdf is first created, the `_normMgr` (which is declared as `RooObjCacheManager _normMgr` in `RooAbsPdf`) is the same as the one in the `_cacheList`. But when you read back the pdf in the second line, the `_normMgr` no longer is the same as the one in the `_cacheList` -- both caches (the one in the `_cacheList` and the `_normMgr`) have the gaus as its owner, but they are distinct objects and when the gaus is deleted I assume the one in the `_cacheList` doesnt get destroyed, causing the leak. . <br>If my diagnosis is correct, then I dunno what would be the correct way to fix this, the best way I can think of so far would be making `RooObjCacheManager` always be a pointer rather than an instance data member. Do others have thoughts? <br>Worth acknowledging the problem probably isn't just a memory leak when we have an inconsistency between the list of caches in the `RooAbsArg` base class vs the actual caches the derived classes might be interacting with directly, but i havent studied that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8764
https://github.com/root-project/root/pull/8766:12,deployability,build,building,12,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:88,deployability,releas,release,88,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:156,deployability,releas,release,156,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:171,deployability,depend,depends,171,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:171,integrability,depend,depends,171,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:121,interoperability,incompatib,incompatible,121,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:171,modifiability,depend,depends,171,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:171,safety,depend,depends,171,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/pull/8766:171,testability,depend,depends,171,[cmake] Fix building ROOT with external llvm.; Fixes #8141. This PR requires a new clad release v0.9. The clad master is incompatible with ROOT atm and the release of 0.9 depends on #8371,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8766
https://github.com/root-project/root/issues/8767:1493,availability,slo,slow,1493,". from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2724,availability,error,error,2724,"src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:461,energy efficiency,alloc,allocator,461,"[netxng] Crash in on-exit destruction of an TNetXNGFile object; root master, xrootd-5.3.0. To reproduce: TFile::Open(""root://.....""), then .q root. I will also post this to xrootd git. ```. 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. (gdb) bt. #0 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. #1 0x00007fffe91ecd62 in XrdCl::Env::GetInt(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int&) (). from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1032,energy efficiency,optim,optimized,1032," of an TNetXNGFile object; root master, xrootd-5.3.0. To reproduce: TFile::Open(""root://.....""), then .q root. I will also post this to xrootd git. ```. 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. (gdb) bt. #0 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. #1 0x00007fffe91ecd62 in XrdCl::Env::GetInt(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int&) (). from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1195,energy efficiency,optim,optimized,1195,"f74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. (gdb) bt. #0 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. #1 0x00007fffe91ecd62 in XrdCl::Env::GetInt(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int&) (). from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1379,energy efficiency,core,core,1379,"rdCl::Env::GetInt(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int&) (). from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1531,energy efficiency,core,core,1531,"7fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /ho",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1650,energy efficiency,alloc,alloc,1650,"::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1669,energy efficiency,optim,optimized,1669,"from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1717,energy efficiency,core,core,1717,"fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 """,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1823,energy efficiency,core,core,1823," XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7fa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2091,energy efficiency,core,core,2091,"c/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermI",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2234,energy efficiency,core,core,2234,"/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::Che",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2371,energy efficiency,core,core,2371,"dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::D",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2558,energy efficiency,core,core,2558,"#11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /hom",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2778,energy efficiency,core,core,2778,"of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (thi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2903,energy efficiency,core,core,2903," /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3032,energy efficiency,core,core,3032,"2a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (arg",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3165,energy efficiency,core,core,3165,"cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (argc=1, argv=0x7fffffffda28) at /home/matevz/root-dev/dev-1/main/src/rmain.cxx:30. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3297,energy efficiency,core,core,3297,"cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (argc=1, argv=0x7fffffffda28) at /home/matevz/root-dev/dev-1/main/src/rmain.cxx:30. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3456,energy efficiency,core,core,3456,"cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (argc=1, argv=0x7fffffffda28) at /home/matevz/root-dev/dev-1/main/src/rmain.cxx:30. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3584,energy efficiency,core,core,3584,"cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (argc=1, argv=0x7fffffffda28) at /home/matevz/root-dev/dev-1/main/src/rmain.cxx:30. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3701,energy efficiency,core,core,3701,"cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (argc=1, argv=0x7fffffffda28) at /home/matevz/root-dev/dev-1/main/src/rmain.cxx:30. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3836,energy efficiency,core,core,3836,"cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (argc=1, argv=0x7fffffffda28) at /home/matevz/root-dev/dev-1/main/src/rmain.cxx:30. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:3970,energy efficiency,core,core,3970,"cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:356. #27 0x00007ffff7b0c963 in TApplication::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1604. #28 0x00007ffff7fabddd in TRint::Run (this=0x482000, retrn=false) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:463. #29 0x00000000004011e8 in main (argc=1, argv=0x7fffffffda28) at /home/matevz/root-dev/dev-1/main/src/rmain.cxx:30. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1032,performance,optimiz,optimized,1032," of an TNetXNGFile object; root master, xrootd-5.3.0. To reproduce: TFile::Open(""root://.....""), then .q root. I will also post this to xrootd git. ```. 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. (gdb) bt. #0 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. #1 0x00007fffe91ecd62 in XrdCl::Env::GetInt(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int&) (). from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a8",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1195,performance,optimiz,optimized,1195,"f74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. (gdb) bt. #0 0x00007ffff74b1a66 in pthread_rwlock_rdlock () from /lib64/libpthread.so.0. #1 0x00007fffe91ecd62 in XrdCl::Env::GetInt(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int&) (). from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1669,performance,optimiz,optimized,1669,"from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2724,performance,error,error,2724,"src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:1493,reliability,slo,slow,1493,". from /lib64/libXrdCl.so.3. #2 0x00007fffe9207a39 in XrdCl::PostMaster::PostMaster() () from /lib64/libXrdCl.so.3. #3 0x00007fffe91fed5e in XrdCl::DefaultEnv::GetPostMaster() () from /lib64/libXrdCl.so.3. #4 0x00007fffe9245fc5 in XrdCl::FileStateHandler::~FileStateHandler() () from /lib64/libXrdCl.so.3. #5 0x00007fffe9243bd0 in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #6 0x00007fffe9243c6d in XrdCl::File::~File() () from /lib64/libXrdCl.so.3. #7 0x00007fffef69630f in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:233. #8 0x00007fffef696396 in TNetXNGFile::~TNetXNGFile (this=0x2019f20, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2724,safety,error,error,2724,"src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2193,usability,statu,status,2193,"ptimized out>). at /home/matevz/root-dev/dev-1/net/netxng/src/TNetXNGFile.cxx:236. #9 0x00007ffff7bc5ad3 in TCollection::GarbageCollect (obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2330,usability,statu,status,2330,"obj=0x2019f20) at /home/matevz/root-dev/dev-1/core/cont/src/TCollection.cxx:736. #10 0x00007ffff7bcdbe5 in TList::Delete (this=0x4307c0, option=0x7ffff7e1726b ""slow"") at /home/matevz/root-dev/dev-1/core/cont/src/TList.cxx:508. #11 0x00007ffff7af756b in TROOT::~TROOT (this=0x7ffff7f5a900 <ROOT::Internal::GetROOT1()::alloc>, __in_chrg=<optimized out>). at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/issues/8767:2724,usability,error,error,2724,"src/TROOT.cxx:889. #12 0x00007ffff7af4f5f in at_exit_of_TROOT () at /home/matevz/root-dev/dev-1/core/base/src/TROOT.cxx:290. #13 0x00007ffff7317247 in __run_exit_handlers () from /lib64/libc.so.6. #14 0x00007ffff73173f0 in exit () from /lib64/libc.so.6. #15 0x00007ffff7c91627 in TUnixSystem::Exit (this=0x42a800, code=0, mode=true) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:2157. #16 0x00007ffff7b0cc16 in TApplication::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1672. #17 0x00007ffff7facf9d in TRint::Terminate (this=0x482000, status=0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:696. #18 0x00007ffff7b0b37d in TApplication::ProcessLine (this=0x482000, line=0x7fffffffb589 "".q"", sync=false, err=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/base/src/TApplication.cxx:1334. #19 0x00007ffff7fad334 in TRint::ProcessLineNr (this=0x482000, filestem=0x7ffff7fbd6cf ""ROOT_prompt_"", line=0x7fffffffb589 "".q"", error=0x7fffffffb51c). at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:766. #20 0x00007ffff7facab4 in TRint::HandleTermInput (this=0x482000) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:612. #21 0x00007ffff7faa5c5 in TTermInputHandler::Notify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:132. #22 0x00007ffff7fae98f in TTermInputHandler::ReadNotify (this=0x1381dc0) at /home/matevz/root-dev/dev-1/core/rint/src/TRint.cxx:124. #23 0x00007ffff7c8fa8a in TUnixSystem::CheckDescriptors (this=0x42a800) at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1322. #24 0x00007ffff7c8eec6 in TUnixSystem::DispatchOneEvent (this=0x42a800, pendingOnly=false). at /home/matevz/root-dev/dev-1/core/unix/src/TUnixSystem.cxx:1077. #25 0x00007ffff7b7e773 in TSystem::InnerLoop (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:406. #26 0x00007ffff7b7e519 in TSystem::Run (this=0x42a800) at /home/matevz/root-dev/dev-1/core/base/src/TSystem.cxx:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8767
https://github.com/root-project/root/pull/8768:120,deployability,build,builds,120,"[RF] Fix rf408_RDataFrameToRooFit.py crash by adding missing std::move; This hotfixes the crashes seen in the recent PR builds. However, having to use `std::move` in pyROOT is quite unpythonic and we. should think about an improved interface for creating RooFit datasets. from RDataFrame in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8768
https://github.com/root-project/root/pull/8768:232,integrability,interfac,interface,232,"[RF] Fix rf408_RDataFrameToRooFit.py crash by adding missing std::move; This hotfixes the crashes seen in the recent PR builds. However, having to use `std::move` in pyROOT is quite unpythonic and we. should think about an improved interface for creating RooFit datasets. from RDataFrame in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8768
https://github.com/root-project/root/pull/8768:232,interoperability,interfac,interface,232,"[RF] Fix rf408_RDataFrameToRooFit.py crash by adding missing std::move; This hotfixes the crashes seen in the recent PR builds. However, having to use `std::move` in pyROOT is quite unpythonic and we. should think about an improved interface for creating RooFit datasets. from RDataFrame in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8768
https://github.com/root-project/root/pull/8768:232,modifiability,interfac,interface,232,"[RF] Fix rf408_RDataFrameToRooFit.py crash by adding missing std::move; This hotfixes the crashes seen in the recent PR builds. However, having to use `std::move` in pyROOT is quite unpythonic and we. should think about an improved interface for creating RooFit datasets. from RDataFrame in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8768
https://github.com/root-project/root/pull/8768:77,safety,hot,hotfixes,77,"[RF] Fix rf408_RDataFrameToRooFit.py crash by adding missing std::move; This hotfixes the crashes seen in the recent PR builds. However, having to use `std::move` in pyROOT is quite unpythonic and we. should think about an improved interface for creating RooFit datasets. from RDataFrame in the future.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8768
https://github.com/root-project/root/pull/8769:1,energy efficiency,core,core,1,"[core][RF] New ROOT/RRangeCast.hxx with RangeStaticCast and RangeDynCast and first use of it in RooFit; In RooFit, iterating over collections of `RooAbsArg*` and applying `static_cast` and `dynamic_cast` to every item is ubiquitous. This PR introduces a way to do the casing in a less verbose way in the `for`-line of the range-based loop with the `static_span_cast` and `dynamic_span_cast` functions. Thanks to @hageboeck for the suggestion. The second commit in this PR shows examples on how they can be used in RooFit. The reason for doing this PR now it that I want to open a `good-first-issue` in RooFit range-based loop migration for people who want to contribute to RooFit by doing some easy tasks. These span-casting functions are the missing ingredient before the migration can be started. By the way, the names of the functions were inspired by `static_pointer_cast` and `dynamic_pointer_cast`:. https://en.cppreference.com/w/cpp/memory/shared_ptr/pointer_cast.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8769
https://github.com/root-project/root/pull/8769:940,performance,memor,memory,940,"[core][RF] New ROOT/RRangeCast.hxx with RangeStaticCast and RangeDynCast and first use of it in RooFit; In RooFit, iterating over collections of `RooAbsArg*` and applying `static_cast` and `dynamic_cast` to every item is ubiquitous. This PR introduces a way to do the casing in a less verbose way in the `for`-line of the range-based loop with the `static_span_cast` and `dynamic_span_cast` functions. Thanks to @hageboeck for the suggestion. The second commit in this PR shows examples on how they can be used in RooFit. The reason for doing this PR now it that I want to open a `good-first-issue` in RooFit range-based loop migration for people who want to contribute to RooFit by doing some easy tasks. These span-casting functions are the missing ingredient before the migration can be started. By the way, the names of the functions were inspired by `static_pointer_cast` and `dynamic_pointer_cast`:. https://en.cppreference.com/w/cpp/memory/shared_ptr/pointer_cast.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8769
https://github.com/root-project/root/pull/8769:940,usability,memor,memory,940,"[core][RF] New ROOT/RRangeCast.hxx with RangeStaticCast and RangeDynCast and first use of it in RooFit; In RooFit, iterating over collections of `RooAbsArg*` and applying `static_cast` and `dynamic_cast` to every item is ubiquitous. This PR introduces a way to do the casing in a less verbose way in the `for`-line of the range-based loop with the `static_span_cast` and `dynamic_span_cast` functions. Thanks to @hageboeck for the suggestion. The second commit in this PR shows examples on how they can be used in RooFit. The reason for doing this PR now it that I want to open a `good-first-issue` in RooFit range-based loop migration for people who want to contribute to RooFit by doing some easy tasks. These span-casting functions are the missing ingredient before the migration can be started. By the way, the names of the functions were inspired by `static_pointer_cast` and `dynamic_pointer_cast`:. https://en.cppreference.com/w/cpp/memory/shared_ptr/pointer_cast.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8769
https://github.com/root-project/root/pull/8770:505,deployability,updat,updated,505,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:374,interoperability,interop,interop,374,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:374,modifiability,interop,interop,374,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:40,performance,I/O,I/O,40,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:107,performance,I/O,I/O,107,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:302,performance,I/O,I/O,302,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:382,performance,I/O,I/O,382,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:280,safety,test,tests,280,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:323,safety,test,tests,323,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:364,safety,test,tests,364,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:475,safety,test,tested,475,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:505,safety,updat,updated,505,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:505,security,updat,updated,505,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:280,testability,test,tests,280,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:323,testability,test,tests,323,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:364,testability,test,tests,364,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:475,testability,test,tested,475,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8770:254,usability,support,support,254,[ntuple] Add RRVecField for type-erased I/O of RVecs; This PR:. - adds the RRVecField type for type-erased I/O of RVecs with RNTuple. - removes some special-casing of `RVec<bool>` which is unnecessary now that we have RVec 2.0. - adds RPrintValueVisitor support for RVecs. - adds tests for type-erased I/O of RVecs. - adds tests for `ntuple->Show` + RVecs. - adds tests for interop I/O of std::vectors and RVecs (i.e. writing one and reading the other). ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary): I don't think it's necessary. This PR fixes #6347 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8770
https://github.com/root-project/root/pull/8771:851,availability,restor,restores,851,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:344,deployability,continu,continuation,344,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:439,deployability,continu,continuation,439,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:823,energy efficiency,current,current,823,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:376,interoperability,Specif,Specifically,376,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:176,modifiability,maintain,maintainable,176,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:851,reliability,restor,restores,851,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:35,safety,Input,InputValidator,35,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:51,safety,valid,validate,51,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:131,safety,Input,InputValidator,131,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:147,safety,valid,validate,147,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:176,safety,maintain,maintainable,176,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:508,safety,input,input,508,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:594,safety,input,input,594,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:749,safety,input,input,749,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:938,safety,Input,InputValidator,938,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:954,safety,valid,validate,954,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:988,safety,test,tested,988,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:51,security,validat,validate,51,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:147,security,validat,validate,147,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:422,security,token,tokens,422,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:494,security,token,tokens,494,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:695,security,token,tokens,695,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:954,security,validat,validate,954,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:162,testability,simpl,simpler,162,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:988,testability,test,tested,988,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:35,usability,Input,InputValidator,35,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:131,usability,Input,InputValidator,131,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:162,usability,simpl,simpler,162,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:508,usability,input,input,508,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:594,usability,input,input,594,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:749,usability,input,input,749,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8771:938,usability,Input,InputValidator,938,"[cling] Rewrite implementation of `InputValidator::validate()`; fixes ROOT-9202; This pull request replaces the implementation of `InputValidator::validate()` by simpler, more maintainable code that also fixes JIRA issue [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202). The previous implementation was unable to properly handle line continuation after ',' or '\\'. Specifically, it skipped over non-punctuation tokens, entering continuation mode even if ',' or '\' were not the last tokens in the input, e.g. ```. int a, b. ```. or. ```. int a \ b. ```. caused cling to request more input, where it shouldn't. ## Changes or fixes:. - MetaLexer:. - Return `/*` and `*/` as independent tokens. - Added `ReadToEndOfLine()` function (consume input until '\r', '\n', or EOF). - Added `MetaLexer::RAII` that saves the current lexing position and restores it on destruction. - Remove unused `LexPunctuatorAndAdvance()`. - Rewrite of `InputValidator::validate()`. ## Checklist:. - [X] tested changes locally. Fixes [ROOT-9202](https://sft.its.cern.ch/jira/browse/ROOT-9202).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8771
https://github.com/root-project/root/pull/8772:359,availability,error,error,359,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:430,availability,error,error,430,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:29,deployability,continu,continuation,29,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:232,deployability,continu,continued,232,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:397,modifiability,paramet,parameter,397,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:359,performance,error,error,359,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:430,performance,error,error,430,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:68,reliability,diagno,diagnostics,68,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:166,safety,input,input,166,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:359,safety,error,error,359,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:430,safety,error,error,430,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:532,safety,test,tested,532,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:455,security,ident,identifier,455,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:68,testability,diagno,diagnostics,68,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:532,testability,test,tested,532,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:166,usability,input,input,166,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:316,usability,cancel,cancel,316,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:359,usability,error,error,359,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8772:430,usability,error,error,430,"[Rint] Correctly handle line continuation after '\'; To have better diagnostics, `TRint::ProcessLineNr()` prepends a `#line 1 ""ROOT_prompt_xxx""` PP directive to each input line. However, this causes problems if the previous line is continued with '\\', e.g. ```. root [0] #define m(x) printf(""%s"", \. root (cont'ed, cancel with .@) [1]x);. ROOT_prompt_0:2:2: error; '#' is not followed by a macro parameter. ^. ROOT_prompt_0:3:1: error; use of undeclared identifier 'x'. x);. ^. ```. This PR fixes issue #8762. ## Checklist:. - [X] tested changes locally",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8772
https://github.com/root-project/root/pull/8773:280,deployability,modul,module,280,"[ntuple, tidy] First attempt at a default set of checks and some fixes; # This Pull request:. A first attempt at picking a good set of defaults for clang-tidy, together with the first 100 or so fixes in the RNTuple code base. It will be some effort to clean even just the RNTuple module, so I expect the cleanup to take several PRs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8773
https://github.com/root-project/root/pull/8773:280,modifiability,modul,module,280,"[ntuple, tidy] First attempt at a default set of checks and some fixes; # This Pull request:. A first attempt at picking a good set of defaults for clang-tidy, together with the first 100 or so fixes in the RNTuple code base. It will be some effort to clean even just the RNTuple module, so I expect the cleanup to take several PRs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8773
https://github.com/root-project/root/pull/8773:280,safety,modul,module,280,"[ntuple, tidy] First attempt at a default set of checks and some fixes; # This Pull request:. A first attempt at picking a good set of defaults for clang-tidy, together with the first 100 or so fixes in the RNTuple code base. It will be some effort to clean even just the RNTuple module, so I expect the cleanup to take several PRs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8773
https://github.com/root-project/root/issues/8774:385,availability,state,state,385,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:346,deployability,depend,dependent,346,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:237,energy efficiency,current,current,237,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:346,integrability,depend,dependent,346,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:385,integrability,state,state,385,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:346,modifiability,depend,dependent,346,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:346,safety,depend,dependent,346,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:346,testability,depend,dependent,346,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8774:421,testability,context,context,421,"[TGaxis] secAxis->SetMaxDigits changes all other axes; ### Is your feature request related to a problem? Please describe. A long-standing TGaxis issue is that calling secondaryXaxis->SetMaxDigits(N) affects all other X and Y axes in the current canvas. ### Describe the solution you'd like. TGaxis::SetMaxDigits, StripDecimals, etc. are all axes-dependent and don't affect the default state of other axes. ### Additional context. https://root-forum.cern.ch/t/tgaxis-setmaxdigits/11543/2?u=ferhue. https://sft.its.cern.ch/jira/browse/ROOT-35. https://root-forum.cern.ch/t/tgaxis-setmaxdigits-not-working-as-expected/2889/3. https://root-forum.cern.ch/t/tgaxis-and-setmaxdigits/19425/5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8774
https://github.com/root-project/root/issues/8775:431,testability,context,context,431,"Freedom; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [idk] when I want to [brb]. -->. ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? Hype. -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8775
https://github.com/root-project/root/issues/8775:460,testability,context,context,460,"Freedom; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [idk] when I want to [brb]. -->. ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? Hype. -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8775
https://github.com/root-project/root/issues/8775:84,usability,clear,clear,84,"Freedom; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [idk] when I want to [brb]. -->. ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? Hype. -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8775
https://github.com/root-project/root/issues/8775:239,usability,clear,clear,239,"Freedom; ### Is your feature request related to a problem? Please describe. <!--. A clear and concise description of what the problem is. E.g ""I always have to [idk] when I want to [brb]. -->. ### Describe the solution you'd like. <!--. A clear and concise description of what you want to happen. -->. ### Describe alternatives you've considered. <!--. Can you think of alternative solutions or features? Hype. -->. ### Additional context. <!--. Add any other context or screenshots about the feature requested here. -->",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8775
https://github.com/root-project/root/pull/8776:57,deployability,patch,patch,57,"[ntuple] Add 'std::' qualifier to int32_t, uint32_t; The patch is a side-effect of addressing your comments in https://github.com/root-project/root/pull/8770 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8776
https://github.com/root-project/root/pull/8776:57,safety,patch,patch,57,"[ntuple] Add 'std::' qualifier to int32_t, uint32_t; The patch is a side-effect of addressing your comments in https://github.com/root-project/root/pull/8770 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8776
https://github.com/root-project/root/pull/8776:57,security,patch,patch,57,"[ntuple] Add 'std::' qualifier to int32_t, uint32_t; The patch is a side-effect of addressing your comments in https://github.com/root-project/root/pull/8770 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8776
https://github.com/root-project/root/issues/8777:1158,availability,error,errors,1158,"urce contributor who wants to get started contributing to ROOT with a well-defined task!**. **This issue has already been addressed partially by many PRs, the only remaining iterator-creating function to look out for and replace is **`RooLinkedList::MakeIterator()`**!**. ## Introduction. RooFit needs to be migrated to use range-based loops to iterate over RooArgLists, RooArgSets, and RooLinkedLists. The [deprecated iterator-creating functions](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooAbsCollection.h#L178) `RooAbsCollection::createIterator()`, `RooAbsCollection::iterator()`, and `RooAbsCollection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((arg=(RooAbsArg*)iter->Next())) { . // do something with arg. }. ```. ```C++. // with range-based loop. for(auto const* arg : *comps) { . // do something with arg.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:823,performance,overhead,overhead,823,"[RF] Migration from RooAbsCollection and RooLinkedList legacy iterators to range-based loops; **This migration is a great first issue for an enthusiastic open source contributor who wants to get started contributing to ROOT with a well-defined task!**. **This issue has already been addressed partially by many PRs, the only remaining iterator-creating function to look out for and replace is **`RooLinkedList::MakeIterator()`**!**. ## Introduction. RooFit needs to be migrated to use range-based loops to iterate over RooArgLists, RooArgSets, and RooLinkedLists. The [deprecated iterator-creating functions](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooAbsCollection.h#L178) `RooAbsCollection::createIterator()`, `RooAbsCollection::iterator()`, and `RooAbsCollection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:859,performance,perform,performance,859,"[RF] Migration from RooAbsCollection and RooLinkedList legacy iterators to range-based loops; **This migration is a great first issue for an enthusiastic open source contributor who wants to get started contributing to ROOT with a well-defined task!**. **This issue has already been addressed partially by many PRs, the only remaining iterator-creating function to look out for and replace is **`RooLinkedList::MakeIterator()`**!**. ## Introduction. RooFit needs to be migrated to use range-based loops to iterate over RooArgLists, RooArgSets, and RooLinkedLists. The [deprecated iterator-creating functions](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooAbsCollection.h#L178) `RooAbsCollection::createIterator()`, `RooAbsCollection::iterator()`, and `RooAbsCollection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:1158,performance,error,errors,1158,"urce contributor who wants to get started contributing to ROOT with a well-defined task!**. **This issue has already been addressed partially by many PRs, the only remaining iterator-creating function to look out for and replace is **`RooLinkedList::MakeIterator()`**!**. ## Introduction. RooFit needs to be migrated to use range-based loops to iterate over RooArgLists, RooArgSets, and RooLinkedLists. The [deprecated iterator-creating functions](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooAbsCollection.h#L178) `RooAbsCollection::createIterator()`, `RooAbsCollection::iterator()`, and `RooAbsCollection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((arg=(RooAbsArg*)iter->Next())) { . // do something with arg. }. ```. ```C++. // with range-based loop. for(auto const* arg : *comps) { . // do something with arg.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:1786,performance,time,time,1786,"llection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((arg=(RooAbsArg*)iter->Next())) { . // do something with arg. }. ```. ```C++. // with range-based loop. for(auto const* arg : *comps) { . // do something with arg. }. ```. 2. Example where one can make use of `static_dynamic_cast`. ```C++. // with legacy iterator. RooFIter siter = fullPdfSet.fwdIterator() ;. RooAbsPdf* pdf ;. while((pdf=(RooAbsPdf*)siter.next())) {. // do something with pdf. }. ```. ```C++. // with range-based loop. for(auto const* pdf : static_range_cast<RooAbsPdf*>(fullPdfSet)) {. // do something with pdf. }. ```. 3. Example where one can make use of `static_dynamic_cast`. ```C++. // with legacy iterator. TIterator* uIter = usedObs->createIterator() ;. RooAbsArg* obs ;. while((obs=(RooAbsArg*)uIter->Next())) {. RooRealVar* rrv = dynamic_cast<RooRealVar*>(obs) ;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:1158,safety,error,errors,1158,"urce contributor who wants to get started contributing to ROOT with a well-defined task!**. **This issue has already been addressed partially by many PRs, the only remaining iterator-creating function to look out for and replace is **`RooLinkedList::MakeIterator()`**!**. ## Introduction. RooFit needs to be migrated to use range-based loops to iterate over RooArgLists, RooArgSets, and RooLinkedLists. The [deprecated iterator-creating functions](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooAbsCollection.h#L178) `RooAbsCollection::createIterator()`, `RooAbsCollection::iterator()`, and `RooAbsCollection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((arg=(RooAbsArg*)iter->Next())) { . // do something with arg. }. ```. ```C++. // with range-based loop. for(auto const* arg : *comps) { . // do something with arg.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:859,usability,perform,performance,859,"[RF] Migration from RooAbsCollection and RooLinkedList legacy iterators to range-based loops; **This migration is a great first issue for an enthusiastic open source contributor who wants to get started contributing to ROOT with a well-defined task!**. **This issue has already been addressed partially by many PRs, the only remaining iterator-creating function to look out for and replace is **`RooLinkedList::MakeIterator()`**!**. ## Introduction. RooFit needs to be migrated to use range-based loops to iterate over RooArgLists, RooArgSets, and RooLinkedLists. The [deprecated iterator-creating functions](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooAbsCollection.h#L178) `RooAbsCollection::createIterator()`, `RooAbsCollection::iterator()`, and `RooAbsCollection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:1158,usability,error,errors,1158,"urce contributor who wants to get started contributing to ROOT with a well-defined task!**. **This issue has already been addressed partially by many PRs, the only remaining iterator-creating function to look out for and replace is **`RooLinkedList::MakeIterator()`**!**. ## Introduction. RooFit needs to be migrated to use range-based loops to iterate over RooArgLists, RooArgSets, and RooLinkedLists. The [deprecated iterator-creating functions](https://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooAbsCollection.h#L178) `RooAbsCollection::createIterator()`, `RooAbsCollection::iterator()`, and `RooAbsCollection::fwdIterator()` have some overhead both is code verbosity and performance. For the RooLinkedList, the relevant function calls to replace are `RooLinkedList::MakeIterator()`, `RooLinkedList::iterator()`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((arg=(RooAbsArg*)iter->Next())) { . // do something with arg. }. ```. ```C++. // with range-based loop. for(auto const* arg : *comps) { . // do something with arg.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:2641,usability,uI,uIter,2641,"`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((arg=(RooAbsArg*)iter->Next())) { . // do something with arg. }. ```. ```C++. // with range-based loop. for(auto const* arg : *comps) { . // do something with arg. }. ```. 2. Example where one can make use of `static_dynamic_cast`. ```C++. // with legacy iterator. RooFIter siter = fullPdfSet.fwdIterator() ;. RooAbsPdf* pdf ;. while((pdf=(RooAbsPdf*)siter.next())) {. // do something with pdf. }. ```. ```C++. // with range-based loop. for(auto const* pdf : static_range_cast<RooAbsPdf*>(fullPdfSet)) {. // do something with pdf. }. ```. 3. Example where one can make use of `static_dynamic_cast`. ```C++. // with legacy iterator. TIterator* uIter = usedObs->createIterator() ;. RooAbsArg* obs ;. while((obs=(RooAbsArg*)uIter->Next())) {. RooRealVar* rrv = dynamic_cast<RooRealVar*>(obs) ;. if (rrv) {. // ... do something with rrv. }. }. ```. ```C++. // with range-based loop. for(auto const* rrv : dynamic_range_cast<RooRealVar*>(*usedObs)) {. if (rrv) {. // ... do something with rrv. }. }. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8777:2719,usability,uI,uIter,2719,"`, and `RooLinkedList::fwdIterator()`. To do the migration, one could remove the deprecated functions from the code and try to recompile ROOT. From the compiler errors, one can see where a migration away from the legacy iterators is needed. Alternatively, one could mark the legacy functions as `[[deprecated]]` and get compiler warnings. If the iteration involved a type casting of each item, one can also use the `static_range_cast` and `dynamic_range_cast` functions in RooFit to make the code more compact (introduced in https://github.com/root-project/root/pull/8769). It is not expected that the full migration is done in one pull request, as these legacy iterations appear everywhere in RooFit. One can proceed with occasional PRs, migrating only one or a few RooFit classes at the time. ## Migration examples. Here are some examples on how the migration to range-based loops can look like. 1. Basic example:. ```C++. // with legacy iterator. TIterator* iter = comps->createIterator() ;. while((arg=(RooAbsArg*)iter->Next())) { . // do something with arg. }. ```. ```C++. // with range-based loop. for(auto const* arg : *comps) { . // do something with arg. }. ```. 2. Example where one can make use of `static_dynamic_cast`. ```C++. // with legacy iterator. RooFIter siter = fullPdfSet.fwdIterator() ;. RooAbsPdf* pdf ;. while((pdf=(RooAbsPdf*)siter.next())) {. // do something with pdf. }. ```. ```C++. // with range-based loop. for(auto const* pdf : static_range_cast<RooAbsPdf*>(fullPdfSet)) {. // do something with pdf. }. ```. 3. Example where one can make use of `static_dynamic_cast`. ```C++. // with legacy iterator. TIterator* uIter = usedObs->createIterator() ;. RooAbsArg* obs ;. while((obs=(RooAbsArg*)uIter->Next())) {. RooRealVar* rrv = dynamic_cast<RooRealVar*>(obs) ;. if (rrv) {. // ... do something with rrv. }. }. ```. ```C++. // with range-based loop. for(auto const* rrv : dynamic_range_cast<RooRealVar*>(*usedObs)) {. if (rrv) {. // ... do something with rrv. }. }. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8777
https://github.com/root-project/root/issues/8778:214,availability,operat,operator,214,"rootdrawtree crash; running rootdrawtree without arguments leads to a crash. ```. [user@host]$ rootdrawtree . /usr/include/c++/8/bits/stl_vector.h:932: std::vector<_Tp, _Alloc>::reference std::vector<_Tp, _Alloc>::operator[](std::vector<_Tp, _Alloc>::size_type) [with _Tp = std::__cxx11::basic_string<char>; _Alloc = std::allocator<std::__cxx11::basic_string<char> >; std::vector<_Tp, _Alloc>::reference = std::__cxx11::basic_string<char>&; std::vector<_Tp, _Alloc>::size_type = long unsigned int]: Assertion '__builtin_expect(__n < this->size(), true)' failed. *** Break *** abort. ```. root 6.22.08 from EPEL on CentOS8 x86_64 . Sorry if that is a duplicate. Best regards,. Andrii.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8778
https://github.com/root-project/root/issues/8778:554,deployability,fail,failed,554,"rootdrawtree crash; running rootdrawtree without arguments leads to a crash. ```. [user@host]$ rootdrawtree . /usr/include/c++/8/bits/stl_vector.h:932: std::vector<_Tp, _Alloc>::reference std::vector<_Tp, _Alloc>::operator[](std::vector<_Tp, _Alloc>::size_type) [with _Tp = std::__cxx11::basic_string<char>; _Alloc = std::allocator<std::__cxx11::basic_string<char> >; std::vector<_Tp, _Alloc>::reference = std::__cxx11::basic_string<char>&; std::vector<_Tp, _Alloc>::size_type = long unsigned int]: Assertion '__builtin_expect(__n < this->size(), true)' failed. *** Break *** abort. ```. root 6.22.08 from EPEL on CentOS8 x86_64 . Sorry if that is a duplicate. Best regards,. Andrii.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8778
https://github.com/root-project/root/issues/8778:322,energy efficiency,alloc,allocator,322,"rootdrawtree crash; running rootdrawtree without arguments leads to a crash. ```. [user@host]$ rootdrawtree . /usr/include/c++/8/bits/stl_vector.h:932: std::vector<_Tp, _Alloc>::reference std::vector<_Tp, _Alloc>::operator[](std::vector<_Tp, _Alloc>::size_type) [with _Tp = std::__cxx11::basic_string<char>; _Alloc = std::allocator<std::__cxx11::basic_string<char> >; std::vector<_Tp, _Alloc>::reference = std::__cxx11::basic_string<char>&; std::vector<_Tp, _Alloc>::size_type = long unsigned int]: Assertion '__builtin_expect(__n < this->size(), true)' failed. *** Break *** abort. ```. root 6.22.08 from EPEL on CentOS8 x86_64 . Sorry if that is a duplicate. Best regards,. Andrii.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8778
